{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация вопросов с помощью Zephyr и Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(city_from, city_to, date_str, date_back, need_luggage):\n",
    "    prompt = \"Q: Generate a request or desire to buy a plane ticket\"\n",
    "    if city_from is not None and not pd.isna(city_from):\n",
    "        prompt += f\" from {city_from}\"\n",
    "    if city_to is not None and not pd.isna(city_to):\n",
    "        prompt += f\" to {city_to}\"\n",
    "    if date_str is not None and not pd.isna(date_str):\n",
    "        prompt += f\" on {date_str}\"\n",
    "    if date_back is not None and not pd.isna(date_back):\n",
    "        prompt += f\" with a return ticket on {date_back}\"\n",
    "    if need_luggage is not None and not pd.isna(need_luggage):\n",
    "        if need_luggage is True:\n",
    "            prompt += f\" with luggage\"\n",
    "        else:\n",
    "            prompt += f\" without luggage\"\n",
    "    prompt += \". Add only information given, do not add anything else. Write briefly, in one-two sentences in English. A:\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Llama.generate: prefix-match hit\n",
      "237it [00:10, 22.79it/s]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.33 ms /    56 runs   (    0.20 ms per token,  4942.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   10294.05 ms /    56 runs   (  183.82 ms per token,     5.44 tokens per second)\n",
      "llama_print_timings:       total time =   10392.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "238it [00:27,  6.89it/s]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.47 ms /    83 runs   (    0.20 ms per token,  5038.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1663.83 ms /    30 tokens (   55.46 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   15137.20 ms /    82 runs   (  184.60 ms per token,     5.42 tokens per second)\n",
      "llama_print_timings:       total time =   16943.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "239it [00:37,  4.36it/s]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    44 runs   (    0.21 ms per token,  4849.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2274.50 ms /    42 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =    7742.83 ms /    43 runs   (  180.07 ms per token,     5.55 tokens per second)\n",
      "llama_print_timings:       total time =   10092.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "240it [01:05,  1.79it/s]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.55 ms /   118 runs   (    0.22 ms per token,  4617.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1923.97 ms /    32 tokens (   60.12 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   25583.70 ms /   117 runs   (  218.66 ms per token,     4.57 tokens per second)\n",
      "llama_print_timings:       total time =   27740.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "241it [01:28,  1.07it/s]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.70 ms /    82 runs   (    0.22 ms per token,  4634.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4672.80 ms /    66 tokens (   70.80 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   18026.25 ms /    81 runs   (  222.55 ms per token,     4.49 tokens per second)\n",
      "llama_print_timings:       total time =   22861.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "242it [01:50,  1.43s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.57 ms /    86 runs   (    0.20 ms per token,  4895.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2702.76 ms /    30 tokens (   90.09 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:        eval time =   19193.30 ms /    85 runs   (  225.80 ms per token,     4.43 tokens per second)\n",
      "llama_print_timings:       total time =   22065.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "243it [02:05,  1.88s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.11 ms /    59 runs   (    0.22 ms per token,  4500.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2079.78 ms /    32 tokens (   64.99 ms per token,    15.39 tokens per second)\n",
      "llama_print_timings:        eval time =   13050.59 ms /    58 runs   (  225.01 ms per token,     4.44 tokens per second)\n",
      "llama_print_timings:       total time =   15248.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "244it [02:32,  2.98s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.74 ms /   108 runs   (    0.23 ms per token,  4365.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2375.06 ms /    30 tokens (   79.17 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:        eval time =   24091.76 ms /   107 runs   (  225.16 ms per token,     4.44 tokens per second)\n",
      "llama_print_timings:       total time =   26692.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "245it [02:44,  3.52s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    52 runs   (    0.23 ms per token,  4344.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2571.59 ms /    42 tokens (   61.23 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =    9473.59 ms /    51 runs   (  185.76 ms per token,     5.38 tokens per second)\n",
      "llama_print_timings:       total time =   12149.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "246it [03:27,  6.65s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      51.26 ms /   222 runs   (    0.23 ms per token,  4330.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3071.38 ms /    36 tokens (   85.32 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:        eval time =   39916.55 ms /   221 runs   (  180.62 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =   43442.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "247it [03:40,  7.30s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.90 ms /    55 runs   (    0.22 ms per token,  4621.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3778.04 ms /    61 tokens (   61.94 ms per token,    16.15 tokens per second)\n",
      "llama_print_timings:        eval time =    9202.97 ms /    54 runs   (  170.43 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   13081.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "248it [04:04,  9.39s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.60 ms /   130 runs   (    0.22 ms per token,  4545.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1790.83 ms /    30 tokens (   59.69 ms per token,    16.75 tokens per second)\n",
      "llama_print_timings:        eval time =   21909.65 ms /   129 runs   (  169.84 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   23954.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "249it [04:16,  9.80s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.08 ms /    59 runs   (    0.22 ms per token,  4511.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2165.67 ms /    33 tokens (   65.63 ms per token,    15.24 tokens per second)\n",
      "llama_print_timings:        eval time =    9782.30 ms /    58 runs   (  168.66 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   12060.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "250it [04:39, 12.11s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.11 ms /   123 runs   (    0.23 ms per token,  4375.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1771.52 ms /    30 tokens (   59.05 ms per token,    16.93 tokens per second)\n",
      "llama_print_timings:        eval time =   20713.28 ms /   122 runs   (  169.78 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   22731.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "251it [04:46, 11.14s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       6.13 ms /    29 runs   (    0.21 ms per token,  4727.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2449.22 ms /    42 tokens (   58.31 ms per token,    17.15 tokens per second)\n",
      "llama_print_timings:        eval time =    4841.53 ms /    28 runs   (  172.91 ms per token,     5.78 tokens per second)\n",
      "llama_print_timings:       total time =    7343.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "252it [04:59, 11.54s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.15 ms /    63 runs   (    0.22 ms per token,  4452.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2254.45 ms /    36 tokens (   62.62 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10543.94 ms /    62 runs   (  170.06 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   12919.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "253it [05:22, 14.30s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.63 ms /   111 runs   (    0.21 ms per token,  4697.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3933.03 ms /    61 tokens (   64.48 ms per token,    15.51 tokens per second)\n",
      "llama_print_timings:        eval time =   18742.59 ms /   110 runs   (  170.39 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   22890.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "254it [05:36, 14.14s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.88 ms /    70 runs   (    0.23 ms per token,  4407.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1782.96 ms /    30 tokens (   59.43 ms per token,    16.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11744.11 ms /    69 runs   (  170.20 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   13665.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "255it [05:55, 15.63s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.36 ms /   105 runs   (    0.22 ms per token,  4494.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1879.35 ms /    32 tokens (   58.73 ms per token,    17.03 tokens per second)\n",
      "llama_print_timings:        eval time =   17593.36 ms /   104 runs   (  169.17 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   19679.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "256it [06:07, 14.37s/it]llama_print_timings:      sample time =      12.87 ms /    55 runs   (    0.23 ms per token,  4275.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1759.26 ms /    30 tokens (   58.64 ms per token,    17.05 tokens per second)\n",
      "llama_print_timings:        eval time =    9204.99 ms /    54 runs   (  170.46 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   11076.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "257it [06:24, 15.24s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.81 ms /    87 runs   (    0.23 ms per token,  4391.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2556.90 ms /    42 tokens (   60.88 ms per token,    16.43 tokens per second)\n",
      "llama_print_timings:        eval time =   14695.64 ms /    86 runs   (  170.88 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   17428.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "258it [06:46, 17.13s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.20 ms /   115 runs   (    0.23 ms per token,  4389.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2201.51 ms /    36 tokens (   61.15 ms per token,    16.35 tokens per second)\n",
      "llama_print_timings:        eval time =   19353.47 ms /   114 runs   (  169.77 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   21783.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "259it [06:59, 15.99s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.60 ms /    57 runs   (    0.22 ms per token,  4524.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3595.86 ms /    61 tokens (   58.95 ms per token,    16.96 tokens per second)\n",
      "llama_print_timings:        eval time =    9539.59 ms /    56 runs   (  170.35 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   13245.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "260it [07:11, 14.86s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.77 ms /    59 runs   (    0.23 ms per token,  4285.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2121.30 ms /    30 tokens (   70.71 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =    9906.04 ms /    58 runs   (  170.79 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   12148.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "261it [07:31, 16.31s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.50 ms /   104 runs   (    0.23 ms per token,  4424.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1991.80 ms /    33 tokens (   60.36 ms per token,    16.57 tokens per second)\n",
      "llama_print_timings:        eval time =   17538.96 ms /   103 runs   (  170.28 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   19733.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "262it [07:46, 15.96s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.78 ms /    78 runs   (    0.23 ms per token,  4387.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1961.98 ms /    30 tokens (   65.40 ms per token,    15.29 tokens per second)\n",
      "llama_print_timings:        eval time =   13022.21 ms /    77 runs   (  169.12 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   15139.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "263it [07:54, 13.59s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    33 runs   (    0.23 ms per token,  4395.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2506.90 ms /    42 tokens (   59.69 ms per token,    16.75 tokens per second)\n",
      "llama_print_timings:        eval time =    5424.36 ms /    32 runs   (  169.51 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =    7996.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "264it [07:56, 10.23s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     2 runs   (    0.26 ms per token,  3795.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2170.08 ms /    36 tokens (   60.28 ms per token,    16.59 tokens per second)\n",
      "llama_print_timings:        eval time =     165.09 ms /     1 runs   (  165.09 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =    2339.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "265it [08:08, 10.70s/it]llama_print_timings:      sample time =      10.86 ms /    49 runs   (    0.22 ms per token,  4513.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3592.35 ms /    61 tokens (   58.89 ms per token,    16.98 tokens per second)\n",
      "llama_print_timings:        eval time =    8124.80 ms /    48 runs   (  169.27 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   11813.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "266it [08:18, 10.32s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    44 runs   (    0.23 ms per token,  4434.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2011.94 ms /    30 tokens (   67.06 ms per token,    14.91 tokens per second)\n",
      "llama_print_timings:        eval time =    7324.38 ms /    43 runs   (  170.33 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =    9424.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "267it [08:38, 13.38s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.15 ms /   109 runs   (    0.23 ms per token,  4334.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1910.04 ms /    32 tokens (   59.69 ms per token,    16.75 tokens per second)\n",
      "llama_print_timings:        eval time =   18407.95 ms /   108 runs   (  170.44 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   20541.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "268it [08:48, 12.34s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.53 ms /    48 runs   (    0.22 ms per token,  4559.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1775.08 ms /    30 tokens (   59.17 ms per token,    16.90 tokens per second)\n",
      "llama_print_timings:        eval time =    8019.84 ms /    47 runs   (  170.63 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =    9889.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "269it [09:11, 15.53s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.80 ms /   120 runs   (    0.23 ms per token,  4315.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2484.45 ms /    42 tokens (   59.15 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =   20255.27 ms /   119 runs   (  170.21 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   22992.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "270it [09:21, 13.88s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.22 ms /    47 runs   (    0.22 ms per token,  4597.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2167.78 ms /    36 tokens (   60.22 ms per token,    16.61 tokens per second)\n",
      "llama_print_timings:        eval time =    7773.58 ms /    46 runs   (  168.99 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   10034.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "271it [09:36, 14.32s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.90 ms /    69 runs   (    0.23 ms per token,  4339.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3630.68 ms /    61 tokens (   59.52 ms per token,    16.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11570.65 ms /    68 runs   (  170.16 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   15345.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "272it [09:48, 13.41s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    56 runs   (    0.22 ms per token,  4518.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1826.54 ms /    30 tokens (   60.88 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =    9350.05 ms /    55 runs   (  170.00 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   11291.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "273it [09:58, 12.46s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.54 ms /    49 runs   (    0.24 ms per token,  4245.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1987.80 ms /    33 tokens (   60.24 ms per token,    16.60 tokens per second)\n",
      "llama_print_timings:        eval time =    8153.55 ms /    48 runs   (  169.87 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   10240.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "274it [10:26, 17.14s/it]llama_print_timings:      sample time =      35.73 ms /   153 runs   (    0.23 ms per token,  4282.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1794.13 ms /    30 tokens (   59.80 ms per token,    16.72 tokens per second)\n",
      "llama_print_timings:        eval time =   25947.16 ms /   152 runs   (  170.71 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   28062.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "275it [10:29, 12.79s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     2 runs   (    0.24 ms per token,  4158.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2465.08 ms /    42 tokens (   58.69 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =     162.11 ms /     1 runs   (  162.11 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =    2630.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "276it [10:44, 13.50s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.99 ms /    76 runs   (    0.24 ms per token,  4224.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2281.90 ms /    36 tokens (   63.39 ms per token,    15.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12728.08 ms /    75 runs   (  169.71 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   15170.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "277it [10:57, 13.49s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.79 ms /    58 runs   (    0.22 ms per token,  4533.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3613.05 ms /    61 tokens (   59.23 ms per token,    16.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9708.54 ms /    57 runs   (  170.33 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   13437.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "278it [11:13, 14.05s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.55 ms /    79 runs   (    0.22 ms per token,  4500.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1804.27 ms /    30 tokens (   60.14 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   13409.14 ms /    78 runs   (  171.91 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =   15376.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "279it [11:21, 12.27s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    37 runs   (    0.23 ms per token,  4333.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1936.28 ms /    32 tokens (   60.51 ms per token,    16.53 tokens per second)\n",
      "llama_print_timings:        eval time =    6091.57 ms /    36 runs   (  169.21 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =    8103.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "280it [11:33, 12.25s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.15 ms /    62 runs   (    0.23 ms per token,  4381.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1784.12 ms /    30 tokens (   59.47 ms per token,    16.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10308.86 ms /    61 runs   (  169.00 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   12218.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "281it [11:41, 11.02s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    34 runs   (    0.23 ms per token,  4268.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2483.84 ms /    42 tokens (   59.14 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =    5589.80 ms /    33 runs   (  169.39 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =    8144.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "282it [11:53, 11.14s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.78 ms /    55 runs   (    0.23 ms per token,  4304.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2178.71 ms /    36 tokens (   60.52 ms per token,    16.52 tokens per second)\n",
      "llama_print_timings:        eval time =    9136.75 ms /    54 runs   (  169.20 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   11424.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "283it [12:08, 12.54s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.89 ms /    72 runs   (    0.22 ms per token,  4532.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3642.57 ms /    61 tokens (   59.71 ms per token,    16.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11990.46 ms /    71 runs   (  168.88 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   15783.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "284it [12:17, 11.51s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.70 ms /    43 runs   (    0.23 ms per token,  4431.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1802.67 ms /    30 tokens (   60.09 ms per token,    16.64 tokens per second)\n",
      "llama_print_timings:        eval time =    7205.89 ms /    42 runs   (  171.57 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =    9099.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "285it [12:29, 11.54s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    57 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1983.44 ms /    33 tokens (   60.10 ms per token,    16.64 tokens per second)\n",
      "llama_print_timings:        eval time =    9521.17 ms /    56 runs   (  170.02 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   11624.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "286it [12:45, 12.85s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.78 ms /    83 runs   (    0.23 ms per token,  4419.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1782.44 ms /    30 tokens (   59.41 ms per token,    16.83 tokens per second)\n",
      "llama_print_timings:        eval time =   13933.32 ms /    82 runs   (  169.92 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   15884.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "287it [12:54, 11.58s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    37 runs   (    0.22 ms per token,  4482.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2485.54 ms /    42 tokens (   59.18 ms per token,    16.90 tokens per second)\n",
      "llama_print_timings:        eval time =    6073.88 ms /    36 runs   (  168.72 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =    8634.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "288it [13:08, 12.43s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.68 ms /    72 runs   (    0.23 ms per token,  4317.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2188.92 ms /    36 tokens (   60.80 ms per token,    16.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12078.29 ms /    71 runs   (  170.12 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   14417.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "289it [13:33, 16.12s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.73 ms /   123 runs   (    0.23 ms per token,  4435.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3618.20 ms /    61 tokens (   59.31 ms per token,    16.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20832.92 ms /   122 runs   (  170.76 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   24710.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "290it [13:44, 14.52s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.26 ms /    52 runs   (    0.22 ms per token,  4616.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1995.61 ms /    30 tokens (   66.52 ms per token,    15.03 tokens per second)\n",
      "llama_print_timings:        eval time =    8685.57 ms /    51 runs   (  170.31 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   10791.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "291it [14:04, 16.23s/it]llama_print_timings:      sample time =      24.69 ms /   107 runs   (    0.23 ms per token,  4333.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1882.30 ms /    32 tokens (   58.82 ms per token,    17.00 tokens per second)\n",
      "llama_print_timings:        eval time =   18115.92 ms /   106 runs   (  170.90 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   20223.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "292it [14:14, 14.50s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.64 ms /    51 runs   (    0.23 ms per token,  4382.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1840.51 ms /    30 tokens (   61.35 ms per token,    16.30 tokens per second)\n",
      "llama_print_timings:        eval time =    8512.22 ms /    50 runs   (  170.24 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   10457.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.68 ms /    41 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2593.32 ms /    42 tokens (   61.75 ms per token,    16.20 tokens per second)\n",
      "llama_print_timings:        eval time =    6859.54 ms /    40 runs   (  171.49 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =    9540.76 ms\n",
      "293it [14:24, 13.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "294it [14:43, 14.83s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.62 ms /    99 runs   (    0.24 ms per token,  4192.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2183.92 ms /    36 tokens (   60.66 ms per token,    16.48 tokens per second)\n",
      "llama_print_timings:        eval time =   16662.08 ms /    98 runs   (  170.02 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   19055.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "295it [14:57, 14.62s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.91 ms /    61 runs   (    0.23 ms per token,  4384.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3722.81 ms /    61 tokens (   61.03 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10288.69 ms /    60 runs   (  171.48 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =   14139.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "296it [15:10, 14.19s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.58 ms /    51 runs   (    0.23 ms per token,  4406.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2040.86 ms /    30 tokens (   68.03 ms per token,    14.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11025.24 ms /    50 runs   (  220.50 ms per token,     4.54 tokens per second)\n",
      "llama_print_timings:       total time =   13183.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "297it [15:13, 10.70s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2580.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2331.99 ms /    33 tokens (   70.67 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =     198.63 ms /     1 runs   (  198.63 ms per token,     5.03 tokens per second)\n",
      "llama_print_timings:       total time =    2538.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "298it [15:25, 11.30s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.50 ms /    59 runs   (    0.25 ms per token,  4067.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2136.37 ms /    30 tokens (   71.21 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10447.02 ms /    58 runs   (  180.12 ms per token,     5.55 tokens per second)\n",
      "llama_print_timings:       total time =   12713.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "299it [15:46, 13.98s/it]llama_print_timings:      sample time =      21.75 ms /    93 runs   (    0.23 ms per token,  4275.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2730.41 ms /    42 tokens (   65.01 ms per token,    15.38 tokens per second)\n",
      "llama_print_timings:        eval time =   17284.94 ms /    92 runs   (  187.88 ms per token,     5.32 tokens per second)\n",
      "llama_print_timings:       total time =   20218.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "300it [16:55, 30.55s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      84.11 ms /   370 runs   (    0.23 ms per token,  4399.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2473.62 ms /    36 tokens (   68.71 ms per token,    14.55 tokens per second)\n",
      "llama_print_timings:        eval time =   65913.19 ms /   369 runs   (  178.63 ms per token,     5.60 tokens per second)\n",
      "llama_print_timings:       total time =   69222.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "301it [17:23, 29.92s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      30.89 ms /   137 runs   (    0.23 ms per token,  4434.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4635.78 ms /    66 tokens (   70.24 ms per token,    14.24 tokens per second)\n",
      "llama_print_timings:        eval time =   23538.69 ms /   136 runs   (  173.08 ms per token,     5.78 tokens per second)\n",
      "llama_print_timings:       total time =   28457.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "302it [17:44, 27.28s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.47 ms /   106 runs   (    0.23 ms per token,  4332.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2080.09 ms /    30 tokens (   69.34 ms per token,    14.42 tokens per second)\n",
      "llama_print_timings:        eval time =   18804.72 ms /   105 runs   (  179.09 ms per token,     5.58 tokens per second)\n",
      "llama_print_timings:       total time =   21114.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "303it [18:12, 27.22s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      32.62 ms /   141 runs   (    0.23 ms per token,  4321.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2026.91 ms /    32 tokens (   63.34 ms per token,    15.79 tokens per second)\n",
      "llama_print_timings:        eval time =   24757.25 ms /   140 runs   (  176.84 ms per token,     5.65 tokens per second)\n",
      "llama_print_timings:       total time =   27088.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "304it [18:35, 26.24s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      29.16 ms /   124 runs   (    0.24 ms per token,  4252.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1872.98 ms /    30 tokens (   62.43 ms per token,    16.02 tokens per second)\n",
      "llama_print_timings:        eval time =   21800.96 ms /   123 runs   (  177.24 ms per token,     5.64 tokens per second)\n",
      "llama_print_timings:       total time =   23938.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "305it [18:46, 21.59s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.05 ms /    48 runs   (    0.23 ms per token,  4342.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2559.13 ms /    42 tokens (   60.93 ms per token,    16.41 tokens per second)\n",
      "llama_print_timings:        eval time =    8089.69 ms /    47 runs   (  172.12 ms per token,     5.81 tokens per second)\n",
      "llama_print_timings:       total time =   10747.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "306it [18:58, 18.52s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.54 ms /    51 runs   (    0.25 ms per token,  4066.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2354.93 ms /    36 tokens (   65.41 ms per token,    15.29 tokens per second)\n",
      "llama_print_timings:        eval time =    8888.14 ms /    50 runs   (  177.76 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   11352.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "307it [19:22, 20.30s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.94 ms /   111 runs   (    0.23 ms per token,  4279.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4224.39 ms /    61 tokens (   69.25 ms per token,    14.44 tokens per second)\n",
      "llama_print_timings:        eval time =   19986.89 ms /   110 runs   (  181.70 ms per token,     5.50 tokens per second)\n",
      "llama_print_timings:       total time =   24457.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "308it [19:33, 17.41s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.93 ms /    52 runs   (    0.23 ms per token,  4359.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1858.70 ms /    30 tokens (   61.96 ms per token,    16.14 tokens per second)\n",
      "llama_print_timings:        eval time =    8692.40 ms /    51 runs   (  170.44 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   10660.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "309it [19:56, 19.14s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      29.17 ms /   122 runs   (    0.24 ms per token,  4182.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2206.83 ms /    33 tokens (   66.87 ms per token,    14.95 tokens per second)\n",
      "llama_print_timings:        eval time =   20705.68 ms /   121 runs   (  171.12 ms per token,     5.84 tokens per second)\n",
      "llama_print_timings:       total time =   23171.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "310it [19:58, 14.00s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     2 runs   (    0.24 ms per token,  4106.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1849.82 ms /    30 tokens (   61.66 ms per token,    16.22 tokens per second)\n",
      "llama_print_timings:        eval time =     166.20 ms /     1 runs   (  166.20 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =    2020.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "311it [20:17, 15.43s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.72 ms /    94 runs   (    0.23 ms per token,  4327.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2662.99 ms /    42 tokens (   63.40 ms per token,    15.77 tokens per second)\n",
      "llama_print_timings:        eval time =   15900.87 ms /    93 runs   (  170.98 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   18750.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "312it [20:34, 16.08s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      20.43 ms /    89 runs   (    0.23 ms per token,  4356.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2400.57 ms /    36 tokens (   66.68 ms per token,    15.00 tokens per second)\n",
      "llama_print_timings:        eval time =   15030.32 ms /    88 runs   (  170.80 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   17609.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "313it [20:58, 18.25s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.96 ms /   115 runs   (    0.23 ms per token,  4429.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3672.70 ms /    61 tokens (   60.21 ms per token,    16.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19400.54 ms /   114 runs   (  170.18 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   23303.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "314it [21:16, 18.40s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.30 ms /    99 runs   (    0.23 ms per token,  4439.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1808.25 ms /    30 tokens (   60.27 ms per token,    16.59 tokens per second)\n",
      "llama_print_timings:        eval time =   16728.77 ms /    98 runs   (  170.70 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   18735.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "315it [21:45, 21.52s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      36.41 ms /   157 runs   (    0.23 ms per token,  4312.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1959.95 ms /    32 tokens (   61.25 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =   26535.82 ms /   156 runs   (  170.10 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   28816.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "316it [21:56, 18.23s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.74 ms /    52 runs   (    0.25 ms per token,  4080.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1845.96 ms /    30 tokens (   61.53 ms per token,    16.25 tokens per second)\n",
      "llama_print_timings:        eval time =    8578.71 ms /    51 runs   (  168.21 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   10532.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "317it [22:03, 15.01s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    30 runs   (    0.22 ms per token,  4464.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2511.94 ms /    42 tokens (   59.81 ms per token,    16.72 tokens per second)\n",
      "llama_print_timings:        eval time =    4922.14 ms /    29 runs   (  169.73 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =    7495.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "318it [22:26, 17.44s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.61 ms /   123 runs   (    0.23 ms per token,  4299.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2204.37 ms /    36 tokens (   61.23 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =   20651.39 ms /   122 runs   (  169.27 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   23107.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "319it [22:39, 15.94s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    52 runs   (    0.23 ms per token,  4292.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3652.67 ms /    61 tokens (   59.88 ms per token,    16.70 tokens per second)\n",
      "llama_print_timings:        eval time =    8675.83 ms /    51 runs   (  170.11 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   12435.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "320it [22:49, 14.21s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.22 ms /    50 runs   (    0.22 ms per token,  4455.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1809.78 ms /    30 tokens (   60.33 ms per token,    16.58 tokens per second)\n",
      "llama_print_timings:        eval time =    8262.62 ms /    49 runs   (  168.62 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   10169.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "321it [23:08, 15.77s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.86 ms /   101 runs   (    0.24 ms per token,  4233.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2067.33 ms /    33 tokens (   62.65 ms per token,    15.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17149.01 ms /   100 runs   (  171.49 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =   19423.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "322it [23:28, 16.85s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.76 ms /   100 runs   (    0.23 ms per token,  4393.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1901.67 ms /    30 tokens (   63.39 ms per token,    15.78 tokens per second)\n",
      "llama_print_timings:        eval time =   16831.67 ms /    99 runs   (  170.02 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   18933.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "323it [23:44, 16.76s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.25 ms /    82 runs   (    0.23 ms per token,  4260.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2643.17 ms /    42 tokens (   62.93 ms per token,    15.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13715.62 ms /    81 runs   (  169.33 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   16527.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "324it [24:02, 17.11s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.31 ms /    92 runs   (    0.24 ms per token,  4123.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2220.91 ms /    36 tokens (   61.69 ms per token,    16.21 tokens per second)\n",
      "llama_print_timings:        eval time =   15524.40 ms /    91 runs   (  170.60 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   17938.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "325it [24:17, 16.36s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.08 ms /    63 runs   (    0.22 ms per token,  4474.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3972.69 ms /    61 tokens (   65.13 ms per token,    15.35 tokens per second)\n",
      "llama_print_timings:        eval time =   10502.77 ms /    62 runs   (  169.40 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   14600.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "326it [24:31, 15.84s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.07 ms /    75 runs   (    0.23 ms per token,  4393.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1846.29 ms /    30 tokens (   61.54 ms per token,    16.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12623.19 ms /    74 runs   (  170.58 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   14620.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "327it [24:43, 14.68s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.80 ms /    58 runs   (    0.24 ms per token,  4201.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2124.86 ms /    32 tokens (   66.40 ms per token,    15.06 tokens per second)\n",
      "llama_print_timings:        eval time =    9733.44 ms /    57 runs   (  170.76 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   11974.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "328it [24:57, 14.36s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.50 ms /    57 runs   (    0.24 ms per token,  4220.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1794.61 ms /    30 tokens (   59.82 ms per token,    16.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11685.07 ms /    56 runs   (  208.66 ms per token,     4.79 tokens per second)\n",
      "llama_print_timings:       total time =   13603.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "329it [25:10, 13.95s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    52 runs   (    0.24 ms per token,  4203.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3754.62 ms /    42 tokens (   89.40 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:        eval time =    9136.08 ms /    51 runs   (  179.14 ms per token,     5.58 tokens per second)\n",
      "llama_print_timings:       total time =   12995.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "330it [25:21, 13.09s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.89 ms /    49 runs   (    0.24 ms per token,  4119.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2397.31 ms /    36 tokens (   66.59 ms per token,    15.02 tokens per second)\n",
      "llama_print_timings:        eval time =    8573.07 ms /    48 runs   (  178.61 ms per token,     5.60 tokens per second)\n",
      "llama_print_timings:       total time =   11073.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "331it [25:46, 16.79s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.32 ms /   118 runs   (    0.23 ms per token,  4319.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3883.96 ms /    61 tokens (   63.67 ms per token,    15.71 tokens per second)\n",
      "llama_print_timings:        eval time =   21284.84 ms /   117 runs   (  181.92 ms per token,     5.50 tokens per second)\n",
      "llama_print_timings:       total time =   25417.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "332it [26:12, 19.34s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.94 ms /   127 runs   (    0.23 ms per token,  4388.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1899.54 ms /    30 tokens (   63.32 ms per token,    15.79 tokens per second)\n",
      "llama_print_timings:        eval time =   23140.64 ms /   126 runs   (  183.66 ms per token,     5.44 tokens per second)\n",
      "llama_print_timings:       total time =   25306.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "333it [26:30, 18.93s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.53 ms /    81 runs   (    0.24 ms per token,  4147.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2544.93 ms /    33 tokens (   77.12 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:        eval time =   15237.36 ms /    80 runs   (  190.47 ms per token,     5.25 tokens per second)\n",
      "llama_print_timings:       total time =   17952.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "334it [26:42, 16.90s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.94 ms /    55 runs   (    0.24 ms per token,  4249.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2118.84 ms /    30 tokens (   70.63 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =    9947.73 ms /    54 runs   (  184.22 ms per token,     5.43 tokens per second)\n",
      "llama_print_timings:       total time =   12177.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "335it [26:54, 15.45s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.39 ms /    48 runs   (    0.24 ms per token,  4212.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2818.25 ms /    42 tokens (   67.10 ms per token,    14.90 tokens per second)\n",
      "llama_print_timings:        eval time =    9138.06 ms /    47 runs   (  194.43 ms per token,     5.14 tokens per second)\n",
      "llama_print_timings:       total time =   12055.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "336it [27:11, 15.93s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.37 ms /    80 runs   (    0.24 ms per token,  4130.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2378.05 ms /    36 tokens (   66.06 ms per token,    15.14 tokens per second)\n",
      "llama_print_timings:        eval time =   14522.70 ms /    79 runs   (  183.83 ms per token,     5.44 tokens per second)\n",
      "llama_print_timings:       total time =   17066.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "337it [27:26, 15.64s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.28 ms /    60 runs   (    0.24 ms per token,  4202.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3965.09 ms /    61 tokens (   65.00 ms per token,    15.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10866.09 ms /    59 runs   (  184.17 ms per token,     5.43 tokens per second)\n",
      "llama_print_timings:       total time =   14956.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "338it [27:52, 18.82s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      29.61 ms /   128 runs   (    0.23 ms per token,  4323.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2030.25 ms /    30 tokens (   67.68 ms per token,    14.78 tokens per second)\n",
      "llama_print_timings:        eval time =   23914.58 ms /   127 runs   (  188.30 ms per token,     5.31 tokens per second)\n",
      "llama_print_timings:       total time =   26219.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "339it [28:19, 21.30s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.70 ms /   108 runs   (    0.25 ms per token,  4044.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2203.18 ms /    32 tokens (   68.85 ms per token,    14.52 tokens per second)\n",
      "llama_print_timings:        eval time =   24618.05 ms /   107 runs   (  230.08 ms per token,     4.35 tokens per second)\n",
      "llama_print_timings:       total time =   27082.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "340it [28:33, 18.89s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.20 ms /    60 runs   (    0.25 ms per token,  3947.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2520.62 ms /    30 tokens (   84.02 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:        eval time =   10610.22 ms /    59 runs   (  179.83 ms per token,     5.56 tokens per second)\n",
      "llama_print_timings:       total time =   13261.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "341it [28:51, 18.89s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.50 ms /    90 runs   (    0.24 ms per token,  4185.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2908.03 ms /    42 tokens (   69.24 ms per token,    14.44 tokens per second)\n",
      "llama_print_timings:        eval time =   15788.23 ms /    89 runs   (  177.40 ms per token,     5.64 tokens per second)\n",
      "llama_print_timings:       total time =   18885.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "342it [29:13, 19.72s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.31 ms /   111 runs   (    0.25 ms per token,  4064.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2426.70 ms /    36 tokens (   67.41 ms per token,    14.83 tokens per second)\n",
      "llama_print_timings:        eval time =   18987.08 ms /   110 runs   (  172.61 ms per token,     5.79 tokens per second)\n",
      "llama_print_timings:       total time =   21649.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "343it [29:29, 18.54s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.26 ms /    58 runs   (    0.25 ms per token,  4067.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4105.76 ms /    61 tokens (   67.31 ms per token,    14.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11565.00 ms /    57 runs   (  202.89 ms per token,     4.93 tokens per second)\n",
      "llama_print_timings:       total time =   15798.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "344it [30:03, 23.37s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      41.95 ms /   176 runs   (    0.24 ms per token,  4195.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2102.82 ms /    30 tokens (   70.09 ms per token,    14.27 tokens per second)\n",
      "llama_print_timings:        eval time =   32140.46 ms /   175 runs   (  183.66 ms per token,     5.44 tokens per second)\n",
      "llama_print_timings:       total time =   34623.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "345it [30:16, 20.17s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.84 ms /    58 runs   (    0.24 ms per token,  4189.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2916.26 ms /    33 tokens (   88.37 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:        eval time =    9661.17 ms /    57 runs   (  169.49 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   12694.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "346it [30:26, 17.02s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.69 ms /    44 runs   (    0.24 ms per token,  4114.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1878.43 ms /    30 tokens (   62.61 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =    7712.11 ms /    43 runs   (  179.35 ms per token,     5.58 tokens per second)\n",
      "llama_print_timings:       total time =    9681.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "347it [30:36, 14.92s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    42 runs   (    0.23 ms per token,  4260.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2634.01 ms /    42 tokens (   62.71 ms per token,    15.95 tokens per second)\n",
      "llama_print_timings:        eval time =    7291.06 ms /    41 runs   (  177.83 ms per token,     5.62 tokens per second)\n",
      "llama_print_timings:       total time =   10011.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "348it [30:46, 13.53s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.85 ms /    42 runs   (    0.23 ms per token,  4266.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2582.97 ms /    36 tokens (   71.75 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =    7606.41 ms /    41 runs   (  185.52 ms per token,     5.39 tokens per second)\n",
      "llama_print_timings:       total time =   10277.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "349it [31:06, 15.30s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.46 ms /    82 runs   (    0.24 ms per token,  4212.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3960.77 ms /    61 tokens (   64.93 ms per token,    15.40 tokens per second)\n",
      "llama_print_timings:        eval time =   15308.35 ms /    81 runs   (  188.99 ms per token,     5.29 tokens per second)\n",
      "llama_print_timings:       total time =   19450.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "350it [31:34, 19.26s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      32.37 ms /   144 runs   (    0.22 ms per token,  4448.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1912.61 ms /    30 tokens (   63.75 ms per token,    15.69 tokens per second)\n",
      "llama_print_timings:        eval time =   26275.88 ms /   143 runs   (  183.75 ms per token,     5.44 tokens per second)\n",
      "llama_print_timings:       total time =   28502.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "351it [31:46, 16.94s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.73 ms /    49 runs   (    0.24 ms per token,  4178.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2176.62 ms /    32 tokens (   68.02 ms per token,    14.70 tokens per second)\n",
      "llama_print_timings:        eval time =    9239.87 ms /    48 runs   (  192.50 ms per token,     5.19 tokens per second)\n",
      "llama_print_timings:       total time =   11523.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "352it [31:54, 14.44s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    36 runs   (    0.25 ms per token,  3988.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1934.63 ms /    30 tokens (   64.49 ms per token,    15.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6571.05 ms /    35 runs   (  187.74 ms per token,     5.33 tokens per second)\n",
      "llama_print_timings:       total time =    8586.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "353it [32:17, 16.99s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.41 ms /   116 runs   (    0.24 ms per token,  4083.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2630.31 ms /    42 tokens (   62.63 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =   20067.20 ms /   115 runs   (  174.50 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =   22951.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "354it [32:28, 15.25s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.54 ms /    56 runs   (    0.24 ms per token,  4134.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2389.20 ms /    36 tokens (   66.37 ms per token,    15.07 tokens per second)\n",
      "llama_print_timings:        eval time =    8669.98 ms /    55 runs   (  157.64 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   11172.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "355it [32:44, 15.45s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.15 ms /    77 runs   (    0.24 ms per token,  4241.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3750.16 ms /    61 tokens (   61.48 ms per token,    16.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12011.64 ms /    76 runs   (  158.05 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   15922.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "356it [32:54, 13.87s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.93 ms /    51 runs   (    0.23 ms per token,  4274.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1885.00 ms /    30 tokens (   62.83 ms per token,    15.92 tokens per second)\n",
      "llama_print_timings:        eval time =    8185.38 ms /    50 runs   (  163.71 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   10177.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "357it [33:05, 12.95s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.89 ms /    57 runs   (    0.24 ms per token,  4102.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2094.37 ms /    33 tokens (   63.47 ms per token,    15.76 tokens per second)\n",
      "llama_print_timings:        eval time =    8578.94 ms /    56 runs   (  153.20 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   10789.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "358it [33:28, 16.01s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      32.93 ms /   134 runs   (    0.25 ms per token,  4069.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1822.41 ms /    30 tokens (   60.75 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   21057.97 ms /   133 runs   (  158.33 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   23175.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "359it [33:46, 16.41s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.00 ms /    92 runs   (    0.24 ms per token,  4182.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2583.28 ms /    42 tokens (   61.51 ms per token,    16.26 tokens per second)\n",
      "llama_print_timings:        eval time =   14513.75 ms /    91 runs   (  159.49 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   17328.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "360it [33:59, 15.37s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.34 ms /    67 runs   (    0.24 ms per token,  4100.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2409.45 ms /    36 tokens (   66.93 ms per token,    14.94 tokens per second)\n",
      "llama_print_timings:        eval time =   10410.97 ms /    66 runs   (  157.74 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   12954.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "361it [34:11, 14.36s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.14 ms /    49 runs   (    0.23 ms per token,  4398.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4332.72 ms /    68 tokens (   63.72 ms per token,    15.69 tokens per second)\n",
      "llama_print_timings:        eval time =    7574.17 ms /    48 runs   (  157.80 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   12003.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "362it [34:27, 14.80s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      20.24 ms /    86 runs   (    0.24 ms per token,  4249.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2021.05 ms /    30 tokens (   67.37 ms per token,    14.84 tokens per second)\n",
      "llama_print_timings:        eval time =   13612.68 ms /    85 runs   (  160.15 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   15810.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "363it [34:34, 12.73s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    37 runs   (    0.23 ms per token,  4438.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2243.00 ms /    32 tokens (   70.09 ms per token,    14.27 tokens per second)\n",
      "llama_print_timings:        eval time =    5587.80 ms /    36 runs   (  155.22 ms per token,     6.44 tokens per second)\n",
      "llama_print_timings:       total time =    7902.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "364it [34:44, 11.67s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.96 ms /    47 runs   (    0.23 ms per token,  4287.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1880.90 ms /    30 tokens (   62.70 ms per token,    15.95 tokens per second)\n",
      "llama_print_timings:        eval time =    7231.66 ms /    46 runs   (  157.21 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =    9209.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.25 ms /   110 runs   (    0.24 ms per token,  4189.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2562.19 ms /    42 tokens (   61.00 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:        eval time =   17667.10 ms /   109 runs   (  162.08 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   20457.90 ms\n",
      "365it [35:04, 14.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "366it [35:22, 15.28s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.18 ms /    97 runs   (    0.23 ms per token,  4373.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2037.92 ms /    32 tokens (   63.69 ms per token,    15.70 tokens per second)\n",
      "llama_print_timings:        eval time =   15295.11 ms /    96 runs   (  159.32 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   17530.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "367it [35:48, 18.58s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      32.27 ms /   140 runs   (    0.23 ms per token,  4337.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3857.74 ms /    61 tokens (   63.24 ms per token,    15.81 tokens per second)\n",
      "llama_print_timings:        eval time =   22136.31 ms /   139 runs   (  159.25 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   26292.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "368it [36:07, 18.60s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.95 ms /   102 runs   (    0.23 ms per token,  4258.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1924.11 ms /    30 tokens (   64.14 ms per token,    15.59 tokens per second)\n",
      "llama_print_timings:        eval time =   16482.80 ms /   101 runs   (  163.20 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   18628.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "369it [36:19, 16.88s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.94 ms /    72 runs   (    0.24 ms per token,  4249.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2012.53 ms /    33 tokens (   60.99 ms per token,    16.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10720.66 ms /    71 runs   (  151.00 ms per token,     6.62 tokens per second)\n",
      "llama_print_timings:       total time =   12880.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "370it [36:41, 18.17s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.08 ms /   117 runs   (    0.24 ms per token,  4167.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2021.88 ms /    30 tokens (   67.40 ms per token,    14.84 tokens per second)\n",
      "llama_print_timings:        eval time =   18888.63 ms /   116 runs   (  162.83 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   21160.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "371it [36:53, 16.57s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.89 ms /    63 runs   (    0.24 ms per token,  4230.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2661.81 ms /    42 tokens (   63.38 ms per token,    15.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10034.59 ms /    62 runs   (  161.85 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   12829.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "372it [37:08, 15.87s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.98 ms /    71 runs   (    0.25 ms per token,  3948.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2078.12 ms /    32 tokens (   64.94 ms per token,    15.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12020.16 ms /    70 runs   (  171.72 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =   14257.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "373it [37:20, 14.79s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.92 ms /    52 runs   (    0.23 ms per token,  4363.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4038.80 ms /    61 tokens (   66.21 ms per token,    15.10 tokens per second)\n",
      "llama_print_timings:        eval time =    8114.67 ms /    51 runs   (  159.11 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   12258.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "374it [37:29, 13.04s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.28 ms /    45 runs   (    0.23 ms per token,  4379.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1929.70 ms /    30 tokens (   64.32 ms per token,    15.55 tokens per second)\n",
      "llama_print_timings:        eval time =    6932.39 ms /    44 runs   (  157.55 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =    8956.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "375it [37:47, 14.68s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.66 ms /   106 runs   (    0.24 ms per token,  4130.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1978.86 ms /    32 tokens (   61.84 ms per token,    16.17 tokens per second)\n",
      "llama_print_timings:        eval time =   16307.07 ms /   105 runs   (  155.31 ms per token,     6.44 tokens per second)\n",
      "llama_print_timings:       total time =   18511.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "376it [38:02, 14.51s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.11 ms /    81 runs   (    0.24 ms per token,  4239.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1850.66 ms /    30 tokens (   61.69 ms per token,    16.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12077.49 ms /    80 runs   (  150.97 ms per token,     6.62 tokens per second)\n",
      "llama_print_timings:       total time =   14095.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "377it [38:18, 15.10s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      20.63 ms /    88 runs   (    0.23 ms per token,  4265.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2615.15 ms /    42 tokens (   62.27 ms per token,    16.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13695.44 ms /    87 runs   (  157.42 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   16496.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "378it [38:39, 16.92s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.49 ms /   115 runs   (    0.24 ms per token,  4183.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2235.83 ms /    32 tokens (   69.87 ms per token,    14.31 tokens per second)\n",
      "llama_print_timings:        eval time =   18670.05 ms /   114 runs   (  163.77 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   21156.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "379it [38:52, 15.74s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.96 ms /    60 runs   (    0.23 ms per token,  4298.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3771.63 ms /    61 tokens (   61.83 ms per token,    16.17 tokens per second)\n",
      "llama_print_timings:        eval time =    9096.11 ms /    59 runs   (  154.17 ms per token,     6.49 tokens per second)\n",
      "llama_print_timings:       total time =   12992.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "380it [39:15, 17.80s/it]llama_print_timings:      sample time =      29.96 ms /   131 runs   (    0.23 ms per token,  4373.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1795.03 ms /    30 tokens (   59.83 ms per token,    16.71 tokens per second)\n",
      "llama_print_timings:        eval time =   20523.16 ms /   130 runs   (  157.87 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   22603.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "381it [39:22, 14.76s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    36 runs   (    0.23 ms per token,  4266.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2209.51 ms /    33 tokens (   66.95 ms per token,    14.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5387.87 ms /    35 runs   (  153.94 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:       total time =    7675.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "382it [39:36, 14.47s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.97 ms /    77 runs   (    0.23 ms per token,  4283.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1830.05 ms /    30 tokens (   61.00 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11785.81 ms /    76 runs   (  155.08 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:       total time =   13779.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "383it [39:53, 15.13s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.80 ms /    91 runs   (    0.24 ms per token,  4174.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2663.95 ms /    42 tokens (   63.43 ms per token,    15.77 tokens per second)\n",
      "llama_print_timings:        eval time =   13807.44 ms /    90 runs   (  153.42 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:       total time =   16663.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "384it [39:58, 12.25s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       5.49 ms /    24 runs   (    0.23 ms per token,  4371.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1966.18 ms /    32 tokens (   61.44 ms per token,    16.28 tokens per second)\n",
      "llama_print_timings:        eval time =    3517.20 ms /    23 runs   (  152.92 ms per token,     6.54 tokens per second)\n",
      "llama_print_timings:       total time =    5530.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "385it [40:10, 12.08s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    52 runs   (    0.23 ms per token,  4256.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3695.59 ms /    61 tokens (   60.58 ms per token,    16.51 tokens per second)\n",
      "llama_print_timings:        eval time =    7886.43 ms /    51 runs   (  154.64 ms per token,     6.47 tokens per second)\n",
      "llama_print_timings:       total time =   11689.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "386it [40:25, 12.93s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.51 ms /    82 runs   (    0.24 ms per token,  4202.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1871.85 ms /    30 tokens (   62.40 ms per token,    16.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12858.83 ms /    81 runs   (  158.75 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =   14907.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "387it [40:35, 12.11s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.35 ms /    52 runs   (    0.24 ms per token,  4211.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2025.51 ms /    32 tokens (   63.30 ms per token,    15.80 tokens per second)\n",
      "llama_print_timings:        eval time =    8075.43 ms /    51 runs   (  158.34 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   10210.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "388it [40:45, 11.33s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.21 ms /    49 runs   (    0.23 ms per token,  4371.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2195.25 ms /    30 tokens (   73.17 ms per token,    13.67 tokens per second)\n",
      "llama_print_timings:        eval time =    7216.28 ms /    48 runs   (  150.34 ms per token,     6.65 tokens per second)\n",
      "llama_print_timings:       total time =    9511.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "389it [41:00, 12.59s/it]llama_print_timings:      sample time =      20.02 ms /    82 runs   (    0.24 ms per token,  4095.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2535.63 ms /    42 tokens (   60.37 ms per token,    16.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12808.38 ms /    81 runs   (  158.13 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   15525.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "390it [41:12, 12.34s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.39 ms /    64 runs   (    0.24 ms per token,  4158.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2003.98 ms /    32 tokens (   62.62 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =    9594.22 ms /    63 runs   (  152.29 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =   11734.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "391it [41:26, 12.83s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.91 ms /    67 runs   (    0.24 ms per token,  4211.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3630.16 ms /    61 tokens (   59.51 ms per token,    16.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10216.84 ms /    66 runs   (  154.80 ms per token,     6.46 tokens per second)\n",
      "llama_print_timings:       total time =   13988.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "392it [41:52, 16.73s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      34.27 ms /   148 runs   (    0.23 ms per token,  4319.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2119.57 ms /    30 tokens (   70.65 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =   23379.42 ms /   147 runs   (  159.04 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   25821.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "393it [41:59, 13.95s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    35 runs   (    0.23 ms per token,  4305.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2150.77 ms /    33 tokens (   65.17 ms per token,    15.34 tokens per second)\n",
      "llama_print_timings:        eval time =    5230.30 ms /    34 runs   (  153.83 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:       total time =    7454.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "394it [42:13, 13.92s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.90 ms /    75 runs   (    0.24 ms per token,  4189.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1872.95 ms /    30 tokens (   62.43 ms per token,    16.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11832.80 ms /    74 runs   (  159.90 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   13867.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "395it [42:28, 14.17s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.05 ms /    74 runs   (    0.24 ms per token,  4099.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2628.86 ms /    42 tokens (   62.59 ms per token,    15.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11953.91 ms /    73 runs   (  163.75 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   14749.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "396it [42:44, 14.77s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      20.95 ms /    89 runs   (    0.24 ms per token,  4248.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2052.01 ms /    32 tokens (   64.13 ms per token,    15.59 tokens per second)\n",
      "llama_print_timings:        eval time =   13906.38 ms /    88 runs   (  158.03 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   16149.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "397it [42:59, 14.71s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.51 ms /    68 runs   (    0.23 ms per token,  4383.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3705.32 ms /    61 tokens (   60.74 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.24 ms /    67 runs   (  160.33 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   14587.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "398it [43:19, 16.54s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.87 ms /   118 runs   (    0.23 ms per token,  4390.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1900.24 ms /    30 tokens (   63.34 ms per token,    15.79 tokens per second)\n",
      "llama_print_timings:        eval time =   18628.73 ms /   117 runs   (  159.22 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   20787.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "399it [43:27, 13.94s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    37 runs   (    0.24 ms per token,  4236.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2057.14 ms /    32 tokens (   64.29 ms per token,    15.56 tokens per second)\n",
      "llama_print_timings:        eval time =    5752.23 ms /    36 runs   (  159.78 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =    7889.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "400it [43:47, 15.52s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.20 ms /   108 runs   (    0.24 ms per token,  4121.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1766.27 ms /    30 tokens (   58.88 ms per token,    16.98 tokens per second)\n",
      "llama_print_timings:        eval time =   17198.97 ms /   107 runs   (  160.74 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   19207.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "401it [44:03, 15.69s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.57 ms /    82 runs   (    0.24 ms per token,  4189.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2653.81 ms /    42 tokens (   63.19 ms per token,    15.83 tokens per second)\n",
      "llama_print_timings:        eval time =   13265.16 ms /    81 runs   (  163.77 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   16093.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "402it [44:13, 13.96s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.20 ms /    47 runs   (    0.24 ms per token,  4194.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2406.34 ms /    32 tokens (   75.20 ms per token,    13.30 tokens per second)\n",
      "llama_print_timings:        eval time =    7393.06 ms /    46 runs   (  160.72 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =    9900.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "403it [44:24, 13.31s/it]llama_print_timings:      sample time =      11.60 ms /    50 runs   (    0.23 ms per token,  4311.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3799.11 ms /    61 tokens (   62.28 ms per token,    16.06 tokens per second)\n",
      "llama_print_timings:        eval time =    7877.99 ms /    49 runs   (  160.78 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   11782.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "404it [44:43, 14.97s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.94 ms /    95 runs   (    0.23 ms per token,  4329.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1978.27 ms /    30 tokens (   65.94 ms per token,    15.16 tokens per second)\n",
      "llama_print_timings:        eval time =   16662.36 ms /    94 runs   (  177.26 ms per token,     5.64 tokens per second)\n",
      "llama_print_timings:       total time =   18848.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "405it [44:56, 14.19s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    56 runs   (    0.24 ms per token,  4206.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2126.03 ms /    33 tokens (   64.43 ms per token,    15.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10133.72 ms /    55 runs   (  184.25 ms per token,     5.43 tokens per second)\n",
      "llama_print_timings:       total time =   12381.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "406it [45:03, 12.15s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    30 runs   (    0.23 ms per token,  4372.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1890.70 ms /    30 tokens (   63.02 ms per token,    15.87 tokens per second)\n",
      "llama_print_timings:        eval time =    5432.82 ms /    29 runs   (  187.34 ms per token,     5.34 tokens per second)\n",
      "llama_print_timings:       total time =    7386.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "407it [45:15, 12.23s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    51 runs   (    0.24 ms per token,  4229.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3043.43 ms /    42 tokens (   72.46 ms per token,    13.80 tokens per second)\n",
      "llama_print_timings:        eval time =    9267.20 ms /    50 runs   (  185.34 ms per token,     5.40 tokens per second)\n",
      "llama_print_timings:       total time =   12419.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "408it [45:26, 11.61s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.24 ms /    44 runs   (    0.23 ms per token,  4298.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2054.79 ms /    32 tokens (   64.21 ms per token,    15.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8011.74 ms /    43 runs   (  186.32 ms per token,     5.37 tokens per second)\n",
      "llama_print_timings:       total time =   10159.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "409it [45:41, 12.63s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.33 ms /    60 runs   (    0.24 ms per token,  4187.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3877.63 ms /    61 tokens (   63.57 ms per token,    15.73 tokens per second)\n",
      "llama_print_timings:        eval time =   11006.25 ms /    59 runs   (  186.55 ms per token,     5.36 tokens per second)\n",
      "llama_print_timings:       total time =   15020.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "410it [45:53, 12.71s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.39 ms /    59 runs   (    0.23 ms per token,  4405.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1996.12 ms /    30 tokens (   66.54 ms per token,    15.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10776.61 ms /    58 runs   (  185.80 ms per token,     5.38 tokens per second)\n",
      "llama_print_timings:       total time =   12897.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "411it [46:18, 16.25s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.92 ms /   120 runs   (    0.24 ms per token,  4149.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2111.42 ms /    32 tokens (   65.98 ms per token,    15.16 tokens per second)\n",
      "llama_print_timings:        eval time =   22114.28 ms /   119 runs   (  185.83 ms per token,     5.38 tokens per second)\n",
      "llama_print_timings:       total time =   24491.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "412it [46:38, 17.40s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.13 ms /    98 runs   (    0.24 ms per token,  4237.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1957.52 ms /    30 tokens (   65.25 ms per token,    15.33 tokens per second)\n",
      "llama_print_timings:        eval time =   17915.02 ms /    97 runs   (  184.69 ms per token,     5.41 tokens per second)\n",
      "llama_print_timings:       total time =   20088.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "413it [47:03, 19.63s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      34.27 ms /   116 runs   (    0.30 ms per token,  3384.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2675.67 ms /    42 tokens (   63.71 ms per token,    15.70 tokens per second)\n",
      "llama_print_timings:        eval time =   21834.22 ms /   115 runs   (  189.86 ms per token,     5.27 tokens per second)\n",
      "llama_print_timings:       total time =   24818.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "414it [47:24, 20.09s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.74 ms /    99 runs   (    0.29 ms per token,  3444.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2461.65 ms /    32 tokens (   76.93 ms per token,    13.00 tokens per second)\n",
      "llama_print_timings:        eval time =   18455.62 ms /    98 runs   (  188.32 ms per token,     5.31 tokens per second)\n",
      "llama_print_timings:       total time =   21178.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "415it [47:51, 22.02s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      32.73 ms /   115 runs   (    0.28 ms per token,  3513.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4657.22 ms /    61 tokens (   76.35 ms per token,    13.10 tokens per second)\n",
      "llama_print_timings:        eval time =   21546.37 ms /   114 runs   (  189.00 ms per token,     5.29 tokens per second)\n",
      "llama_print_timings:       total time =   26506.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "416it [48:07, 20.37s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.19 ms /    75 runs   (    0.28 ms per token,  3539.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2325.95 ms /    30 tokens (   77.53 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:        eval time =   13996.19 ms /    74 runs   (  189.14 ms per token,     5.29 tokens per second)\n",
      "llama_print_timings:       total time =   16514.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "417it [48:26, 19.95s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.44 ms /    85 runs   (    0.29 ms per token,  3478.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2827.99 ms /    33 tokens (   85.70 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:        eval time =   15909.86 ms /    84 runs   (  189.40 ms per token,     5.28 tokens per second)\n",
      "llama_print_timings:       total time =   18957.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "418it [49:01, 24.33s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      49.63 ms /   169 runs   (    0.29 ms per token,  3404.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2320.75 ms /    30 tokens (   77.36 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:        eval time =   31796.40 ms /   168 runs   (  189.26 ms per token,     5.28 tokens per second)\n",
      "llama_print_timings:       total time =   34568.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "419it [49:23, 23.74s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.00 ms /    87 runs   (    0.30 ms per token,  3346.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3694.27 ms /    42 tokens (   87.96 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:        eval time =   18416.93 ms /    86 runs   (  214.15 ms per token,     4.67 tokens per second)\n",
      "llama_print_timings:       total time =   22357.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "420it [49:47, 23.90s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      30.61 ms /   100 runs   (    0.31 ms per token,  3267.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2564.40 ms /    32 tokens (   80.14 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:        eval time =   21416.14 ms /    99 runs   (  216.32 ms per token,     4.62 tokens per second)\n",
      "llama_print_timings:       total time =   24257.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "421it [50:06, 22.50s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.01 ms /    65 runs   (    0.29 ms per token,  3418.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5305.39 ms /    66 tokens (   80.38 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:        eval time =   13748.53 ms /    64 runs   (  214.82 ms per token,     4.66 tokens per second)\n",
      "llama_print_timings:       total time =   19232.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "422it [50:39, 25.43s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      40.80 ms /   138 runs   (    0.30 ms per token,  3382.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2405.80 ms /    30 tokens (   80.19 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:        eval time =   29466.17 ms /   137 runs   (  215.08 ms per token,     4.65 tokens per second)\n",
      "llama_print_timings:       total time =   32264.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "423it [50:49, 21.00s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.35 ms /    38 runs   (    0.30 ms per token,  3348.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2557.55 ms /    32 tokens (   79.92 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:        eval time =    7999.17 ms /    37 runs   (  216.19 ms per token,     4.63 tokens per second)\n",
      "llama_print_timings:       total time =   10657.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "424it [51:01, 18.06s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    40 runs   (    0.30 ms per token,  3380.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2449.43 ms /    30 tokens (   81.65 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:        eval time =    8643.15 ms /    39 runs   (  221.62 ms per token,     4.51 tokens per second)\n",
      "llama_print_timings:       total time =   11205.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "425it [51:14, 16.68s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.28 ms /    44 runs   (    0.30 ms per token,  3313.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3936.94 ms /    42 tokens (   93.74 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:        eval time =    9385.46 ms /    43 runs   (  218.27 ms per token,     4.58 tokens per second)\n",
      "llama_print_timings:       total time =   13442.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "426it [51:34, 17.62s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.81 ms /    76 runs   (    0.30 ms per token,  3331.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3173.26 ms /    36 tokens (   88.15 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:        eval time =   16431.84 ms /    75 runs   (  219.09 ms per token,     4.56 tokens per second)\n",
      "llama_print_timings:       total time =   19812.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "427it [52:06, 21.89s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      35.89 ms /   122 runs   (    0.29 ms per token,  3399.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5065.80 ms /    61 tokens (   83.05 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =   26455.49 ms /   121 runs   (  218.64 ms per token,     4.57 tokens per second)\n",
      "llama_print_timings:       total time =   31869.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "428it [52:31, 22.95s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      29.17 ms /    99 runs   (    0.29 ms per token,  3393.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2967.41 ms /    30 tokens (   98.91 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:        eval time =   22171.06 ms /    98 runs   (  226.24 ms per token,     4.42 tokens per second)\n",
      "llama_print_timings:       total time =   25421.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "429it [52:50, 21.83s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.19 ms /    73 runs   (    0.30 ms per token,  3289.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2756.57 ms /    33 tokens (   83.53 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:        eval time =   16239.77 ms /    72 runs   (  225.55 ms per token,     4.43 tokens per second)\n",
      "llama_print_timings:       total time =   19205.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "430it [53:23, 24.98s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      39.38 ms /   131 runs   (    0.30 ms per token,  3326.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2528.83 ms /    30 tokens (   84.29 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =   29437.02 ms /   130 runs   (  226.44 ms per token,     4.42 tokens per second)\n",
      "llama_print_timings:       total time =   32333.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "431it [53:42, 23.23s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.45 ms /    65 runs   (    0.30 ms per token,  3341.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4570.69 ms /    42 tokens (  108.83 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:        eval time =   14376.71 ms /    64 runs   (  224.64 ms per token,     4.45 tokens per second)\n",
      "llama_print_timings:       total time =   19130.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "432it [54:03, 22.71s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.51 ms /    78 runs   (    0.31 ms per token,  3182.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3713.65 ms /    36 tokens (  103.16 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:        eval time =   17549.46 ms /    77 runs   (  227.92 ms per token,     4.39 tokens per second)\n",
      "llama_print_timings:       total time =   21489.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "433it [54:37, 26.14s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      37.04 ms /   126 runs   (    0.29 ms per token,  3401.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4962.03 ms /    61 tokens (   81.34 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:        eval time =   28821.65 ms /   125 runs   (  230.57 ms per token,     4.34 tokens per second)\n",
      "llama_print_timings:       total time =   34151.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "434it [55:06, 26.93s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      33.13 ms /   115 runs   (    0.29 ms per token,  3470.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2472.26 ms /    30 tokens (   82.41 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:        eval time =   25970.87 ms /   114 runs   (  227.81 ms per token,     4.39 tokens per second)\n",
      "llama_print_timings:       total time =   28777.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "435it [55:17, 22.18s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.40 ms /    38 runs   (    0.30 ms per token,  3333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2661.01 ms /    32 tokens (   83.16 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =    8303.19 ms /    37 runs   (  224.41 ms per token,     4.46 tokens per second)\n",
      "llama_print_timings:       total time =   11074.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "436it [55:48, 24.62s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      35.21 ms /   122 runs   (    0.29 ms per token,  3464.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2473.10 ms /    30 tokens (   82.44 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:        eval time =   27497.07 ms /   121 runs   (  227.25 ms per token,     4.40 tokens per second)\n",
      "llama_print_timings:       total time =   30323.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "437it [56:19, 26.70s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      36.30 ms /   120 runs   (    0.30 ms per token,  3306.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4177.77 ms /    42 tokens (   99.47 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:        eval time =   27012.57 ms /   119 runs   (  227.00 ms per token,     4.41 tokens per second)\n",
      "llama_print_timings:       total time =   31540.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "438it [56:41, 25.22s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.16 ms /    83 runs   (    0.30 ms per token,  3298.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2988.00 ms /    36 tokens (   83.00 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:        eval time =   18555.84 ms /    82 runs   (  226.29 ms per token,     4.42 tokens per second)\n",
      "llama_print_timings:       total time =   21780.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "439it [57:24, 30.57s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      48.59 ms /   163 runs   (    0.30 ms per token,  3354.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5758.88 ms /    61 tokens (   94.41 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:        eval time =   36801.49 ms /   162 runs   (  227.17 ms per token,     4.40 tokens per second)\n",
      "llama_print_timings:       total time =   43035.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "440it [57:38, 25.60s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.43 ms /    49 runs   (    0.29 ms per token,  3395.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2871.93 ms /    30 tokens (   95.73 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10997.78 ms /    48 runs   (  229.12 ms per token,     4.36 tokens per second)\n",
      "llama_print_timings:       total time =   14009.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "441it [58:05, 25.87s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      31.33 ms /   103 runs   (    0.30 ms per token,  3287.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2944.33 ms /    33 tokens (   89.22 ms per token,    11.21 tokens per second)\n",
      "llama_print_timings:        eval time =   23263.01 ms /   102 runs   (  228.07 ms per token,     4.38 tokens per second)\n",
      "llama_print_timings:       total time =   26505.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "442it [58:22, 23.50s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      20.38 ms /    68 runs   (    0.30 ms per token,  3336.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2595.71 ms /    30 tokens (   86.52 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:        eval time =   15158.90 ms /    67 runs   (  226.25 ms per token,     4.42 tokens per second)\n",
      "llama_print_timings:       total time =   17944.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "443it [58:45, 23.25s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.31 ms /    85 runs   (    0.30 ms per token,  3358.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3577.88 ms /    42 tokens (   85.19 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:        eval time =   18861.12 ms /    84 runs   (  224.54 ms per token,     4.45 tokens per second)\n",
      "llama_print_timings:       total time =   22677.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "444it [59:05, 22.09s/it]llama_print_timings:      sample time =      22.41 ms /    73 runs   (    0.31 ms per token,  3257.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2992.23 ms /    36 tokens (   83.12 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:        eval time =   16183.89 ms /    72 runs   (  224.78 ms per token,     4.45 tokens per second)\n",
      "llama_print_timings:       total time =   19384.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "445it [59:24, 21.41s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.30 ms /    59 runs   (    0.29 ms per token,  3411.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6634.54 ms /    61 tokens (  108.76 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13029.48 ms /    58 runs   (  224.65 ms per token,     4.45 tokens per second)\n",
      "llama_print_timings:       total time =   19830.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "446it [59:59, 25.25s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      39.99 ms /   136 runs   (    0.29 ms per token,  3400.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3304.16 ms /    30 tokens (  110.14 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:        eval time =   30502.40 ms /   135 runs   (  225.94 ms per token,     4.43 tokens per second)\n",
      "llama_print_timings:       total time =   34201.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "447it [1:00:22, 24.63s/it]llama_print_timings:      sample time =      26.80 ms /    90 runs   (    0.30 ms per token,  3358.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2798.49 ms /    32 tokens (   87.45 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:        eval time =   20118.17 ms /    89 runs   (  226.05 ms per token,     4.42 tokens per second)\n",
      "llama_print_timings:       total time =   23173.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "448it [1:00:36, 21.48s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.94 ms /    52 runs   (    0.31 ms per token,  3261.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2492.65 ms /    30 tokens (   83.09 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11498.40 ms /    51 runs   (  225.46 ms per token,     4.44 tokens per second)\n",
      "llama_print_timings:       total time =   14137.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "449it [1:00:53, 20.31s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.01 ms /    63 runs   (    0.30 ms per token,  3314.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3463.88 ms /    42 tokens (   82.47 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13916.00 ms /    62 runs   (  224.45 ms per token,     4.46 tokens per second)\n",
      "llama_print_timings:       total time =   17558.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "450it [1:01:10, 19.31s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.65 ms /    58 runs   (    0.30 ms per token,  3285.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3952.41 ms /    36 tokens (  109.79 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12857.58 ms /    57 runs   (  225.57 ms per token,     4.43 tokens per second)\n",
      "llama_print_timings:       total time =   16972.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "451it [1:01:46, 24.26s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      37.68 ms /   128 runs   (    0.29 ms per token,  3396.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6708.57 ms /    61 tokens (  109.98 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:        eval time =   28753.06 ms /   127 runs   (  226.40 ms per token,     4.42 tokens per second)\n",
      "llama_print_timings:       total time =   35831.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "452it [1:02:14, 25.42s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      31.87 ms /   110 runs   (    0.29 ms per token,  3452.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2918.20 ms /    30 tokens (   97.27 ms per token,    10.28 tokens per second)\n",
      "llama_print_timings:        eval time =   24897.24 ms /   109 runs   (  228.42 ms per token,     4.38 tokens per second)\n",
      "llama_print_timings:       total time =   28124.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "453it [1:02:29, 22.31s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.20 ms /    53 runs   (    0.31 ms per token,  3272.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3172.88 ms /    33 tokens (   96.15 ms per token,    10.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11717.51 ms /    52 runs   (  225.34 ms per token,     4.44 tokens per second)\n",
      "llama_print_timings:       total time =   15042.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "454it [1:02:45, 20.23s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.62 ms /    55 runs   (    0.30 ms per token,  3308.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2977.34 ms /    30 tokens (   99.24 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12225.99 ms /    54 runs   (  226.41 ms per token,     4.42 tokens per second)\n",
      "llama_print_timings:       total time =   15360.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "455it [1:04:31, 46.00s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =     137.82 ms /   446 runs   (    0.31 ms per token,  3236.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3437.17 ms /    42 tokens (   81.84 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:        eval time =  101254.67 ms /   445 runs   (  227.54 ms per token,     4.39 tokens per second)\n",
      "llama_print_timings:       total time =  106127.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "456it [1:04:57, 40.11s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      32.02 ms /   103 runs   (    0.31 ms per token,  3217.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2990.78 ms /    36 tokens (   83.08 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =   23083.88 ms /   102 runs   (  226.31 ms per token,     4.42 tokens per second)\n",
      "llama_print_timings:       total time =   26382.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "457it [1:05:17, 34.03s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.69 ms /    66 runs   (    0.30 ms per token,  3352.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5013.16 ms /    61 tokens (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:        eval time =   14638.53 ms /    65 runs   (  225.21 ms per token,     4.44 tokens per second)\n",
      "llama_print_timings:       total time =   19845.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "458it [1:05:52, 34.28s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      40.49 ms /   139 runs   (    0.29 ms per token,  3432.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3285.54 ms /    30 tokens (  109.52 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:        eval time =   31146.59 ms /   138 runs   (  225.70 ms per token,     4.43 tokens per second)\n",
      "llama_print_timings:       total time =   34841.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "459it [1:06:08, 28.91s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.52 ms /    58 runs   (    0.30 ms per token,  3311.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3325.44 ms /    32 tokens (  103.92 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12907.28 ms /    57 runs   (  226.44 ms per token,     4.42 tokens per second)\n",
      "llama_print_timings:       total time =   16394.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "460it [1:06:35, 28.18s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      31.75 ms /   106 runs   (    0.30 ms per token,  3338.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2495.43 ms /    30 tokens (   83.18 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =   23653.23 ms /   105 runs   (  225.27 ms per token,     4.44 tokens per second)\n",
      "llama_print_timings:       total time =   26452.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "461it [1:06:58, 26.76s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.78 ms /    89 runs   (    0.30 ms per token,  3323.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3400.30 ms /    42 tokens (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:        eval time =   19811.24 ms /    88 runs   (  225.13 ms per token,     4.44 tokens per second)\n",
      "llama_print_timings:       total time =   23464.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "462it [1:07:23, 26.05s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      29.35 ms /    94 runs   (    0.31 ms per token,  3202.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3258.04 ms /    36 tokens (   90.50 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:        eval time =   20867.57 ms /    93 runs   (  224.38 ms per token,     4.46 tokens per second)\n",
      "llama_print_timings:       total time =   24397.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "463it [1:07:28, 19.95s/it]llama_print_timings:      sample time =       0.60 ms /     2 runs   (    0.30 ms per token,  3316.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5454.53 ms /    61 tokens (   89.42 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:        eval time =     229.96 ms /     1 runs   (  229.96 ms per token,     4.35 tokens per second)\n",
      "llama_print_timings:       total time =    5691.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "464it [1:08:02, 24.14s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      42.83 ms /   147 runs   (    0.29 ms per token,  3432.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3370.72 ms /    30 tokens (  112.36 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:        eval time =   30124.38 ms /   146 runs   (  206.33 ms per token,     4.85 tokens per second)\n",
      "llama_print_timings:       total time =   33928.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "465it [1:08:14, 20.39s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.43 ms /    51 runs   (    0.28 ms per token,  3535.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2600.36 ms /    33 tokens (   78.80 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:        eval time =    8886.36 ms /    50 runs   (  177.73 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   11619.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "466it [1:08:28, 18.40s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    65 runs   (    0.23 ms per token,  4333.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2361.79 ms /    30 tokens (   78.73 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11247.31 ms /    64 runs   (  175.74 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   13752.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "467it [1:08:31, 13.80s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     2 runs   (    0.25 ms per token,  3992.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2908.93 ms /    42 tokens (   69.26 ms per token,    14.44 tokens per second)\n",
      "llama_print_timings:        eval time =     174.12 ms /     1 runs   (  174.12 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =    3087.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "468it [1:08:45, 13.93s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.10 ms /    67 runs   (    0.24 ms per token,  4160.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2537.87 ms /    36 tokens (   70.50 ms per token,    14.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11532.72 ms /    66 runs   (  174.74 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   14219.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "469it [1:08:59, 14.00s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.86 ms /    60 runs   (    0.23 ms per token,  4329.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3791.95 ms /    61 tokens (   62.16 ms per token,    16.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10252.51 ms /    59 runs   (  173.77 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   14174.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "470it [1:09:10, 12.98s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.41 ms /    50 runs   (    0.23 ms per token,  4380.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1974.30 ms /    30 tokens (   65.81 ms per token,    15.20 tokens per second)\n",
      "llama_print_timings:        eval time =    8493.16 ms /    49 runs   (  173.33 ms per token,     5.77 tokens per second)\n",
      "llama_print_timings:       total time =   10575.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "471it [1:09:18, 11.60s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    37 runs   (    0.24 ms per token,  4157.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2092.55 ms /    32 tokens (   65.39 ms per token,    15.29 tokens per second)\n",
      "llama_print_timings:        eval time =    6226.78 ms /    36 runs   (  172.97 ms per token,     5.78 tokens per second)\n",
      "llama_print_timings:       total time =    8402.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "472it [1:09:44, 15.87s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      31.37 ms /   136 runs   (    0.23 ms per token,  4335.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1985.33 ms /    30 tokens (   66.18 ms per token,    15.11 tokens per second)\n",
      "llama_print_timings:        eval time =   23509.13 ms /   135 runs   (  174.14 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   25809.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "473it [1:09:54, 14.25s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.45 ms /    44 runs   (    0.24 ms per token,  4210.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2748.56 ms /    42 tokens (   65.44 ms per token,    15.28 tokens per second)\n",
      "llama_print_timings:        eval time =    7633.68 ms /    43 runs   (  177.53 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   10479.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "474it [1:10:18, 17.04s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.75 ms /   120 runs   (    0.24 ms per token,  4173.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2392.88 ms /    36 tokens (   66.47 ms per token,    15.04 tokens per second)\n",
      "llama_print_timings:        eval time =   20897.55 ms /   119 runs   (  175.61 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   23561.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "475it [1:10:32, 16.22s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    59 runs   (    0.24 ms per token,  4195.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3987.94 ms /    61 tokens (   65.38 ms per token,    15.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10184.40 ms /    58 runs   (  175.59 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   14306.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.33 ms /    63 runs   (    0.23 ms per token,  4395.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2082.89 ms /    30 tokens (   69.43 ms per token,    14.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10865.74 ms /    62 runs   (  175.25 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   13086.90 ms\n",
      "476it [1:10:45, 15.28s/it]Llama.generate: prefix-match hit\n",
      "477it [1:10:58, 14.58s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.16 ms /    60 runs   (    0.24 ms per token,  4236.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2502.00 ms /    33 tokens (   75.82 ms per token,    13.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10306.51 ms /    59 runs   (  174.69 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   12940.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "478it [1:11:10, 13.57s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.72 ms /    53 runs   (    0.24 ms per token,  4166.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1910.03 ms /    30 tokens (   63.67 ms per token,    15.71 tokens per second)\n",
      "llama_print_timings:        eval time =    9185.29 ms /    52 runs   (  176.64 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =   11212.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "479it [1:11:29, 15.26s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.80 ms /    93 runs   (    0.23 ms per token,  4265.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2861.66 ms /    42 tokens (   68.13 ms per token,    14.68 tokens per second)\n",
      "llama_print_timings:        eval time =   16114.63 ms /    92 runs   (  175.16 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   19184.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "480it [1:11:52, 17.71s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.96 ms /   120 runs   (    0.23 ms per token,  4292.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2344.25 ms /    36 tokens (   65.12 ms per token,    15.36 tokens per second)\n",
      "llama_print_timings:        eval time =   20835.28 ms /   119 runs   (  175.09 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   23448.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "481it [1:12:07, 16.73s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.04 ms /    57 runs   (    0.23 ms per token,  4369.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4485.74 ms /    66 tokens (   67.97 ms per token,    14.71 tokens per second)\n",
      "llama_print_timings:        eval time =    9806.09 ms /    56 runs   (  175.11 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   14417.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "482it [1:12:23, 16.50s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.30 ms /    73 runs   (    0.24 ms per token,  4220.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1927.50 ms /    30 tokens (   64.25 ms per token,    15.56 tokens per second)\n",
      "llama_print_timings:        eval time =   13875.53 ms /    72 runs   (  192.72 ms per token,     5.19 tokens per second)\n",
      "llama_print_timings:       total time =   15975.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "483it [1:12:37, 15.77s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.16 ms /    68 runs   (    0.24 ms per token,  4208.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2059.37 ms /    32 tokens (   64.36 ms per token,    15.54 tokens per second)\n",
      "llama_print_timings:        eval time =   11843.49 ms /    67 runs   (  176.77 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =   14054.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "484it [1:12:49, 14.62s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    57 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1972.75 ms /    30 tokens (   65.76 ms per token,    15.21 tokens per second)\n",
      "llama_print_timings:        eval time =    9852.33 ms /    56 runs   (  175.93 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   11954.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "485it [1:13:23, 20.45s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      42.46 ms /   175 runs   (    0.24 ms per token,  4121.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2913.07 ms /    42 tokens (   69.36 ms per token,    14.42 tokens per second)\n",
      "llama_print_timings:        eval time =   30716.20 ms /   174 runs   (  176.53 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =   34039.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "486it [1:13:32, 17.07s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.43 ms /    40 runs   (    0.24 ms per token,  4241.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2301.63 ms /    36 tokens (   63.93 ms per token,    15.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6796.81 ms /    39 runs   (  174.28 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =    9187.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "487it [1:13:49, 17.04s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.67 ms /    75 runs   (    0.24 ms per token,  4243.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3849.31 ms /    61 tokens (   63.10 ms per token,    15.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12934.61 ms /    74 runs   (  174.79 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   16961.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.15 ms /   108 runs   (    0.22 ms per token,  4471.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1963.50 ms /    30 tokens (   65.45 ms per token,    15.28 tokens per second)\n",
      "llama_print_timings:        eval time =   18815.33 ms /   107 runs   (  175.84 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   21020.44 ms\n",
      "488it [1:14:10, 18.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.74 ms /    71 runs   (    0.24 ms per token,  4240.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2263.56 ms /    33 tokens (   68.59 ms per token,    14.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12227.41 ms /    70 runs   (  174.68 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   14651.46 ms\n",
      "489it [1:14:25, 17.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "490it [1:14:47, 18.69s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.83 ms /   113 runs   (    0.24 ms per token,  4211.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2268.42 ms /    30 tokens (   75.61 ms per token,    13.23 tokens per second)\n",
      "llama_print_timings:        eval time =   19733.67 ms /   112 runs   (  176.19 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   22264.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "491it [1:15:03, 17.89s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.85 ms /    76 runs   (    0.23 ms per token,  4256.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2765.37 ms /    42 tokens (   65.84 ms per token,    15.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13072.41 ms /    75 runs   (  174.30 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   16004.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "492it [1:15:24, 18.75s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.30 ms /   105 runs   (    0.24 ms per token,  4150.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2312.03 ms /    36 tokens (   64.22 ms per token,    15.57 tokens per second)\n",
      "llama_print_timings:        eval time =   18206.34 ms /   104 runs   (  175.06 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   20760.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "493it [1:15:38, 17.58s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.36 ms /    62 runs   (    0.23 ms per token,  4318.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3929.20 ms /    61 tokens (   64.41 ms per token,    15.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10768.64 ms /    61 runs   (  176.54 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =   14838.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "494it [1:15:50, 15.73s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    53 runs   (    0.23 ms per token,  4264.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2175.48 ms /    30 tokens (   72.52 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =    9129.10 ms /    52 runs   (  175.56 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   11421.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "495it [1:16:07, 16.11s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.92 ms /    84 runs   (    0.24 ms per token,  4216.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2201.36 ms /    32 tokens (   68.79 ms per token,    14.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14591.60 ms /    83 runs   (  175.80 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   16981.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "496it [1:16:17, 14.34s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    48 runs   (    0.23 ms per token,  4266.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1900.85 ms /    30 tokens (   63.36 ms per token,    15.78 tokens per second)\n",
      "llama_print_timings:        eval time =    8207.99 ms /    47 runs   (  174.64 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =   10214.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "497it [1:16:40, 17.01s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.53 ms /   116 runs   (    0.24 ms per token,  4213.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2744.38 ms /    42 tokens (   65.34 ms per token,    15.30 tokens per second)\n",
      "llama_print_timings:        eval time =   20227.15 ms /   115 runs   (  175.89 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   23236.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "498it [1:16:54, 16.10s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.83 ms /    67 runs   (    0.24 ms per token,  4231.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2342.76 ms /    36 tokens (   65.08 ms per token,    15.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11503.07 ms /    66 runs   (  174.29 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   13992.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "499it [1:17:09, 15.58s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.33 ms /    60 runs   (    0.24 ms per token,  4186.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3849.14 ms /    61 tokens (   63.10 ms per token,    15.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10353.07 ms /    59 runs   (  175.48 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   14338.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "500it [1:17:19, 14.07s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.57 ms /    50 runs   (    0.23 ms per token,  4323.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1923.96 ms /    30 tokens (   64.13 ms per token,    15.59 tokens per second)\n",
      "llama_print_timings:        eval time =    8524.40 ms /    49 runs   (  173.97 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   10560.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "501it [1:17:36, 14.86s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      20.46 ms /    83 runs   (    0.25 ms per token,  4057.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2118.17 ms /    33 tokens (   64.19 ms per token,    15.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14395.72 ms /    82 runs   (  175.56 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   16701.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "502it [1:17:53, 15.41s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.62 ms /    83 runs   (    0.24 ms per token,  4230.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2171.14 ms /    30 tokens (   72.37 ms per token,    13.82 tokens per second)\n",
      "llama_print_timings:        eval time =   14326.42 ms /    82 runs   (  174.71 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   16681.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "503it [1:18:07, 15.01s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.03 ms /    65 runs   (    0.25 ms per token,  4055.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2741.40 ms /    42 tokens (   65.27 ms per token,    15.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11175.99 ms /    64 runs   (  174.62 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =   14070.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "504it [1:18:25, 15.88s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      20.98 ms /    89 runs   (    0.24 ms per token,  4242.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2303.56 ms /    36 tokens (   63.99 ms per token,    15.63 tokens per second)\n",
      "llama_print_timings:        eval time =   15429.13 ms /    88 runs   (  175.33 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   17930.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "505it [1:18:37, 14.99s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    52 runs   (    0.23 ms per token,  4283.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3857.01 ms /    61 tokens (   63.23 ms per token,    15.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8935.02 ms /    51 runs   (  175.20 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   12910.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "506it [1:18:59, 17.05s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.12 ms /   112 runs   (    0.22 ms per token,  4459.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2136.66 ms /    30 tokens (   71.22 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   19455.76 ms /   111 runs   (  175.28 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   21846.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "507it [1:19:07, 14.27s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    32 runs   (    0.24 ms per token,  4217.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2266.87 ms /    32 tokens (   70.84 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =    5459.33 ms /    31 runs   (  176.11 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =    7798.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "508it [1:19:18, 13.39s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.99 ms /    52 runs   (    0.23 ms per token,  4336.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2321.07 ms /    30 tokens (   77.37 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:        eval time =    8885.16 ms /    51 runs   (  174.22 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   11323.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "509it [1:19:47, 17.91s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      35.03 ms /   146 runs   (    0.24 ms per token,  4168.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2709.71 ms /    42 tokens (   64.52 ms per token,    15.50 tokens per second)\n",
      "llama_print_timings:        eval time =   25406.02 ms /   145 runs   (  175.21 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   28454.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "510it [1:20:12, 20.04s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      29.54 ms /   122 runs   (    0.24 ms per token,  4130.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2313.23 ms /    36 tokens (   64.26 ms per token,    15.56 tokens per second)\n",
      "llama_print_timings:        eval time =   22392.85 ms /   121 runs   (  185.06 ms per token,     5.40 tokens per second)\n",
      "llama_print_timings:       total time =   24997.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "511it [1:20:25, 18.09s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    54 runs   (    0.23 ms per token,  4412.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3895.80 ms /    61 tokens (   63.87 ms per token,    15.66 tokens per second)\n",
      "llama_print_timings:        eval time =    9522.18 ms /    53 runs   (  179.66 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =   13537.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "512it [1:20:36, 15.87s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.23 ms /    48 runs   (    0.23 ms per token,  4273.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2244.49 ms /    30 tokens (   74.82 ms per token,    13.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8328.81 ms /    47 runs   (  177.21 ms per token,     5.64 tokens per second)\n",
      "llama_print_timings:       total time =   10682.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "513it [1:20:46, 13.93s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.76 ms /    42 runs   (    0.23 ms per token,  4304.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2228.27 ms /    33 tokens (   67.52 ms per token,    14.81 tokens per second)\n",
      "llama_print_timings:        eval time =    7103.91 ms /    41 runs   (  173.27 ms per token,     5.77 tokens per second)\n",
      "llama_print_timings:       total time =    9424.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "514it [1:21:04, 15.43s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.78 ms /    97 runs   (    0.23 ms per token,  4257.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1902.66 ms /    30 tokens (   63.42 ms per token,    15.77 tokens per second)\n",
      "llama_print_timings:        eval time =   16807.58 ms /    96 runs   (  175.08 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   18934.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "515it [1:21:25, 17.09s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.63 ms /   101 runs   (    0.23 ms per token,  4274.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2622.48 ms /    42 tokens (   62.44 ms per token,    16.02 tokens per second)\n",
      "llama_print_timings:        eval time =   18103.54 ms /   100 runs   (  181.04 ms per token,     5.52 tokens per second)\n",
      "llama_print_timings:       total time =   20960.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "516it [1:21:41, 16.55s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.89 ms /    60 runs   (    0.25 ms per token,  4028.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2550.84 ms /    36 tokens (   70.86 ms per token,    14.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12575.37 ms /    59 runs   (  213.14 ms per token,     4.69 tokens per second)\n",
      "llama_print_timings:       total time =   15280.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "517it [1:21:56, 16.26s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.16 ms /    61 runs   (    0.23 ms per token,  4307.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4786.67 ms /    61 tokens (   78.47 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10659.77 ms /    60 runs   (  177.66 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   15582.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "518it [1:22:10, 15.42s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.93 ms /    65 runs   (    0.23 ms per token,  4353.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2116.72 ms /    30 tokens (   70.56 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =   11183.54 ms /    64 runs   (  174.74 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   13448.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "519it [1:22:20, 13.80s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.04 ms /    46 runs   (    0.24 ms per token,  4167.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2043.38 ms /    32 tokens (   63.86 ms per token,    15.66 tokens per second)\n",
      "llama_print_timings:        eval time =    7892.99 ms /    45 runs   (  175.40 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   10038.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "520it [1:22:30, 12.62s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    46 runs   (    0.24 ms per token,  4244.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1902.40 ms /    30 tokens (   63.41 ms per token,    15.77 tokens per second)\n",
      "llama_print_timings:        eval time =    7848.61 ms /    45 runs   (  174.41 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =    9853.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "521it [1:22:46, 13.70s/it]llama_print_timings:      sample time =      18.06 ms /    78 runs   (    0.23 ms per token,  4318.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2641.47 ms /    42 tokens (   62.89 ms per token,    15.90 tokens per second)\n",
      "llama_print_timings:        eval time =   13392.98 ms /    77 runs   (  173.93 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   16208.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "522it [1:22:54, 12.10s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    35 runs   (    0.23 ms per token,  4355.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2313.29 ms /    36 tokens (   64.26 ms per token,    15.56 tokens per second)\n",
      "llama_print_timings:        eval time =    5967.97 ms /    34 runs   (  175.53 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =    8356.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "523it [1:23:22, 16.68s/it]llama_print_timings:      sample time =      30.19 ms /   128 runs   (    0.24 ms per token,  4240.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4744.37 ms /    61 tokens (   77.78 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:        eval time =   22319.45 ms /   127 runs   (  175.74 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   27365.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "524it [1:23:45, 18.59s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.51 ms /   119 runs   (    0.22 ms per token,  4488.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1980.98 ms /    30 tokens (   66.03 ms per token,    15.14 tokens per second)\n",
      "llama_print_timings:        eval time =   20808.83 ms /   118 runs   (  176.35 ms per token,     5.67 tokens per second)\n",
      "llama_print_timings:       total time =   23061.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "525it [1:24:04, 18.68s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.66 ms /    96 runs   (    0.24 ms per token,  4235.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2107.83 ms /    33 tokens (   63.87 ms per token,    15.66 tokens per second)\n",
      "llama_print_timings:        eval time =   16558.92 ms /    95 runs   (  174.30 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   18882.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "526it [1:24:31, 21.31s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      35.00 ms /   144 runs   (    0.24 ms per token,  4114.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1914.10 ms /    30 tokens (   63.80 ms per token,    15.67 tokens per second)\n",
      "llama_print_timings:        eval time =   25178.23 ms /   143 runs   (  176.07 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   27433.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "527it [1:24:42, 18.09s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.88 ms /    46 runs   (    0.24 ms per token,  4226.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2630.19 ms /    42 tokens (   62.62 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =    7833.30 ms /    45 runs   (  174.07 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   10566.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "528it [1:24:54, 16.54s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.36 ms /    52 runs   (    0.24 ms per token,  4206.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2621.74 ms /    36 tokens (   72.83 ms per token,    13.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10191.29 ms /    51 runs   (  199.83 ms per token,     5.00 tokens per second)\n",
      "llama_print_timings:       total time =   12936.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "529it [1:25:18, 18.54s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.50 ms /   108 runs   (    0.23 ms per token,  4407.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4266.38 ms /    61 tokens (   69.94 ms per token,    14.30 tokens per second)\n",
      "llama_print_timings:        eval time =   18695.00 ms /   107 runs   (  174.72 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   23211.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "530it [1:25:37, 18.73s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.54 ms /    93 runs   (    0.23 ms per token,  4318.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2343.29 ms /    30 tokens (   78.11 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:        eval time =   16610.45 ms /    92 runs   (  180.55 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =   19165.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "531it [1:25:59, 19.64s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.33 ms /   111 runs   (    0.24 ms per token,  4215.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2278.96 ms /    32 tokens (   71.22 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   19225.78 ms /   110 runs   (  174.78 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   21762.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "532it [1:26:09, 16.89s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.26 ms /    49 runs   (    0.23 ms per token,  4351.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1977.62 ms /    30 tokens (   65.92 ms per token,    15.17 tokens per second)\n",
      "llama_print_timings:        eval time =    8390.92 ms /    48 runs   (  174.81 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   10477.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "533it [1:26:25, 16.60s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.15 ms /    75 runs   (    0.24 ms per token,  4132.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2736.45 ms /    42 tokens (   65.15 ms per token,    15.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12998.58 ms /    74 runs   (  175.66 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   15909.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "534it [1:26:47, 18.10s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.04 ms /   110 runs   (    0.25 ms per token,  4068.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2340.61 ms /    36 tokens (   65.02 ms per token,    15.38 tokens per second)\n",
      "llama_print_timings:        eval time =   18996.61 ms /   109 runs   (  174.28 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   21599.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "535it [1:27:12, 20.24s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.78 ms /   111 runs   (    0.23 ms per token,  4306.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3810.73 ms /    61 tokens (   62.47 ms per token,    16.01 tokens per second)\n",
      "llama_print_timings:        eval time =   21157.25 ms /   110 runs   (  192.34 ms per token,     5.20 tokens per second)\n",
      "llama_print_timings:       total time =   25234.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "536it [1:27:25, 18.20s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.28 ms /    58 runs   (    0.23 ms per token,  4367.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2935.09 ms /    30 tokens (   97.84 ms per token,    10.22 tokens per second)\n",
      "llama_print_timings:        eval time =   10367.61 ms /    57 runs   (  181.89 ms per token,     5.50 tokens per second)\n",
      "llama_print_timings:       total time =   13431.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "537it [1:27:34, 15.45s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    39 runs   (    0.25 ms per token,  4007.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2370.59 ms /    33 tokens (   71.84 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =    6583.88 ms /    38 runs   (  173.26 ms per token,     5.77 tokens per second)\n",
      "llama_print_timings:       total time =    9048.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "538it [1:27:55, 16.95s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.18 ms /   105 runs   (    0.23 ms per token,  4342.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1958.50 ms /    30 tokens (   65.28 ms per token,    15.32 tokens per second)\n",
      "llama_print_timings:        eval time =   18229.50 ms /   104 runs   (  175.28 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   20430.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "539it [1:28:10, 16.32s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.27 ms /    68 runs   (    0.24 ms per token,  4178.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2796.42 ms /    42 tokens (   66.58 ms per token,    15.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11897.84 ms /    67 runs   (  177.58 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   14856.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "540it [1:28:20, 14.42s/it]llama_print_timings:      sample time =      10.27 ms /    43 runs   (    0.24 ms per token,  4188.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2330.67 ms /    36 tokens (   64.74 ms per token,    15.45 tokens per second)\n",
      "llama_print_timings:        eval time =    7543.44 ms /    42 runs   (  179.61 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =    9972.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "541it [1:28:47, 18.23s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.36 ms /    98 runs   (    0.24 ms per token,  4195.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6611.30 ms /    68 tokens (   97.22 ms per token,    10.29 tokens per second)\n",
      "llama_print_timings:        eval time =   20255.31 ms /    97 runs   (  208.82 ms per token,     4.79 tokens per second)\n",
      "llama_print_timings:       total time =   27121.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "542it [1:29:05, 18.17s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.76 ms /    81 runs   (    0.23 ms per token,  4318.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2546.15 ms /    30 tokens (   84.87 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:        eval time =   15305.47 ms /    80 runs   (  191.32 ms per token,     5.23 tokens per second)\n",
      "llama_print_timings:       total time =   18038.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "543it [1:29:15, 15.89s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    49 runs   (    0.24 ms per token,  4143.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2023.88 ms /    32 tokens (   63.25 ms per token,    15.81 tokens per second)\n",
      "llama_print_timings:        eval time =    8421.49 ms /    48 runs   (  175.45 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   10555.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "544it [1:29:23, 13.39s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    32 runs   (    0.23 ms per token,  4391.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1929.89 ms /    30 tokens (   64.33 ms per token,    15.54 tokens per second)\n",
      "llama_print_timings:        eval time =    5545.37 ms /    31 runs   (  178.88 ms per token,     5.59 tokens per second)\n",
      "llama_print_timings:       total time =    7545.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "545it [1:29:42, 15.25s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.19 ms /    93 runs   (    0.24 ms per token,  4191.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2593.88 ms /    42 tokens (   61.76 ms per token,    16.19 tokens per second)\n",
      "llama_print_timings:        eval time =   16789.05 ms /    92 runs   (  182.49 ms per token,     5.48 tokens per second)\n",
      "llama_print_timings:       total time =   19600.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "546it [1:30:10, 19.02s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      33.59 ms /   142 runs   (    0.24 ms per token,  4227.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2040.86 ms /    32 tokens (   63.78 ms per token,    15.68 tokens per second)\n",
      "llama_print_timings:        eval time =   25449.48 ms /   141 runs   (  180.49 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =   27823.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "547it [1:30:31, 19.57s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.09 ms /    93 runs   (    0.23 ms per token,  4410.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3890.00 ms /    61 tokens (   63.77 ms per token,    15.68 tokens per second)\n",
      "llama_print_timings:        eval time =   16729.45 ms /    92 runs   (  181.84 ms per token,     5.50 tokens per second)\n",
      "llama_print_timings:       total time =   20834.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "548it [1:30:58, 21.87s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      29.45 ms /   125 runs   (    0.24 ms per token,  4244.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2059.76 ms /    30 tokens (   68.66 ms per token,    14.56 tokens per second)\n",
      "llama_print_timings:        eval time =   24878.34 ms /   124 runs   (  200.63 ms per token,     4.98 tokens per second)\n",
      "llama_print_timings:       total time =   27254.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "549it [1:31:13, 19.84s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.32 ms /    68 runs   (    0.24 ms per token,  4166.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2303.64 ms /    33 tokens (   69.81 ms per token,    14.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12616.65 ms /    67 runs   (  188.31 ms per token,     5.31 tokens per second)\n",
      "llama_print_timings:       total time =   15076.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "550it [1:31:25, 17.40s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    54 runs   (    0.23 ms per token,  4290.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1891.77 ms /    30 tokens (   63.06 ms per token,    15.86 tokens per second)\n",
      "llama_print_timings:        eval time =    9712.12 ms /    53 runs   (  183.25 ms per token,     5.46 tokens per second)\n",
      "llama_print_timings:       total time =   11725.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "551it [1:31:36, 15.31s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.36 ms /    44 runs   (    0.24 ms per token,  4249.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2836.85 ms /    42 tokens (   67.54 ms per token,    14.81 tokens per second)\n",
      "llama_print_timings:        eval time =    7470.26 ms /    43 runs   (  173.73 ms per token,     5.76 tokens per second)\n",
      "llama_print_timings:       total time =   10408.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "552it [1:31:48, 14.49s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.41 ms /    60 runs   (    0.24 ms per token,  4162.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2175.60 ms /    32 tokens (   67.99 ms per token,    14.71 tokens per second)\n",
      "llama_print_timings:        eval time =   10253.70 ms /    59 runs   (  173.79 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   12569.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "553it [1:32:02, 14.43s/it]llama_print_timings:      sample time =      13.89 ms /    60 runs   (    0.23 ms per token,  4320.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3841.78 ms /    61 tokens (   62.98 ms per token,    15.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10333.43 ms /    59 runs   (  175.14 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   14314.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "554it [1:32:26, 17.13s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.34 ms /   122 runs   (    0.23 ms per token,  4305.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1948.09 ms /    30 tokens (   64.94 ms per token,    15.40 tokens per second)\n",
      "llama_print_timings:        eval time =   21187.02 ms /   121 runs   (  175.10 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   23422.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "555it [1:32:34, 14.55s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    34 runs   (    0.23 ms per token,  4373.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2005.08 ms /    32 tokens (   62.66 ms per token,    15.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6444.58 ms /    33 runs   (  195.29 ms per token,     5.12 tokens per second)\n",
      "llama_print_timings:       total time =    8526.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "556it [1:33:11, 21.13s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      45.68 ms /   191 runs   (    0.24 ms per token,  4181.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1887.79 ms /    30 tokens (   62.93 ms per token,    15.89 tokens per second)\n",
      "llama_print_timings:        eval time =   34128.42 ms /   190 runs   (  179.62 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =   36466.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "557it [1:33:26, 19.37s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.11 ms /    72 runs   (    0.24 ms per token,  4207.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2727.38 ms /    42 tokens (   64.94 ms per token,    15.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12367.59 ms /    71 runs   (  174.19 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   15261.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "558it [1:33:40, 17.74s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.38 ms /    65 runs   (    0.24 ms per token,  4224.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2084.72 ms /    32 tokens (   65.15 ms per token,    15.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11722.41 ms /    64 runs   (  183.16 ms per token,     5.46 tokens per second)\n",
      "llama_print_timings:       total time =   13956.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "559it [1:34:07, 20.61s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      30.35 ms /   130 runs   (    0.23 ms per token,  4283.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3807.04 ms /    61 tokens (   62.41 ms per token,    16.02 tokens per second)\n",
      "llama_print_timings:        eval time =   23164.57 ms /   129 runs   (  179.57 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =   27278.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "560it [1:34:18, 17.52s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.85 ms /    48 runs   (    0.23 ms per token,  4426.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1962.87 ms /    30 tokens (   65.43 ms per token,    15.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8248.64 ms /    47 runs   (  175.50 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   10317.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "561it [1:34:34, 17.02s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.62 ms /    77 runs   (    0.24 ms per token,  4135.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2357.82 ms /    33 tokens (   71.45 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13319.24 ms /    76 runs   (  175.25 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   15854.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "562it [1:34:48, 16.14s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.63 ms /    70 runs   (    0.24 ms per token,  4209.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1887.74 ms /    30 tokens (   62.92 ms per token,    15.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12049.67 ms /    69 runs   (  174.63 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =   14097.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "563it [1:34:56, 13.91s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    34 runs   (    0.24 ms per token,  4189.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2764.19 ms /    42 tokens (   65.81 ms per token,    15.19 tokens per second)\n",
      "llama_print_timings:        eval time =    5848.36 ms /    33 runs   (  177.22 ms per token,     5.64 tokens per second)\n",
      "llama_print_timings:       total time =    8689.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "564it [1:35:17, 15.86s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.42 ms /   101 runs   (    0.24 ms per token,  4135.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2265.81 ms /    32 tokens (   70.81 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   17919.51 ms /   100 runs   (  179.20 ms per token,     5.58 tokens per second)\n",
      "llama_print_timings:       total time =   20421.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "565it [1:35:32, 15.60s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.79 ms /    62 runs   (    0.24 ms per token,  4193.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3982.57 ms /    61 tokens (   65.29 ms per token,    15.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10855.82 ms /    61 runs   (  177.96 ms per token,     5.62 tokens per second)\n",
      "llama_print_timings:       total time =   14983.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "566it [1:35:52, 16.88s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.67 ms /   101 runs   (    0.22 ms per token,  4455.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2174.78 ms /    30 tokens (   72.49 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:        eval time =   17476.69 ms /   100 runs   (  174.77 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   19879.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "567it [1:36:04, 15.40s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.88 ms /    53 runs   (    0.24 ms per token,  4114.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2130.88 ms /    32 tokens (   66.59 ms per token,    15.02 tokens per second)\n",
      "llama_print_timings:        eval time =    9681.67 ms /    52 runs   (  186.19 ms per token,     5.37 tokens per second)\n",
      "llama_print_timings:       total time =   11937.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "568it [1:36:14, 14.01s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.37 ms /    50 runs   (    0.23 ms per token,  4396.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2090.09 ms /    30 tokens (   69.67 ms per token,    14.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8558.75 ms /    49 runs   (  174.67 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =   10760.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "569it [1:36:36, 16.20s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.68 ms /    87 runs   (    0.25 ms per token,  4012.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2945.88 ms /    42 tokens (   70.14 ms per token,    14.26 tokens per second)\n",
      "llama_print_timings:        eval time =   18137.91 ms /    86 runs   (  210.91 ms per token,     4.74 tokens per second)\n",
      "llama_print_timings:       total time =   21303.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "570it [1:36:52, 16.31s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.53 ms /    81 runs   (    0.24 ms per token,  4146.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2397.21 ms /    32 tokens (   74.91 ms per token,    13.35 tokens per second)\n",
      "llama_print_timings:        eval time =   13996.19 ms /    80 runs   (  174.95 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   16580.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "571it [1:37:15, 18.21s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.83 ms /   104 runs   (    0.23 ms per token,  4364.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4076.95 ms /    61 tokens (   66.84 ms per token,    14.96 tokens per second)\n",
      "llama_print_timings:        eval time =   18311.68 ms /   103 runs   (  177.78 ms per token,     5.62 tokens per second)\n",
      "llama_print_timings:       total time =   22628.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "572it [1:37:25, 15.64s/it]llama_print_timings:      sample time =      10.19 ms /    44 runs   (    0.23 ms per token,  4317.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2048.45 ms /    30 tokens (   68.28 ms per token,    14.65 tokens per second)\n",
      "llama_print_timings:        eval time =    7488.40 ms /    43 runs   (  174.15 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =    9637.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "573it [1:37:36, 14.47s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.35 ms /    52 runs   (    0.24 ms per token,  4211.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2474.21 ms /    33 tokens (   74.98 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:        eval time =    9153.19 ms /    51 runs   (  179.47 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =   11744.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "574it [1:37:57, 16.25s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.67 ms /   105 runs   (    0.23 ms per token,  4255.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1899.46 ms /    30 tokens (   63.32 ms per token,    15.79 tokens per second)\n",
      "llama_print_timings:        eval time =   18254.81 ms /   104 runs   (  175.53 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   20402.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    40 runs   (    0.23 ms per token,  4348.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2611.68 ms /    42 tokens (   62.18 ms per token,    16.08 tokens per second)\n",
      "llama_print_timings:        eval time =    7407.32 ms /    39 runs   (  189.93 ms per token,     5.27 tokens per second)\n",
      "llama_print_timings:       total time =   10112.34 ms\n",
      "575it [1:38:07, 14.41s/it]Llama.generate: prefix-match hit\n",
      "576it [1:38:20, 13.91s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.30 ms /    60 runs   (    0.24 ms per token,  4194.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2272.54 ms /    32 tokens (   71.02 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:        eval time =   10325.45 ms /    59 runs   (  175.01 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   12731.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "577it [1:38:43, 16.82s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.46 ms /   108 runs   (    0.23 ms per token,  4414.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4263.69 ms /    61 tokens (   69.90 ms per token,    14.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19103.60 ms /   107 runs   (  178.54 ms per token,     5.60 tokens per second)\n",
      "llama_print_timings:       total time =   23616.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "578it [1:38:55, 15.37s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    58 runs   (    0.22 ms per token,  4454.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1889.34 ms /    30 tokens (   62.98 ms per token,    15.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9966.69 ms /    57 runs   (  174.85 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   11984.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "579it [1:39:15, 16.87s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.50 ms /   100 runs   (    0.24 ms per token,  4255.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2493.31 ms /    32 tokens (   77.92 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:        eval time =   17640.68 ms /    99 runs   (  178.19 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:       total time =   20365.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "580it [1:39:35, 17.78s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.76 ms /    99 runs   (    0.24 ms per token,  4167.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2009.19 ms /    30 tokens (   66.97 ms per token,    14.93 tokens per second)\n",
      "llama_print_timings:        eval time =   17663.91 ms /    98 runs   (  180.24 ms per token,     5.55 tokens per second)\n",
      "llama_print_timings:       total time =   19908.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "581it [1:39:45, 15.18s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    36 runs   (    0.24 ms per token,  4239.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2864.22 ms /    42 tokens (   68.20 ms per token,    14.66 tokens per second)\n",
      "llama_print_timings:        eval time =    6175.35 ms /    35 runs   (  176.44 ms per token,     5.67 tokens per second)\n",
      "llama_print_timings:       total time =    9121.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "582it [1:39:55, 13.65s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.67 ms /    46 runs   (    0.23 ms per token,  4312.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1983.11 ms /    32 tokens (   61.97 ms per token,    16.14 tokens per second)\n",
      "llama_print_timings:        eval time =    7990.80 ms /    45 runs   (  177.57 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   10076.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "583it [1:40:20, 17.29s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.22 ms /   119 runs   (    0.23 ms per token,  4371.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4654.94 ms /    61 tokens (   76.31 ms per token,    13.10 tokens per second)\n",
      "llama_print_timings:        eval time =   20843.13 ms /   118 runs   (  176.64 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =   25771.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "584it [1:40:30, 15.13s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    44 runs   (    0.22 ms per token,  4497.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1893.19 ms /    30 tokens (   63.11 ms per token,    15.85 tokens per second)\n",
      "llama_print_timings:        eval time =    8116.70 ms /    43 runs   (  188.76 ms per token,     5.30 tokens per second)\n",
      "llama_print_timings:       total time =   10108.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "585it [1:40:49, 16.04s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.41 ms /    91 runs   (    0.24 ms per token,  4250.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2099.11 ms /    33 tokens (   63.61 ms per token,    15.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15853.97 ms /    90 runs   (  176.16 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   18160.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "586it [1:41:00, 14.78s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.79 ms /    55 runs   (    0.23 ms per token,  4299.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1873.42 ms /    30 tokens (   62.45 ms per token,    16.01 tokens per second)\n",
      "llama_print_timings:        eval time =    9839.16 ms /    54 runs   (  182.21 ms per token,     5.49 tokens per second)\n",
      "llama_print_timings:       total time =   11836.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "587it [1:41:11, 13.56s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.30 ms /    46 runs   (    0.22 ms per token,  4466.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2785.71 ms /    42 tokens (   66.33 ms per token,    15.08 tokens per second)\n",
      "llama_print_timings:        eval time =    7829.46 ms /    45 runs   (  173.99 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   10715.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "588it [1:41:21, 12.52s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.79 ms /    46 runs   (    0.23 ms per token,  4263.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2168.29 ms /    32 tokens (   67.76 ms per token,    14.76 tokens per second)\n",
      "llama_print_timings:        eval time =    7804.90 ms /    45 runs   (  173.44 ms per token,     5.77 tokens per second)\n",
      "llama_print_timings:       total time =   10075.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "589it [1:41:35, 12.81s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.45 ms /    47 runs   (    0.24 ms per token,  4103.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3979.58 ms /    61 tokens (   65.24 ms per token,    15.33 tokens per second)\n",
      "llama_print_timings:        eval time =    9404.41 ms /    46 runs   (  204.44 ms per token,     4.89 tokens per second)\n",
      "llama_print_timings:       total time =   13499.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "590it [1:41:45, 11.92s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.11 ms /    44 runs   (    0.23 ms per token,  4351.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2044.43 ms /    30 tokens (   68.15 ms per token,    14.67 tokens per second)\n",
      "llama_print_timings:        eval time =    7684.62 ms /    43 runs   (  178.71 ms per token,     5.60 tokens per second)\n",
      "llama_print_timings:       total time =    9831.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "591it [1:42:11, 16.35s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      31.91 ms /   136 runs   (    0.23 ms per token,  4261.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2013.81 ms /    32 tokens (   62.93 ms per token,    15.89 tokens per second)\n",
      "llama_print_timings:        eval time =   24354.52 ms /   135 runs   (  180.40 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =   26686.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "592it [1:42:23, 14.97s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.44 ms /    57 runs   (    0.24 ms per token,  4242.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1894.57 ms /    30 tokens (   63.15 ms per token,    15.83 tokens per second)\n",
      "llama_print_timings:        eval time =    9729.78 ms /    56 runs   (  173.75 ms per token,     5.76 tokens per second)\n",
      "llama_print_timings:       total time =   11750.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "593it [1:42:34, 13.85s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    46 runs   (    0.24 ms per token,  4201.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2671.90 ms /    42 tokens (   63.62 ms per token,    15.72 tokens per second)\n",
      "llama_print_timings:        eval time =    8443.00 ms /    45 runs   (  187.62 ms per token,     5.33 tokens per second)\n",
      "llama_print_timings:       total time =   11223.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "594it [1:42:50, 14.46s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.46 ms /    78 runs   (    0.24 ms per token,  4225.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2239.60 ms /    32 tokens (   69.99 ms per token,    14.29 tokens per second)\n",
      "llama_print_timings:        eval time =   13460.51 ms /    77 runs   (  174.81 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   15882.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "595it [1:43:06, 14.89s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.68 ms /    65 runs   (    0.23 ms per token,  4426.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3833.32 ms /    61 tokens (   62.84 ms per token,    15.91 tokens per second)\n",
      "llama_print_timings:        eval time =   11911.68 ms /    64 runs   (  186.12 ms per token,     5.37 tokens per second)\n",
      "llama_print_timings:       total time =   15894.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "596it [1:43:27, 16.71s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.26 ms /   105 runs   (    0.22 ms per token,  4513.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1890.86 ms /    30 tokens (   63.03 ms per token,    15.87 tokens per second)\n",
      "llama_print_timings:        eval time =   18810.60 ms /   104 runs   (  180.87 ms per token,     5.53 tokens per second)\n",
      "llama_print_timings:       total time =   20945.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "597it [1:43:49, 18.42s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.29 ms /   113 runs   (    0.23 ms per token,  4298.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2436.01 ms /    33 tokens (   73.82 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19707.66 ms /   112 runs   (  175.96 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   22401.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "598it [1:44:18, 21.42s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      34.64 ms /   147 runs   (    0.24 ms per token,  4243.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1903.90 ms /    30 tokens (   63.46 ms per token,    15.76 tokens per second)\n",
      "llama_print_timings:        eval time =   26185.30 ms /   146 runs   (  179.35 ms per token,     5.58 tokens per second)\n",
      "llama_print_timings:       total time =   28428.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "599it [1:44:31, 18.80s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.41 ms /    53 runs   (    0.23 ms per token,  4270.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3092.99 ms /    42 tokens (   73.64 ms per token,    13.58 tokens per second)\n",
      "llama_print_timings:        eval time =    9455.94 ms /    52 runs   (  181.84 ms per token,     5.50 tokens per second)\n",
      "llama_print_timings:       total time =   12669.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "600it [1:44:41, 16.21s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    44 runs   (    0.24 ms per token,  4187.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2588.47 ms /    32 tokens (   80.89 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:        eval time =    7486.42 ms /    43 runs   (  174.10 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   10174.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "601it [1:45:02, 17.88s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.07 ms /   100 runs   (    0.23 ms per token,  4334.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4298.24 ms /    66 tokens (   65.12 ms per token,    15.36 tokens per second)\n",
      "llama_print_timings:        eval time =   17254.87 ms /    99 runs   (  174.29 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   21784.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "602it [1:45:25, 19.19s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.04 ms /   113 runs   (    0.23 ms per token,  4339.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2118.88 ms /    30 tokens (   70.63 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =   19853.04 ms /   112 runs   (  177.26 ms per token,     5.64 tokens per second)\n",
      "llama_print_timings:       total time =   22236.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "603it [1:45:44, 19.34s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.62 ms /    96 runs   (    0.24 ms per token,  4244.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2419.73 ms /    32 tokens (   75.62 ms per token,    13.22 tokens per second)\n",
      "llama_print_timings:        eval time =   17055.09 ms /    95 runs   (  179.53 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =   19689.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "604it [1:45:58, 17.73s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.38 ms /    68 runs   (    0.24 ms per token,  4150.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2074.67 ms /    30 tokens (   69.16 ms per token,    14.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11739.27 ms /    67 runs   (  175.21 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   13971.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "605it [1:46:15, 17.25s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.78 ms /    74 runs   (    0.23 ms per token,  4410.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2793.88 ms /    42 tokens (   66.52 ms per token,    15.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13166.74 ms /    73 runs   (  180.37 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =   16134.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "606it [1:46:40, 19.69s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      30.09 ms /   126 runs   (    0.24 ms per token,  4186.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2545.33 ms /    36 tokens (   70.70 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   22524.04 ms /   125 runs   (  180.19 ms per token,     5.55 tokens per second)\n",
      "llama_print_timings:       total time =   25361.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "607it [1:46:59, 19.64s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.96 ms /    85 runs   (    0.23 ms per token,  4258.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3889.01 ms /    61 tokens (   63.75 ms per token,    15.69 tokens per second)\n",
      "llama_print_timings:        eval time =   15435.74 ms /    84 runs   (  183.76 ms per token,     5.44 tokens per second)\n",
      "llama_print_timings:       total time =   19527.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "608it [1:47:11, 17.08s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    52 runs   (    0.23 ms per token,  4308.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2056.49 ms /    30 tokens (   68.55 ms per token,    14.59 tokens per second)\n",
      "llama_print_timings:        eval time =    8927.59 ms /    51 runs   (  175.05 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   11099.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "609it [1:47:23, 15.66s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.83 ms /    59 runs   (    0.23 ms per token,  4265.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2088.07 ms /    33 tokens (   63.27 ms per token,    15.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10138.44 ms /    58 runs   (  174.80 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   12357.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "610it [1:47:42, 16.79s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.76 ms /    96 runs   (    0.24 ms per token,  4217.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1907.82 ms /    30 tokens (   63.59 ms per token,    15.72 tokens per second)\n",
      "llama_print_timings:        eval time =   17299.18 ms /    95 runs   (  182.10 ms per token,     5.49 tokens per second)\n",
      "llama_print_timings:       total time =   19429.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "611it [1:47:54, 15.21s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    50 runs   (    0.23 ms per token,  4286.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2665.20 ms /    42 tokens (   63.46 ms per token,    15.76 tokens per second)\n",
      "llama_print_timings:        eval time =    8739.09 ms /    49 runs   (  178.35 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:       total time =   11515.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "612it [1:48:11, 15.71s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.84 ms /    83 runs   (    0.24 ms per token,  4183.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2420.76 ms /    36 tokens (   67.24 ms per token,    14.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14250.73 ms /    82 runs   (  173.79 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   16870.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "613it [1:48:24, 15.04s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.56 ms /    55 runs   (    0.23 ms per token,  4378.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3958.04 ms /    61 tokens (   64.89 ms per token,    15.41 tokens per second)\n",
      "llama_print_timings:        eval time =    9382.76 ms /    54 runs   (  173.75 ms per token,     5.76 tokens per second)\n",
      "llama_print_timings:       total time =   13468.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.03 ms /    56 runs   (    0.23 ms per token,  4297.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2140.46 ms /    30 tokens (   71.35 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10001.88 ms /    55 runs   (  181.85 ms per token,     5.50 tokens per second)\n",
      "llama_print_timings:       total time =   12269.85 ms\n",
      "614it [1:48:36, 14.21s/it]Llama.generate: prefix-match hit\n",
      "615it [1:48:46, 12.83s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.55 ms /    44 runs   (    0.24 ms per token,  4169.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2039.57 ms /    32 tokens (   63.74 ms per token,    15.69 tokens per second)\n",
      "llama_print_timings:        eval time =    7459.43 ms /    43 runs   (  173.48 ms per token,     5.76 tokens per second)\n",
      "llama_print_timings:       total time =    9597.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "616it [1:49:06, 15.03s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.48 ms /   100 runs   (    0.23 ms per token,  4259.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1989.85 ms /    30 tokens (   66.33 ms per token,    15.08 tokens per second)\n",
      "llama_print_timings:        eval time =   17936.43 ms /    99 runs   (  181.18 ms per token,     5.52 tokens per second)\n",
      "llama_print_timings:       total time =   20159.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "617it [1:49:25, 16.07s/it]llama_print_timings:      sample time =      21.54 ms /    90 runs   (    0.24 ms per token,  4178.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2707.48 ms /    42 tokens (   64.46 ms per token,    15.51 tokens per second)\n",
      "llama_print_timings:        eval time =   15576.00 ms /    89 runs   (  175.01 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   18491.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "618it [1:49:36, 14.77s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.90 ms /    50 runs   (    0.24 ms per token,  4201.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2418.91 ms /    36 tokens (   67.19 ms per token,    14.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9211.57 ms /    49 runs   (  187.99 ms per token,     5.32 tokens per second)\n",
      "llama_print_timings:       total time =   11743.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "619it [1:49:54, 15.52s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.24 ms /    77 runs   (    0.24 ms per token,  4221.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3801.85 ms /    61 tokens (   62.33 ms per token,    16.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13288.06 ms /    76 runs   (  174.84 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   17271.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "620it [1:50:18, 18.22s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.15 ms /   123 runs   (    0.23 ms per token,  4369.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2059.48 ms /    30 tokens (   68.65 ms per token,    14.57 tokens per second)\n",
      "llama_print_timings:        eval time =   22171.87 ms /   122 runs   (  181.74 ms per token,     5.50 tokens per second)\n",
      "llama_print_timings:       total time =   24513.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "621it [1:50:41, 19.69s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.76 ms /   105 runs   (    0.25 ms per token,  4076.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2331.30 ms /    33 tokens (   70.65 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =   20531.35 ms /   104 runs   (  197.42 ms per token,     5.07 tokens per second)\n",
      "llama_print_timings:       total time =   23121.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "622it [1:50:53, 17.13s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.68 ms /    53 runs   (    0.24 ms per token,  4181.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1888.36 ms /    30 tokens (   62.95 ms per token,    15.89 tokens per second)\n",
      "llama_print_timings:        eval time =    9155.54 ms /    52 runs   (  176.07 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   11164.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "623it [1:51:14, 18.50s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.81 ms /   103 runs   (    0.23 ms per token,  4326.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2838.07 ms /    42 tokens (   67.57 ms per token,    14.80 tokens per second)\n",
      "llama_print_timings:        eval time =   18603.89 ms /   102 runs   (  182.39 ms per token,     5.48 tokens per second)\n",
      "llama_print_timings:       total time =   21676.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "624it [1:51:40, 20.56s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      29.05 ms /   125 runs   (    0.23 ms per token,  4302.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2643.75 ms /    36 tokens (   73.44 ms per token,    13.62 tokens per second)\n",
      "llama_print_timings:        eval time =   22439.23 ms /   124 runs   (  180.96 ms per token,     5.53 tokens per second)\n",
      "llama_print_timings:       total time =   25378.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "625it [1:52:11, 23.74s/it]llama_print_timings:      sample time =      34.98 ms /   151 runs   (    0.23 ms per token,  4316.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3923.60 ms /    61 tokens (   64.32 ms per token,    15.55 tokens per second)\n",
      "llama_print_timings:        eval time =   26862.79 ms /   150 runs   (  179.09 ms per token,     5.58 tokens per second)\n",
      "llama_print_timings:       total time =   31138.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "626it [1:52:36, 24.21s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      29.13 ms /   123 runs   (    0.24 ms per token,  4223.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2000.65 ms /    30 tokens (   66.69 ms per token,    15.00 tokens per second)\n",
      "llama_print_timings:        eval time =   23022.03 ms /   122 runs   (  188.71 ms per token,     5.30 tokens per second)\n",
      "llama_print_timings:       total time =   25314.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "627it [1:53:00, 24.10s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.27 ms /   118 runs   (    0.24 ms per token,  4174.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2547.10 ms /    32 tokens (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:        eval time =   21035.09 ms /   117 runs   (  179.79 ms per token,     5.56 tokens per second)\n",
      "llama_print_timings:       total time =   23857.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "628it [1:53:20, 22.89s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.36 ms /    99 runs   (    0.24 ms per token,  4237.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2623.42 ms /    30 tokens (   87.45 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:        eval time =   17218.58 ms /    98 runs   (  175.70 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   20068.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "629it [1:53:33, 19.91s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.19 ms /    56 runs   (    0.24 ms per token,  4246.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2654.77 ms /    42 tokens (   63.21 ms per token,    15.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10175.89 ms /    55 runs   (  185.02 ms per token,     5.40 tokens per second)\n",
      "llama_print_timings:       total time =   12957.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "630it [1:53:50, 19.14s/it]llama_print_timings:      sample time =      18.35 ms /    75 runs   (    0.24 ms per token,  4087.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2718.73 ms /    36 tokens (   75.52 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =   14421.47 ms /    74 runs   (  194.88 ms per token,     5.13 tokens per second)\n",
      "llama_print_timings:       total time =   17323.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "631it [1:54:08, 18.61s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.49 ms /    67 runs   (    0.23 ms per token,  4324.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4610.13 ms /    61 tokens (   75.58 ms per token,    13.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12616.74 ms /    66 runs   (  191.16 ms per token,     5.23 tokens per second)\n",
      "llama_print_timings:       total time =   17389.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "632it [1:54:21, 16.96s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.51 ms /    63 runs   (    0.23 ms per token,  4342.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2035.16 ms /    30 tokens (   67.84 ms per token,    14.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10922.34 ms /    62 runs   (  176.17 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   13101.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "633it [1:54:41, 17.94s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.34 ms /    97 runs   (    0.24 ms per token,  4156.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2406.36 ms /    33 tokens (   72.92 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:        eval time =   17581.02 ms /    96 runs   (  183.14 ms per token,     5.46 tokens per second)\n",
      "llama_print_timings:       total time =   20220.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "634it [1:54:49, 15.07s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    37 runs   (    0.24 ms per token,  4161.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1973.19 ms /    30 tokens (   65.77 ms per token,    15.20 tokens per second)\n",
      "llama_print_timings:        eval time =    6302.41 ms /    36 runs   (  175.07 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =    8361.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "635it [1:55:14, 17.88s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.80 ms /   119 runs   (    0.24 ms per token,  4132.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2733.66 ms /    42 tokens (   65.09 ms per token,    15.36 tokens per second)\n",
      "llama_print_timings:        eval time =   21414.95 ms /   118 runs   (  181.48 ms per token,     5.51 tokens per second)\n",
      "llama_print_timings:       total time =   24436.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "636it [1:55:23, 15.43s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    41 runs   (    0.23 ms per token,  4363.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2573.25 ms /    36 tokens (   71.48 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =    7062.30 ms /    40 runs   (  176.56 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =    9726.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "637it [1:55:48, 18.28s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.63 ms /   118 runs   (    0.23 ms per token,  4431.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3969.98 ms /    61 tokens (   65.08 ms per token,    15.37 tokens per second)\n",
      "llama_print_timings:        eval time =   20681.92 ms /   117 runs   (  176.77 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =   24924.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "638it [1:56:10, 19.37s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.88 ms /   109 runs   (    0.23 ms per token,  4381.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2013.81 ms /    30 tokens (   67.13 ms per token,    14.90 tokens per second)\n",
      "llama_print_timings:        eval time =   19658.40 ms /   108 runs   (  182.02 ms per token,     5.49 tokens per second)\n",
      "llama_print_timings:       total time =   21925.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "639it [1:56:21, 16.76s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    49 runs   (    0.24 ms per token,  4136.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2031.65 ms /    32 tokens (   63.49 ms per token,    15.75 tokens per second)\n",
      "llama_print_timings:        eval time =    8510.78 ms /    48 runs   (  177.31 ms per token,     5.64 tokens per second)\n",
      "llama_print_timings:       total time =   10653.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "640it [1:56:31, 14.87s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.29 ms /    49 runs   (    0.23 ms per token,  4341.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1896.57 ms /    30 tokens (   63.22 ms per token,    15.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8452.46 ms /    48 runs   (  176.09 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   10461.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "641it [1:56:44, 14.16s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    51 runs   (    0.23 ms per token,  4304.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3684.85 ms /    42 tokens (   87.73 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:        eval time =    8694.95 ms /    50 runs   (  173.90 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   12496.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "642it [1:56:47, 10.77s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     2 runs   (    0.32 ms per token,  3086.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2674.60 ms /    36 tokens (   74.29 ms per token,    13.46 tokens per second)\n",
      "llama_print_timings:        eval time =     173.94 ms /     1 runs   (  173.94 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =    2855.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "643it [1:57:04, 12.62s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.67 ms /    69 runs   (    0.24 ms per token,  4139.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4191.63 ms /    61 tokens (   68.72 ms per token,    14.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12569.43 ms /    68 runs   (  184.84 ms per token,     5.41 tokens per second)\n",
      "llama_print_timings:       total time =   16928.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "644it [1:57:28, 16.25s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      29.37 ms /   128 runs   (    0.23 ms per token,  4358.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2042.62 ms /    30 tokens (   68.09 ms per token,    14.69 tokens per second)\n",
      "llama_print_timings:        eval time =   22373.90 ms /   127 runs   (  176.17 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   24715.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "645it [1:57:49, 17.50s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.29 ms /   102 runs   (    0.24 ms per token,  4199.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2250.21 ms /    33 tokens (   68.19 ms per token,    14.67 tokens per second)\n",
      "llama_print_timings:        eval time =   17945.43 ms /   101 runs   (  177.68 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   20435.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "646it [1:57:57, 14.67s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.57 ms /    36 runs   (    0.24 ms per token,  4201.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1889.69 ms /    30 tokens (   62.99 ms per token,    15.88 tokens per second)\n",
      "llama_print_timings:        eval time =    6069.73 ms /    35 runs   (  173.42 ms per token,     5.77 tokens per second)\n",
      "llama_print_timings:       total time =    8042.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "647it [1:58:17, 16.36s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.77 ms /    95 runs   (    0.24 ms per token,  4172.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2872.27 ms /    42 tokens (   68.39 ms per token,    14.62 tokens per second)\n",
      "llama_print_timings:        eval time =   17208.68 ms /    94 runs   (  183.07 ms per token,     5.46 tokens per second)\n",
      "llama_print_timings:       total time =   20307.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "648it [1:58:26, 13.96s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    34 runs   (    0.23 ms per token,  4357.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2346.35 ms /    36 tokens (   65.18 ms per token,    15.34 tokens per second)\n",
      "llama_print_timings:        eval time =    5925.18 ms /    33 runs   (  179.55 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =    8347.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "649it [1:58:39, 13.81s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    54 runs   (    0.23 ms per token,  4398.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4014.72 ms /    61 tokens (   65.82 ms per token,    15.19 tokens per second)\n",
      "llama_print_timings:        eval time =    9336.47 ms /    53 runs   (  176.16 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   13473.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "650it [1:58:41, 10.29s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     2 runs   (    0.25 ms per token,  3992.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1883.09 ms /    30 tokens (   62.77 ms per token,    15.93 tokens per second)\n",
      "llama_print_timings:        eval time =     169.22 ms /     1 runs   (  169.22 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =    2056.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "651it [1:59:00, 12.77s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.39 ms /    79 runs   (    0.23 ms per token,  4296.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2116.27 ms /    32 tokens (   66.13 ms per token,    15.12 tokens per second)\n",
      "llama_print_timings:        eval time =   16240.94 ms /    78 runs   (  208.22 ms per token,     4.80 tokens per second)\n",
      "llama_print_timings:       total time =   18550.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "652it [1:59:28, 17.34s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      34.34 ms /   143 runs   (    0.24 ms per token,  4163.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2030.32 ms /    30 tokens (   67.68 ms per token,    14.78 tokens per second)\n",
      "llama_print_timings:        eval time =   25639.01 ms /   142 runs   (  180.56 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =   28013.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "653it [1:59:50, 18.82s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.05 ms /   110 runs   (    0.24 ms per token,  4222.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2667.53 ms /    42 tokens (   63.51 ms per token,    15.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19359.14 ms /   109 runs   (  177.61 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   22281.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "654it [2:00:00, 16.16s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    39 runs   (    0.23 ms per token,  4321.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2460.26 ms /    36 tokens (   68.34 ms per token,    14.63 tokens per second)\n",
      "llama_print_timings:        eval time =    7393.10 ms /    38 runs   (  194.56 ms per token,     5.14 tokens per second)\n",
      "llama_print_timings:       total time =    9944.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "655it [2:00:22, 17.94s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      21.90 ms /    93 runs   (    0.24 ms per token,  4245.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4101.05 ms /    61 tokens (   67.23 ms per token,    14.87 tokens per second)\n",
      "llama_print_timings:        eval time =   17758.43 ms /    92 runs   (  193.03 ms per token,     5.18 tokens per second)\n",
      "llama_print_timings:       total time =   22085.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "656it [2:00:25, 13.39s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2599.10 ms /    30 tokens (   86.64 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:        eval time =     172.61 ms /     1 runs   (  172.61 ms per token,     5.79 tokens per second)\n",
      "llama_print_timings:       total time =    2775.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "657it [2:00:37, 13.11s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.89 ms /    49 runs   (    0.24 ms per token,  4120.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2098.09 ms /    33 tokens (   63.58 ms per token,    15.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10233.83 ms /    48 runs   (  213.20 ms per token,     4.69 tokens per second)\n",
      "llama_print_timings:       total time =   12458.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "658it [2:00:50, 13.01s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.89 ms /    58 runs   (    0.26 ms per token,  3895.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2137.43 ms /    30 tokens (   71.25 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10506.79 ms /    57 runs   (  184.33 ms per token,     5.43 tokens per second)\n",
      "llama_print_timings:       total time =   12784.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "659it [2:01:13, 16.09s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.75 ms /   117 runs   (    0.24 ms per token,  4215.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2634.10 ms /    42 tokens (   62.72 ms per token,    15.94 tokens per second)\n",
      "llama_print_timings:        eval time =   20362.23 ms /   116 runs   (  175.54 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   23264.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "660it [2:01:29, 15.87s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.88 ms /    74 runs   (    0.24 ms per token,  4137.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2324.31 ms /    36 tokens (   64.56 ms per token,    15.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12868.01 ms /    73 runs   (  176.27 ms per token,     5.67 tokens per second)\n",
      "llama_print_timings:       total time =   15363.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "661it [2:02:49, 35.13s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =     100.94 ms /   421 runs   (    0.24 ms per token,  4170.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4794.15 ms /    66 tokens (   72.64 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   74184.35 ms /   420 runs   (  176.63 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =   80054.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "662it [2:03:13, 32.01s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.72 ms /   126 runs   (    0.23 ms per token,  4387.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1977.97 ms /    30 tokens (   65.93 ms per token,    15.17 tokens per second)\n",
      "llama_print_timings:        eval time =   22455.69 ms /   125 runs   (  179.65 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =   24723.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "663it [2:03:31, 27.71s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      20.59 ms /    89 runs   (    0.23 ms per token,  4321.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2009.63 ms /    32 tokens (   62.80 ms per token,    15.92 tokens per second)\n",
      "llama_print_timings:        eval time =   15486.03 ms /    88 runs   (  175.98 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   17696.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "664it [2:03:44, 23.15s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.32 ms /    55 runs   (    0.24 ms per token,  4129.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2822.25 ms /    30 tokens (   94.08 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9552.00 ms /    54 runs   (  176.89 ms per token,     5.65 tokens per second)\n",
      "llama_print_timings:       total time =   12503.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "665it [2:03:54, 19.22s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    44 runs   (    0.23 ms per token,  4310.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2567.26 ms /    42 tokens (   61.13 ms per token,    16.36 tokens per second)\n",
      "llama_print_timings:        eval time =    7365.04 ms /    43 runs   (  171.28 ms per token,     5.84 tokens per second)\n",
      "llama_print_timings:       total time =   10029.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "666it [2:04:06, 17.15s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.52 ms /    58 runs   (    0.23 ms per token,  4291.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2410.24 ms /    36 tokens (   66.95 ms per token,    14.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9777.34 ms /    57 runs   (  171.53 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =   12321.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "667it [2:04:31, 19.47s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.72 ms /   119 runs   (    0.22 ms per token,  4453.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3846.18 ms /    61 tokens (   63.05 ms per token,    15.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20771.55 ms /   118 runs   (  176.03 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   24894.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "668it [2:04:53, 20.29s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      26.99 ms /   117 runs   (    0.23 ms per token,  4335.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2115.61 ms /    30 tokens (   70.52 ms per token,    14.18 tokens per second)\n",
      "llama_print_timings:        eval time =   19799.58 ms /   116 runs   (  170.69 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   22191.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "669it [2:05:09, 18.91s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.05 ms /    76 runs   (    0.24 ms per token,  4210.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2117.03 ms /    33 tokens (   64.15 ms per token,    15.59 tokens per second)\n",
      "llama_print_timings:        eval time =   13413.42 ms /    75 runs   (  178.85 ms per token,     5.59 tokens per second)\n",
      "llama_print_timings:       total time =   15706.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "670it [2:05:20, 16.45s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    52 runs   (    0.23 ms per token,  4356.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1912.97 ms /    30 tokens (   63.77 ms per token,    15.68 tokens per second)\n",
      "llama_print_timings:        eval time =    8684.05 ms /    51 runs   (  170.28 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   10712.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "671it [2:05:28, 14.04s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    31 runs   (    0.23 ms per token,  4313.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2590.29 ms /    42 tokens (   61.67 ms per token,    16.21 tokens per second)\n",
      "llama_print_timings:        eval time =    5751.35 ms /    30 runs   (  191.71 ms per token,     5.22 tokens per second)\n",
      "llama_print_timings:       total time =    8414.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "672it [2:05:44, 14.72s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.50 ms /    82 runs   (    0.24 ms per token,  4205.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2276.07 ms /    36 tokens (   63.22 ms per token,    15.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13840.21 ms /    81 runs   (  170.87 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   16306.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "673it [2:06:06, 16.93s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.18 ms /   103 runs   (    0.23 ms per token,  4443.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3738.84 ms /    61 tokens (   61.29 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:        eval time =   18117.62 ms /   102 runs   (  177.62 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   22091.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "674it [2:06:23, 16.77s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      18.84 ms /    82 runs   (    0.23 ms per token,  4352.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1891.51 ms /    30 tokens (   63.05 ms per token,    15.86 tokens per second)\n",
      "llama_print_timings:        eval time =   14317.72 ms /    81 runs   (  176.76 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =   16400.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "675it [2:06:33, 14.77s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    37 runs   (    0.24 ms per token,  4204.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2012.81 ms /    32 tokens (   62.90 ms per token,    15.90 tokens per second)\n",
      "llama_print_timings:        eval time =    7994.32 ms /    36 runs   (  222.06 ms per token,     4.50 tokens per second)\n",
      "llama_print_timings:       total time =   10101.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "676it [2:06:52, 16.11s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      22.65 ms /    98 runs   (    0.23 ms per token,  4327.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2557.03 ms /    30 tokens (   85.23 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:        eval time =   16442.00 ms /    97 runs   (  169.51 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   19225.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "677it [2:07:03, 14.48s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.15 ms /    48 runs   (    0.23 ms per token,  4303.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2525.10 ms /    42 tokens (   60.12 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =    8033.76 ms /    47 runs   (  170.93 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   10667.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "678it [2:07:24, 16.39s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.42 ms /   103 runs   (    0.24 ms per token,  4218.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2860.69 ms /    36 tokens (   79.46 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:        eval time =   17746.53 ms /   102 runs   (  173.99 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   20845.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "679it [2:07:54, 20.52s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      34.16 ms /   151 runs   (    0.23 ms per token,  4420.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3991.19 ms /    61 tokens (   65.43 ms per token,    15.28 tokens per second)\n",
      "llama_print_timings:        eval time =   25822.92 ms /   150 runs   (  172.15 ms per token,     5.81 tokens per second)\n",
      "llama_print_timings:       total time =   30163.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "680it [2:08:16, 20.93s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.71 ms /   110 runs   (    0.22 ms per token,  4451.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2223.94 ms /    30 tokens (   74.13 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =   19403.90 ms /   109 runs   (  178.02 ms per token,     5.62 tokens per second)\n",
      "llama_print_timings:       total time =   21877.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "681it [2:08:27, 18.17s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.61 ms /    57 runs   (    0.24 ms per token,  4186.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2028.21 ms /    33 tokens (   61.46 ms per token,    16.27 tokens per second)\n",
      "llama_print_timings:        eval time =    9568.98 ms /    56 runs   (  170.87 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   11728.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "682it [2:08:43, 17.31s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.20 ms /    75 runs   (    0.23 ms per token,  4361.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2002.39 ms /    30 tokens (   66.75 ms per token,    14.98 tokens per second)\n",
      "llama_print_timings:        eval time =   13135.64 ms /    74 runs   (  177.51 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   15306.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "683it [2:08:53, 15.13s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.63 ms /    43 runs   (    0.22 ms per token,  4463.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2840.57 ms /    42 tokens (   67.63 ms per token,    14.79 tokens per second)\n",
      "llama_print_timings:        eval time =    7105.97 ms /    42 runs   (  169.19 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   10039.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "684it [2:09:09, 15.55s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.02 ms /    80 runs   (    0.24 ms per token,  4206.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2411.42 ms /    36 tokens (   66.98 ms per token,    14.93 tokens per second)\n",
      "llama_print_timings:        eval time =   13938.98 ms /    79 runs   (  176.44 ms per token,     5.67 tokens per second)\n",
      "llama_print_timings:       total time =   16538.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "685it [2:09:22, 14.75s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    54 runs   (    0.24 ms per token,  4236.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3737.54 ms /    61 tokens (   61.27 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:        eval time =    9010.41 ms /    53 runs   (  170.01 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   12874.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "686it [2:09:36, 14.52s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.29 ms /    67 runs   (    0.23 ms per token,  4381.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1889.02 ms /    30 tokens (   62.97 ms per token,    15.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11950.35 ms /    66 runs   (  181.07 ms per token,     5.52 tokens per second)\n",
      "llama_print_timings:       total time =   13990.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "687it [2:09:59, 16.94s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      27.88 ms /   120 runs   (    0.23 ms per token,  4304.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2009.99 ms /    32 tokens (   62.81 ms per token,    15.92 tokens per second)\n",
      "llama_print_timings:        eval time =   20290.83 ms /   119 runs   (  170.51 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   22579.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "688it [2:10:13, 16.13s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      16.12 ms /    68 runs   (    0.24 ms per token,  4217.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2146.52 ms /    30 tokens (   71.55 ms per token,    13.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11945.77 ms /    67 runs   (  178.30 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:       total time =   14251.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "689it [2:11:35, 35.89s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =     101.13 ms /   446 runs   (    0.23 ms per token,  4410.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2804.66 ms /    42 tokens (   66.78 ms per token,    14.98 tokens per second)\n",
      "llama_print_timings:        eval time =   78064.88 ms /   445 runs   (  175.43 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   81993.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "690it [2:11:43, 27.48s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    33 runs   (    0.22 ms per token,  4451.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2288.82 ms /    36 tokens (   63.58 ms per token,    15.73 tokens per second)\n",
      "llama_print_timings:        eval time =    5488.53 ms /    32 runs   (  171.52 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =    7850.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "691it [2:12:00, 24.51s/it]llama_print_timings:      sample time =      16.08 ms /    69 runs   (    0.23 ms per token,  4290.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4393.58 ms /    61 tokens (   72.03 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =   13007.42 ms /    68 runs   (  191.29 ms per token,     5.23 tokens per second)\n",
      "llama_print_timings:       total time =   17567.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "692it [2:12:20, 23.06s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      23.43 ms /   100 runs   (    0.23 ms per token,  4267.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2600.24 ms /    30 tokens (   86.67 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:        eval time =   16845.29 ms /    99 runs   (  170.15 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   19670.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "693it [2:12:35, 20.63s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      17.13 ms /    71 runs   (    0.24 ms per token,  4144.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2128.22 ms /    33 tokens (   64.49 ms per token,    15.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12680.21 ms /    70 runs   (  181.15 ms per token,     5.52 tokens per second)\n",
      "llama_print_timings:       total time =   14977.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "694it [2:12:58, 21.41s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      28.35 ms /   121 runs   (    0.23 ms per token,  4267.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1934.99 ms /    30 tokens (   64.50 ms per token,    15.50 tokens per second)\n",
      "llama_print_timings:        eval time =   21017.64 ms /   120 runs   (  175.15 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   23231.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "695it [2:13:10, 18.60s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    53 runs   (    0.24 ms per token,  4210.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2663.59 ms /    42 tokens (   63.42 ms per token,    15.77 tokens per second)\n",
      "llama_print_timings:        eval time =    9263.91 ms /    52 runs   (  178.15 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:       total time =   12048.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "696it [2:13:23, 16.85s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.34 ms /    61 runs   (    0.24 ms per token,  4254.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2404.56 ms /    36 tokens (   66.79 ms per token,    14.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10193.42 ms /    60 runs   (  169.89 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   12738.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "697it [2:13:38, 16.16s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.74 ms /    60 runs   (    0.23 ms per token,  4367.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3737.01 ms /    61 tokens (   61.26 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:        eval time =   10672.14 ms /    59 runs   (  180.88 ms per token,     5.53 tokens per second)\n",
      "llama_print_timings:       total time =   14549.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "698it [2:13:50, 15.11s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.09 ms /    63 runs   (    0.22 ms per token,  4470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2021.91 ms /    30 tokens (   67.40 ms per token,    14.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10514.06 ms /    62 runs   (  169.58 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   12675.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "699it [2:14:02, 14.00s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    52 runs   (    0.24 ms per token,  4224.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1970.23 ms /    32 tokens (   61.57 ms per token,    16.24 tokens per second)\n",
      "llama_print_timings:        eval time =    9316.60 ms /    51 runs   (  182.68 ms per token,     5.47 tokens per second)\n",
      "llama_print_timings:       total time =   11405.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "700it [2:14:14, 13.55s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.44 ms /    60 runs   (    0.24 ms per token,  4155.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1885.10 ms /    30 tokens (   62.84 ms per token,    15.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10466.02 ms /    59 runs   (  177.39 ms per token,     5.64 tokens per second)\n",
      "llama_print_timings:       total time =   12488.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "701it [2:14:23, 12.02s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    35 runs   (    0.23 ms per token,  4297.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2592.89 ms /    42 tokens (   61.74 ms per token,    16.20 tokens per second)\n",
      "llama_print_timings:        eval time =    5773.62 ms /    34 runs   (  169.81 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =    8446.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "702it [2:14:40, 13.55s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.42 ms /    83 runs   (    0.23 ms per token,  4274.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2315.49 ms /    36 tokens (   64.32 ms per token,    15.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14607.92 ms /    82 runs   (  178.15 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:       total time =   17117.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "703it [2:15:03, 16.48s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      24.44 ms /   111 runs   (    0.22 ms per token,  4541.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3862.85 ms /    61 tokens (   63.33 ms per token,    15.79 tokens per second)\n",
      "llama_print_timings:        eval time =   19192.00 ms /   110 runs   (  174.47 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =   23309.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "704it [2:15:23, 17.49s/it]llama_print_timings:      sample time =      23.28 ms /   103 runs   (    0.23 ms per token,  4424.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2148.50 ms /    30 tokens (   71.62 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17452.54 ms /   102 runs   (  171.10 ms per token,     5.84 tokens per second)\n",
      "llama_print_timings:       total time =   19839.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "705it [2:15:48, 19.84s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      30.69 ms /   130 runs   (    0.24 ms per token,  4236.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2334.00 ms /    33 tokens (   70.73 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   22698.72 ms /   129 runs   (  175.96 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   25339.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "706it [2:16:00, 17.52s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      13.78 ms /    57 runs   (    0.24 ms per token,  4136.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1852.12 ms /    30 tokens (   61.74 ms per token,    16.20 tokens per second)\n",
      "llama_print_timings:        eval time =   10091.94 ms /    56 runs   (  180.21 ms per token,     5.55 tokens per second)\n",
      "llama_print_timings:       total time =   12080.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "707it [2:16:12, 15.79s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.69 ms /    54 runs   (    0.24 ms per token,  4254.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2629.99 ms /    42 tokens (   62.62 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =    8994.93 ms /    53 runs   (  169.72 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   11750.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "708it [2:16:26, 15.31s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      15.84 ms /    68 runs   (    0.23 ms per token,  4294.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2282.03 ms /    36 tokens (   63.39 ms per token,    15.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11752.18 ms /    67 runs   (  175.41 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   14187.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "709it [2:16:50, 17.82s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      25.97 ms /   112 runs   (    0.23 ms per token,  4312.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3782.96 ms /    61 tokens (   62.02 ms per token,    16.12 tokens per second)\n",
      "llama_print_timings:        eval time =   19644.90 ms /   111 runs   (  176.98 ms per token,     5.65 tokens per second)\n",
      "llama_print_timings:       total time =   23695.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "710it [2:17:01, 15.70s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.46 ms /    48 runs   (    0.24 ms per token,  4187.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1864.65 ms /    30 tokens (   62.16 ms per token,    16.09 tokens per second)\n",
      "llama_print_timings:        eval time =    8754.39 ms /    47 runs   (  186.26 ms per token,     5.37 tokens per second)\n",
      "llama_print_timings:       total time =   10731.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "711it [2:17:10, 13.70s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       9.81 ms /    42 runs   (    0.23 ms per token,  4282.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2003.79 ms /    32 tokens (   62.62 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6939.30 ms /    41 runs   (  169.25 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =    9038.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "712it [2:17:27, 14.66s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.78 ms /    85 runs   (    0.23 ms per token,  4298.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1892.64 ms /    30 tokens (   63.09 ms per token,    15.85 tokens per second)\n",
      "llama_print_timings:        eval time =   14794.48 ms /    84 runs   (  176.12 ms per token,     5.68 tokens per second)\n",
      "llama_print_timings:       total time =   16885.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "713it [2:17:36, 12.96s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    34 runs   (    0.23 ms per token,  4325.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2990.22 ms /    42 tokens (   71.20 ms per token,    14.05 tokens per second)\n",
      "llama_print_timings:        eval time =    5925.95 ms /    33 runs   (  179.57 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =    8993.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "714it [2:17:49, 13.03s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.83 ms /    64 runs   (    0.23 ms per token,  4317.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2300.07 ms /    36 tokens (   63.89 ms per token,    15.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10763.73 ms /    63 runs   (  170.85 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   13210.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "715it [2:18:17, 17.61s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      31.22 ms /   137 runs   (    0.23 ms per token,  4388.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3804.60 ms /    61 tokens (   62.37 ms per token,    16.03 tokens per second)\n",
      "llama_print_timings:        eval time =   24138.43 ms /   136 runs   (  177.49 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   28270.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "716it [2:18:28, 15.55s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      11.54 ms /    48 runs   (    0.24 ms per token,  4157.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1998.35 ms /    30 tokens (   66.61 ms per token,    15.01 tokens per second)\n",
      "llama_print_timings:        eval time =    8637.66 ms /    47 runs   (  183.78 ms per token,     5.44 tokens per second)\n",
      "llama_print_timings:       total time =   10750.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "717it [2:18:37, 13.70s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    43 runs   (    0.24 ms per token,  4246.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2047.27 ms /    33 tokens (   62.04 ms per token,    16.12 tokens per second)\n",
      "llama_print_timings:        eval time =    7247.07 ms /    42 runs   (  172.55 ms per token,     5.80 tokens per second)\n",
      "llama_print_timings:       total time =    9394.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "718it [2:18:48, 12.78s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    52 runs   (    0.23 ms per token,  4291.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1841.98 ms /    30 tokens (   61.40 ms per token,    16.29 tokens per second)\n",
      "llama_print_timings:        eval time =    8657.62 ms /    51 runs   (  169.76 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   10618.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "719it [2:19:06, 14.31s/it]\n",
      "llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      19.53 ms /    84 runs   (    0.23 ms per token,  4301.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2885.48 ms /    42 tokens (   68.70 ms per token,    14.56 tokens per second)\n",
      "llama_print_timings:        eval time =   14791.27 ms /    83 runs   (  178.21 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:       total time =   17875.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "720it [2:19:18, 13.80s/it]llama_print_timings:        load time =    5330.46 ms\n",
      "llama_print_timings:      sample time =      14.10 ms /    61 runs   (    0.23 ms per token,  4326.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2259.96 ms /    36 tokens (   62.78 ms per token,    15.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10217.62 ms /    60 runs   (  170.29 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   12615.89 ms\n",
      "720it [2:19:18, 11.61s/it]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/preprocessed/test.csv\")\n",
    "llm = Llama(model_path=\"../models/zephyr-7b-beta.Q4_K_M.gguf\")\n",
    "\n",
    "outputs_zephyr = []\n",
    "\n",
    "for i, row in tqdm(data.iterrows()):\n",
    "    if i < 236:\n",
    "        continue\n",
    "    city_from, city_to, date_str, date_back, need_luggage = (\n",
    "        row[\"city_from\"],\n",
    "        row[\"city_to\"],\n",
    "        row[\"date\"],\n",
    "        row[\"date_back\"],\n",
    "        row[\"need_luggage\"],\n",
    "    )\n",
    "    question = generate_prompt(city_from, city_to, date_str, date_back, need_luggage)\n",
    "    output = llm.create_chat_completion(\n",
    "        messages=[{\"role\": \"user\", \"content\": question}], temperature=0.8\n",
    "    )\n",
    "\n",
    "    outputs_zephyr.append(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "\n",
    "data[\"zephyr_question\"] = outputs_zephyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from ../models/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:           blk.15.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.15.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:             blk.15.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:             blk.15.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:        blk.15.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:             blk.15.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:             blk.15.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:           blk.16.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.16.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:             blk.16.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:             blk.16.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:        blk.16.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.16.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:             blk.16.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:           blk.17.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.17.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.17.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:             blk.17.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:        blk.17.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.17.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:             blk.17.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:           blk.18.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.18.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.18.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.18.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:        blk.18.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:             blk.18.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.18.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.19.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.19.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.19.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.19.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:        blk.19.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:             blk.19.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.19.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.2.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:            blk.2.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:              blk.2.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.2.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:         blk.2.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.2.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:              blk.2.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.20.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.20.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.20.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.20.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.20.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.20.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.20.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.21.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.21.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.21.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.21.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.21.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.21.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.21.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.22.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.22.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.22.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.22.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.22.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.22.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.22.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.23.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.23.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.23.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.23.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.23.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.23.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.23.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:            blk.3.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:            blk.3.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:              blk.3.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:              blk.3.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:         blk.3.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:              blk.3.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:              blk.3.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:            blk.4.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:            blk.4.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:              blk.4.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:              blk.4.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:         blk.4.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:              blk.4.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:              blk.4.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:            blk.5.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:            blk.5.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:              blk.5.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:              blk.5.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:         blk.5.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:              blk.5.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:              blk.5.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:            blk.6.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:            blk.6.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:              blk.6.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:              blk.6.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:         blk.6.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:              blk.6.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:              blk.6.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:            blk.7.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:            blk.7.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:              blk.7.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:              blk.7.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:         blk.7.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:              blk.7.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:              blk.7.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:            blk.8.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:            blk.8.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:              blk.8.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:              blk.8.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:         blk.8.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:              blk.8.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:              blk.8.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:            blk.9.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:            blk.9.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:              blk.9.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:              blk.9.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:         blk.9.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:              blk.9.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:              blk.9.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:           blk.24.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.24.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:        blk.24.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.24.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:           blk.25.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:             blk.25.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:        blk.25.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.25.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:           blk.26.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:             blk.26.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:             blk.26.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:        blk.26.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.26.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:           blk.27.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:             blk.27.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:             blk.27.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:        blk.27.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.27.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:           blk.28.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:             blk.28.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:             blk.28.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:        blk.28.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.28.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:           blk.29.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:             blk.29.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:             blk.29.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:        blk.29.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.29.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:           blk.30.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:           blk.30.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:             blk.30.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:        blk.30.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:             blk.30.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.30.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: mem required  = 3891.35 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =  256.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 740/740\n",
      "llama_new_context_with_model: compute buffer total size = 73.56 MiB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
      "1it [00:26, 26.25s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.18 ms /   128 runs   (    0.20 ms per token,  4889.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4677.75 ms /    89 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   21277.13 ms /   127 runs   (  167.54 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   26245.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "2it [00:46, 22.89s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.86 ms /   111 runs   (    0.21 ms per token,  4855.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1838.31 ms /    30 tokens (   61.28 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:        eval time =   18441.29 ms /   110 runs   (  167.65 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   20536.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "3it [01:01, 18.98s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.34 ms /    76 runs   (    0.22 ms per token,  4650.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1987.80 ms /    33 tokens (   60.24 ms per token,    16.60 tokens per second)\n",
      "llama_print_timings:        eval time =   12166.97 ms /    75 runs   (  162.23 ms per token,     6.16 tokens per second)\n",
      "llama_print_timings:       total time =   14326.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "4it [01:14, 16.76s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.91 ms /    67 runs   (    0.22 ms per token,  4494.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1970.16 ms /    30 tokens (   65.67 ms per token,    15.23 tokens per second)\n",
      "llama_print_timings:        eval time =   11238.38 ms /    66 runs   (  170.28 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   13363.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "5it [01:26, 14.91s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    56 runs   (    0.22 ms per token,  4563.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2408.81 ms /    42 tokens (   57.35 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =    9092.33 ms /    55 runs   (  165.32 ms per token,     6.05 tokens per second)\n",
      "llama_print_timings:       total time =   11631.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "6it [01:37, 13.69s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.87 ms /    56 runs   (    0.23 ms per token,  4351.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2212.77 ms /    36 tokens (   61.47 ms per token,    16.27 tokens per second)\n",
      "llama_print_timings:        eval time =    8956.37 ms /    55 runs   (  162.84 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   11298.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "7it [01:59, 16.38s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.95 ms /   107 runs   (    0.21 ms per token,  4662.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3950.76 ms /    62 tokens (   63.72 ms per token,    15.69 tokens per second)\n",
      "llama_print_timings:        eval time =   17738.28 ms /   106 runs   (  167.34 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   21939.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "8it [02:21, 18.18s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.20 ms /   118 runs   (    0.21 ms per token,  4683.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1886.60 ms /    30 tokens (   62.89 ms per token,    15.90 tokens per second)\n",
      "llama_print_timings:        eval time =   19846.85 ms /   117 runs   (  169.63 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   22009.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "9it [02:36, 17.13s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.75 ms /    78 runs   (    0.23 ms per token,  4394.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1973.00 ms /    34 tokens (   58.03 ms per token,    17.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12683.98 ms /    77 runs   (  164.73 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =   14840.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "10it [02:49, 15.95s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.91 ms /    68 runs   (    0.22 ms per token,  4560.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2240.91 ms /    30 tokens (   74.70 ms per token,    13.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10891.12 ms /    67 runs   (  162.55 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   13286.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "11it [03:01, 14.86s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.40 ms /    59 runs   (    0.23 ms per token,  4402.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2730.81 ms /    42 tokens (   65.02 ms per token,    15.38 tokens per second)\n",
      "llama_print_timings:        eval time =    9518.49 ms /    58 runs   (  164.11 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =   12387.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "12it [03:14, 14.32s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.66 ms /    64 runs   (    0.23 ms per token,  4367.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2105.82 ms /    36 tokens (   58.50 ms per token,    17.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10840.56 ms /    63 runs   (  172.07 ms per token,     5.81 tokens per second)\n",
      "llama_print_timings:       total time =   13097.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "13it [03:39, 17.40s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.84 ms /   121 runs   (    0.22 ms per token,  4508.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3677.93 ms /    62 tokens (   59.32 ms per token,    16.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20511.55 ms /   120 runs   (  170.93 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   24488.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "14it [03:57, 17.62s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.28 ms /    97 runs   (    0.22 ms per token,  4558.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1917.19 ms /    30 tokens (   63.91 ms per token,    15.65 tokens per second)\n",
      "llama_print_timings:        eval time =   15974.58 ms /    96 runs   (  166.40 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =   18120.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "15it [04:12, 16.70s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.68 ms /    74 runs   (    0.23 ms per token,  4437.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1930.72 ms /    33 tokens (   58.51 ms per token,    17.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12463.95 ms /    73 runs   (  170.74 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   14569.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "16it [04:21, 14.61s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.09 ms /    49 runs   (    0.23 ms per token,  4417.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1803.77 ms /    30 tokens (   60.13 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =    7836.87 ms /    48 runs   (  163.27 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =    9754.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "17it [04:33, 13.69s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    55 runs   (    0.22 ms per token,  4503.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2506.18 ms /    42 tokens (   59.67 ms per token,    16.76 tokens per second)\n",
      "llama_print_timings:        eval time =    8902.09 ms /    54 runs   (  164.85 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =   11535.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "18it [04:42, 12.25s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    36 runs   (    0.23 ms per token,  4385.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2442.58 ms /    36 tokens (   67.85 ms per token,    14.74 tokens per second)\n",
      "llama_print_timings:        eval time =    6371.47 ms /    35 runs   (  182.04 ms per token,     5.49 tokens per second)\n",
      "llama_print_timings:       total time =    8901.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "19it [05:06, 15.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.97 ms /   122 runs   (    0.22 ms per token,  4524.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3667.07 ms /    62 tokens (   59.15 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =   20384.04 ms /   121 runs   (  168.46 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   24342.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "20it [05:26, 16.95s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.67 ms /   107 runs   (    0.21 ms per token,  4720.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1742.81 ms /    30 tokens (   58.09 ms per token,    17.21 tokens per second)\n",
      "llama_print_timings:        eval time =   17449.24 ms /   106 runs   (  164.62 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =   19440.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "21it [05:41, 16.49s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.47 ms /    79 runs   (    0.22 ms per token,  4521.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2056.91 ms /    34 tokens (   60.50 ms per token,    16.53 tokens per second)\n",
      "llama_print_timings:        eval time =   13177.00 ms /    78 runs   (  168.94 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   15419.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "22it [05:55, 15.83s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.23 ms /    76 runs   (    0.23 ms per token,  4411.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1815.62 ms /    30 tokens (   60.52 ms per token,    16.52 tokens per second)\n",
      "llama_print_timings:        eval time =   12271.88 ms /    75 runs   (  163.63 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   14269.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "23it [06:11, 15.86s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.55 ms /    76 runs   (    0.22 ms per token,  4591.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2509.28 ms /    42 tokens (   59.74 ms per token,    16.74 tokens per second)\n",
      "llama_print_timings:        eval time =   13248.09 ms /    75 runs   (  176.64 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =   15939.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "24it [06:23, 14.64s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    50 runs   (    0.24 ms per token,  4206.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2577.96 ms /    36 tokens (   71.61 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:        eval time =    9074.01 ms /    49 runs   (  185.18 ms per token,     5.40 tokens per second)\n",
      "llama_print_timings:       total time =   11775.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "25it [06:45, 16.80s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.30 ms /   108 runs   (    0.23 ms per token,  4444.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3865.43 ms /    62 tokens (   62.35 ms per token,    16.04 tokens per second)\n",
      "llama_print_timings:        eval time =   17713.34 ms /   107 runs   (  165.55 ms per token,     6.04 tokens per second)\n",
      "llama_print_timings:       total time =   21835.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "26it [06:56, 15.04s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.49 ms /    61 runs   (    0.22 ms per token,  4521.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1787.62 ms /    30 tokens (   59.59 ms per token,    16.78 tokens per second)\n",
      "llama_print_timings:        eval time =    9029.00 ms /    60 runs   (  150.48 ms per token,     6.65 tokens per second)\n",
      "llama_print_timings:       total time =   10952.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "27it [07:12, 15.24s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.03 ms /    87 runs   (    0.23 ms per token,  4343.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1859.76 ms /    33 tokens (   56.36 ms per token,    17.74 tokens per second)\n",
      "llama_print_timings:        eval time =   13628.73 ms /    86 runs   (  158.47 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =   15694.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "28it [07:21, 13.47s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.92 ms /    49 runs   (    0.22 ms per token,  4486.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1909.98 ms /    30 tokens (   63.67 ms per token,    15.71 tokens per second)\n",
      "llama_print_timings:        eval time =    7324.69 ms /    48 runs   (  152.60 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =    9342.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "29it [07:34, 13.28s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.23 ms /    69 runs   (    0.22 ms per token,  4529.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2406.12 ms /    42 tokens (   57.29 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10271.61 ms /    68 runs   (  151.05 ms per token,     6.62 tokens per second)\n",
      "llama_print_timings:       total time =   12834.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "30it [07:44, 12.46s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    51 runs   (    0.23 ms per token,  4376.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2319.02 ms /    36 tokens (   64.42 ms per token,    15.52 tokens per second)\n",
      "llama_print_timings:        eval time =    8095.53 ms /    50 runs   (  161.91 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   10536.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "31it [08:04, 14.76s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.16 ms /   108 runs   (    0.22 ms per token,  4469.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3574.74 ms /    62 tokens (   57.66 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =   16309.37 ms /   107 runs   (  152.42 ms per token,     6.56 tokens per second)\n",
      "llama_print_timings:       total time =   20143.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "32it [08:24, 16.11s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.08 ms /   109 runs   (    0.22 ms per token,  4527.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1723.15 ms /    30 tokens (   57.44 ms per token,    17.41 tokens per second)\n",
      "llama_print_timings:        eval time =   17254.71 ms /   108 runs   (  159.77 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   19234.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "33it [08:38, 15.53s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.50 ms /    76 runs   (    0.23 ms per token,  4343.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1969.41 ms /    34 tokens (   57.92 ms per token,    17.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12054.86 ms /    75 runs   (  160.73 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   14200.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "34it [08:50, 14.48s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.15 ms /    66 runs   (    0.23 ms per token,  4356.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1728.29 ms /    30 tokens (   57.61 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =   10124.13 ms /    65 runs   (  155.76 ms per token,     6.42 tokens per second)\n",
      "llama_print_timings:       total time =   12012.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "35it [09:03, 14.13s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.07 ms /    71 runs   (    0.23 ms per token,  4417.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2461.30 ms /    42 tokens (   58.60 ms per token,    17.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10682.75 ms /    70 runs   (  152.61 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =   13306.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "36it [09:17, 13.89s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.48 ms /    70 runs   (    0.22 ms per token,  4522.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2119.09 ms /    36 tokens (   58.86 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:        eval time =   11049.82 ms /    69 runs   (  160.14 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   13326.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "37it [09:39, 16.50s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.32 ms /   120 runs   (    0.22 ms per token,  4560.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3865.25 ms /    62 tokens (   62.34 ms per token,    16.04 tokens per second)\n",
      "llama_print_timings:        eval time =   18448.04 ms /   119 runs   (  155.03 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:       total time =   22588.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "38it [09:56, 16.74s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.47 ms /   100 runs   (    0.21 ms per token,  4657.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1846.98 ms /    30 tokens (   61.57 ms per token,    16.24 tokens per second)\n",
      "llama_print_timings:        eval time =   15226.00 ms /    99 runs   (  153.80 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:       total time =   17305.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "39it [10:10, 15.91s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.47 ms /    79 runs   (    0.22 ms per token,  4521.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1888.85 ms /    33 tokens (   57.24 ms per token,    17.47 tokens per second)\n",
      "llama_print_timings:        eval time =   11901.95 ms /    78 runs   (  152.59 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =   13970.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "40it [10:23, 14.99s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.88 ms /    69 runs   (    0.23 ms per token,  4346.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2160.33 ms /    30 tokens (   72.01 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10513.57 ms /    68 runs   (  154.61 ms per token,     6.47 tokens per second)\n",
      "llama_print_timings:       total time =   12835.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "41it [10:35, 13.94s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.28 ms /    60 runs   (    0.22 ms per token,  4518.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2417.76 ms /    42 tokens (   57.57 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =    8928.46 ms /    59 runs   (  151.33 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:       total time =   11483.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "42it [10:47, 13.36s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.07 ms /    61 runs   (    0.23 ms per token,  4336.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2054.17 ms /    36 tokens (   57.06 ms per token,    17.53 tokens per second)\n",
      "llama_print_timings:        eval time =    9826.85 ms /    60 runs   (  163.78 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   12021.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "43it [11:08, 15.69s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.68 ms /   108 runs   (    0.22 ms per token,  4560.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3849.11 ms /    62 tokens (   62.08 ms per token,    16.11 tokens per second)\n",
      "llama_print_timings:        eval time =   16999.71 ms /   107 runs   (  158.88 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   21100.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "44it [11:27, 16.72s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.50 ms /   113 runs   (    0.22 ms per token,  4611.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1821.51 ms /    30 tokens (   60.72 ms per token,    16.47 tokens per second)\n",
      "llama_print_timings:        eval time =   17042.70 ms /   112 runs   (  152.17 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =   19124.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "45it [11:42, 16.20s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.91 ms /    80 runs   (    0.22 ms per token,  4467.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2150.73 ms /    34 tokens (   63.26 ms per token,    15.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12648.63 ms /    79 runs   (  160.11 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   14986.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "46it [11:54, 15.04s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.85 ms /    69 runs   (    0.23 ms per token,  4353.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1906.36 ms /    30 tokens (   63.55 ms per token,    15.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10268.05 ms /    68 runs   (  151.00 ms per token,     6.62 tokens per second)\n",
      "llama_print_timings:       total time =   12334.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "47it [12:08, 14.54s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.03 ms /    69 runs   (    0.22 ms per token,  4591.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2389.78 ms /    42 tokens (   56.90 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10821.68 ms /    68 runs   (  159.14 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   13371.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "48it [12:19, 13.73s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.23 ms /    64 runs   (    0.24 ms per token,  4202.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2065.99 ms /    36 tokens (   57.39 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =    9616.32 ms /    63 runs   (  152.64 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =   11831.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "49it [12:42, 16.32s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.19 ms /   118 runs   (    0.22 ms per token,  4505.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3632.15 ms /    62 tokens (   58.58 ms per token,    17.07 tokens per second)\n",
      "llama_print_timings:        eval time =   18448.68 ms /   117 runs   (  157.68 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   22363.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "50it [13:01, 17.29s/it]llama_print_timings:      sample time =      25.63 ms /   116 runs   (    0.22 ms per token,  4525.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1715.61 ms /    30 tokens (   57.19 ms per token,    17.49 tokens per second)\n",
      "llama_print_timings:        eval time =   17580.92 ms /   115 runs   (  152.88 ms per token,     6.54 tokens per second)\n",
      "llama_print_timings:       total time =   19565.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "51it [13:18, 16.94s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.72 ms /    88 runs   (    0.22 ms per token,  4463.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2001.22 ms /    33 tokens (   60.64 ms per token,    16.49 tokens per second)\n",
      "llama_print_timings:        eval time =   13920.33 ms /    87 runs   (  160.00 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   16124.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "52it [13:30, 15.46s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.58 ms /    68 runs   (    0.23 ms per token,  4364.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1682.08 ms /    30 tokens (   56.07 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10167.58 ms /    67 runs   (  151.75 ms per token,     6.59 tokens per second)\n",
      "llama_print_timings:       total time =   12004.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "53it [13:43, 14.80s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.12 ms /    68 runs   (    0.22 ms per token,  4497.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2397.53 ms /    42 tokens (   57.08 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10694.76 ms /    67 runs   (  159.62 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   13248.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "54it [13:52, 13.01s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.00 ms /    43 runs   (    0.23 ms per token,  4300.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2397.07 ms /    36 tokens (   66.59 ms per token,    15.02 tokens per second)\n",
      "llama_print_timings:        eval time =    6353.33 ms /    42 runs   (  151.27 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:       total time =    8844.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "55it [14:12, 15.20s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.14 ms /   104 runs   (    0.22 ms per token,  4494.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3644.89 ms /    62 tokens (   58.79 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:        eval time =   16413.64 ms /   103 runs   (  159.36 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   20305.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "56it [14:22, 13.75s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.56 ms /    57 runs   (    0.22 ms per token,  4539.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1726.25 ms /    30 tokens (   57.54 ms per token,    17.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8514.83 ms /    56 runs   (  152.05 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   10368.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "57it [14:37, 13.90s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.67 ms /    79 runs   (    0.24 ms per token,  4230.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2160.06 ms /    34 tokens (   63.53 ms per token,    15.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11903.53 ms /    78 runs   (  152.61 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =   14251.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "58it [14:51, 14.08s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.49 ms /    80 runs   (    0.22 ms per token,  4573.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1825.56 ms /    30 tokens (   60.85 ms per token,    16.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12467.76 ms /    79 runs   (  157.82 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   14481.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "59it [15:02, 13.15s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.76 ms /    56 runs   (    0.23 ms per token,  4388.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2420.00 ms /    42 tokens (   57.62 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =    8435.00 ms /    55 runs   (  153.36 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:       total time =   10986.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "60it [15:14, 12.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.26 ms /    62 runs   (    0.23 ms per token,  4349.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2263.61 ms /    36 tokens (   62.88 ms per token,    15.90 tokens per second)\n",
      "llama_print_timings:        eval time =    9837.21 ms /    61 runs   (  161.27 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   12249.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "61it [15:28, 13.17s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.59 ms /    65 runs   (    0.22 ms per token,  4454.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3858.62 ms /    67 tokens (   57.59 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =    9828.43 ms /    64 runs   (  153.57 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:       total time =   13837.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "62it [15:48, 15.09s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.08 ms /   111 runs   (    0.22 ms per token,  4609.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1698.12 ms /    30 tokens (   56.60 ms per token,    17.67 tokens per second)\n",
      "llama_print_timings:        eval time =   17602.79 ms /   110 runs   (  160.03 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   19566.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "63it [16:02, 14.71s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.39 ms /    77 runs   (    0.23 ms per token,  4428.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2066.46 ms /    33 tokens (   62.62 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11592.99 ms /    76 runs   (  152.54 ms per token,     6.56 tokens per second)\n",
      "llama_print_timings:       total time =   13835.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "64it [16:13, 13.87s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.44 ms /    62 runs   (    0.23 ms per token,  4293.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1824.79 ms /    30 tokens (   60.83 ms per token,    16.44 tokens per second)\n",
      "llama_print_timings:        eval time =    9915.34 ms /    61 runs   (  162.55 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   11889.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "65it [16:24, 12.90s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    53 runs   (    0.22 ms per token,  4542.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2587.13 ms /    42 tokens (   61.60 ms per token,    16.23 tokens per second)\n",
      "llama_print_timings:        eval time =    7928.25 ms /    52 runs   (  152.47 ms per token,     6.56 tokens per second)\n",
      "llama_print_timings:       total time =   10637.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "66it [16:34, 12.01s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    52 runs   (    0.23 ms per token,  4423.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2084.46 ms /    36 tokens (   57.90 ms per token,    17.27 tokens per second)\n",
      "llama_print_timings:        eval time =    7734.61 ms /    51 runs   (  151.66 ms per token,     6.59 tokens per second)\n",
      "llama_print_timings:       total time =    9934.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "67it [16:53, 14.06s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.59 ms /    93 runs   (    0.22 ms per token,  4516.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3894.95 ms /    62 tokens (   62.82 ms per token,    15.92 tokens per second)\n",
      "llama_print_timings:        eval time =   14721.44 ms /    92 runs   (  160.02 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   18834.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "68it [17:09, 14.79s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.22 ms /    94 runs   (    0.22 ms per token,  4648.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1717.09 ms /    30 tokens (   57.24 ms per token,    17.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14562.89 ms /    93 runs   (  156.59 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =   16500.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "69it [17:25, 15.08s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.55 ms /    83 runs   (    0.22 ms per token,  4473.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2372.24 ms /    34 tokens (   69.77 ms per token,    14.33 tokens per second)\n",
      "llama_print_timings:        eval time =   13183.57 ms /    82 runs   (  160.78 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   15747.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "70it [17:37, 14.20s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.68 ms /    65 runs   (    0.23 ms per token,  4426.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1684.40 ms /    30 tokens (   56.15 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10305.64 ms /    64 runs   (  161.03 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   12141.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "71it [17:48, 13.29s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    56 runs   (    0.23 ms per token,  4374.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2601.29 ms /    42 tokens (   61.94 ms per token,    16.15 tokens per second)\n",
      "llama_print_timings:        eval time =    8421.90 ms /    55 runs   (  153.13 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   11154.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "72it [18:01, 12.96s/it]llama_print_timings:      sample time =      14.96 ms /    67 runs   (    0.22 ms per token,  4478.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2038.10 ms /    36 tokens (   56.61 ms per token,    17.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10005.54 ms /    66 runs   (  151.60 ms per token,     6.60 tokens per second)\n",
      "llama_print_timings:       total time =   12193.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "73it [18:20, 15.03s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.78 ms /   101 runs   (    0.22 ms per token,  4637.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3663.73 ms /    62 tokens (   59.09 ms per token,    16.92 tokens per second)\n",
      "llama_print_timings:        eval time =   15955.11 ms /   100 runs   (  159.55 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   19854.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "74it [18:38, 15.75s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.76 ms /   102 runs   (    0.21 ms per token,  4687.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1705.74 ms /    30 tokens (   56.86 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =   15487.50 ms /   101 runs   (  153.34 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:       total time =   17427.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "75it [18:52, 15.31s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.80 ms /    76 runs   (    0.23 ms per token,  4270.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1943.38 ms /    33 tokens (   58.89 ms per token,    16.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12145.66 ms /    75 runs   (  161.94 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   14273.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "76it [19:04, 14.35s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    66 runs   (    0.23 ms per token,  4399.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1893.43 ms /    30 tokens (   63.11 ms per token,    15.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10072.78 ms /    65 runs   (  154.97 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:       total time =   12121.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "77it [19:13, 12.59s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    38 runs   (    0.23 ms per token,  4406.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2745.56 ms /    42 tokens (   65.37 ms per token,    15.30 tokens per second)\n",
      "llama_print_timings:        eval time =    5649.51 ms /    37 runs   (  152.69 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =    8480.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "78it [19:24, 12.07s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    58 runs   (    0.22 ms per token,  4530.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2111.60 ms /    36 tokens (   58.66 ms per token,    17.05 tokens per second)\n",
      "llama_print_timings:        eval time =    8626.30 ms /    57 runs   (  151.34 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:       total time =   10867.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "79it [19:45, 14.73s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.66 ms /   108 runs   (    0.22 ms per token,  4565.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3736.51 ms /    62 tokens (   60.27 ms per token,    16.59 tokens per second)\n",
      "llama_print_timings:        eval time =   16928.07 ms /   107 runs   (  158.21 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   20918.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "80it [20:04, 16.05s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.38 ms /   112 runs   (    0.22 ms per token,  4593.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1886.40 ms /    30 tokens (   62.88 ms per token,    15.90 tokens per second)\n",
      "llama_print_timings:        eval time =   16981.97 ms /   111 runs   (  152.99 ms per token,     6.54 tokens per second)\n",
      "llama_print_timings:       total time =   19133.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "81it [20:18, 15.44s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.16 ms /    75 runs   (    0.23 ms per token,  4371.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1960.90 ms /    34 tokens (   57.67 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =   11867.24 ms /    74 runs   (  160.37 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   14001.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "82it [20:29, 14.12s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.35 ms /    60 runs   (    0.22 ms per token,  4494.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1969.56 ms /    30 tokens (   65.65 ms per token,    15.23 tokens per second)\n",
      "llama_print_timings:        eval time =    8927.33 ms /    59 runs   (  151.31 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:       total time =   11033.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "83it [20:39, 12.85s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.81 ms /    48 runs   (    0.23 ms per token,  4438.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2588.58 ms /    42 tokens (   61.63 ms per token,    16.23 tokens per second)\n",
      "llama_print_timings:        eval time =    7207.57 ms /    47 runs   (  153.35 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:       total time =    9906.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "84it [20:47, 11.48s/it]llama_print_timings:      sample time =       8.70 ms /    37 runs   (    0.24 ms per token,  4252.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2089.48 ms /    36 tokens (   58.04 ms per token,    17.23 tokens per second)\n",
      "llama_print_timings:        eval time =    6080.59 ms /    36 runs   (  168.91 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =    8261.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "85it [21:10, 14.82s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.14 ms /   121 runs   (    0.22 ms per token,  4628.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3499.41 ms /    62 tokens (   56.44 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =   18830.46 ms /   120 runs   (  156.92 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =   22607.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "86it [21:30, 16.38s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.29 ms /   117 runs   (    0.22 ms per token,  4626.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2097.38 ms /    30 tokens (   69.91 ms per token,    14.30 tokens per second)\n",
      "llama_print_timings:        eval time =   17640.91 ms /   116 runs   (  152.08 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   20011.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "87it [21:44, 15.72s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.41 ms /    77 runs   (    0.23 ms per token,  4421.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1904.86 ms /    33 tokens (   57.72 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12091.80 ms /    76 runs   (  159.10 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   14176.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "88it [21:57, 14.92s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.71 ms /    75 runs   (    0.22 ms per token,  4488.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1705.26 ms /    30 tokens (   56.84 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =   11190.67 ms /    74 runs   (  151.23 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:       total time =   13065.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "89it [22:06, 13.29s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.48 ms /    46 runs   (    0.23 ms per token,  4389.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2519.02 ms /    42 tokens (   59.98 ms per token,    16.67 tokens per second)\n",
      "llama_print_timings:        eval time =    6839.54 ms /    45 runs   (  151.99 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =    9467.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "90it [22:18, 12.86s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.73 ms /    60 runs   (    0.23 ms per token,  4368.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2154.30 ms /    36 tokens (   59.84 ms per token,    16.71 tokens per second)\n",
      "llama_print_timings:        eval time =    9570.05 ms /    59 runs   (  162.20 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   11863.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "91it [22:38, 14.96s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.38 ms /   103 runs   (    0.22 ms per token,  4601.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3524.83 ms /    62 tokens (   56.85 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =   16103.31 ms /   102 runs   (  157.88 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   19864.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "92it [22:55, 15.54s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.30 ms /    99 runs   (    0.22 ms per token,  4647.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1759.29 ms /    30 tokens (   58.64 ms per token,    17.05 tokens per second)\n",
      "llama_print_timings:        eval time =   14899.66 ms /    98 runs   (  152.04 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   16887.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "93it [23:09, 15.24s/it]llama_print_timings:      sample time =      17.42 ms /    76 runs   (    0.23 ms per token,  4363.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2240.72 ms /    34 tokens (   65.90 ms per token,    15.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12104.90 ms /    75 runs   (  161.40 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   14522.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "94it [23:24, 14.93s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.68 ms /    80 runs   (    0.22 ms per token,  4525.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1941.42 ms /    30 tokens (   64.71 ms per token,    15.45 tokens per second)\n",
      "llama_print_timings:        eval time =   12098.71 ms /    79 runs   (  153.15 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   14218.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "95it [23:37, 14.34s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.34 ms /    69 runs   (    0.22 ms per token,  4497.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2401.53 ms /    42 tokens (   57.18 ms per token,    17.49 tokens per second)\n",
      "llama_print_timings:        eval time =   10408.72 ms /    68 runs   (  153.07 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   12971.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "96it [23:48, 13.44s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.36 ms /    58 runs   (    0.23 ms per token,  4340.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2102.41 ms /    36 tokens (   58.40 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:        eval time =    9088.12 ms /    57 runs   (  159.44 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   11322.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "97it [24:11, 16.23s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.77 ms /   121 runs   (    0.22 ms per token,  4520.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3541.48 ms /    62 tokens (   57.12 ms per token,    17.51 tokens per second)\n",
      "llama_print_timings:        eval time =   18906.54 ms /   120 runs   (  157.55 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   22733.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "98it [24:30, 17.05s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.31 ms /   112 runs   (    0.22 ms per token,  4607.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1764.94 ms /    30 tokens (   58.83 ms per token,    17.00 tokens per second)\n",
      "llama_print_timings:        eval time =   16954.86 ms /   111 runs   (  152.75 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =   18979.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "99it [24:43, 16.08s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.80 ms /    74 runs   (    0.23 ms per token,  4405.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1883.25 ms /    33 tokens (   57.07 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11744.49 ms /    73 runs   (  160.88 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   13796.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "100it [24:55, 14.80s/it]llama_print_timings:      sample time =      14.88 ms /    67 runs   (    0.22 ms per token,  4503.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1690.18 ms /    30 tokens (   56.34 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =    9985.55 ms /    66 runs   (  151.30 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:       total time =   11827.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "101it [25:07, 14.00s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.23 ms /    63 runs   (    0.23 ms per token,  4426.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2447.03 ms /    42 tokens (   58.26 ms per token,    17.16 tokens per second)\n",
      "llama_print_timings:        eval time =    9527.43 ms /    62 runs   (  153.67 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:       total time =   12117.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "102it [25:19, 13.17s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    56 runs   (    0.23 ms per token,  4335.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2064.25 ms /    36 tokens (   57.34 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =    9028.76 ms /    55 runs   (  164.16 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =   11222.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "103it [25:41, 16.05s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.07 ms /   121 runs   (    0.22 ms per token,  4641.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3543.68 ms /    62 tokens (   57.16 ms per token,    17.50 tokens per second)\n",
      "llama_print_timings:        eval time =   18947.04 ms /   120 runs   (  157.89 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   22773.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "104it [25:58, 16.32s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.14 ms /    99 runs   (    0.21 ms per token,  4681.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1690.58 ms /    30 tokens (   56.35 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =   15042.38 ms /    98 runs   (  153.49 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:       total time =   16957.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "105it [26:13, 15.95s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.03 ms /    82 runs   (    0.22 ms per token,  4548.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1979.41 ms /    34 tokens (   58.22 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12894.49 ms /    81 runs   (  159.19 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   15065.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "106it [26:25, 14.70s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.34 ms /    66 runs   (    0.23 ms per token,  4303.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1694.56 ms /    30 tokens (   56.49 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =    9937.31 ms /    65 runs   (  152.88 ms per token,     6.54 tokens per second)\n",
      "llama_print_timings:       total time =   11784.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "107it [26:38, 14.03s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.33 ms /    66 runs   (    0.22 ms per token,  4604.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2402.23 ms /    42 tokens (   57.20 ms per token,    17.48 tokens per second)\n",
      "llama_print_timings:        eval time =    9928.38 ms /    65 runs   (  152.74 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =   12477.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "108it [26:50, 13.67s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.49 ms /    66 runs   (    0.23 ms per token,  4262.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2116.84 ms /    36 tokens (   58.80 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10545.63 ms /    65 runs   (  162.24 ms per token,     6.16 tokens per second)\n",
      "llama_print_timings:       total time =   12818.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "109it [27:12, 16.01s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.50 ms /   113 runs   (    0.22 ms per token,  4612.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4035.72 ms /    62 tokens (   65.09 ms per token,    15.36 tokens per second)\n",
      "llama_print_timings:        eval time =   17176.67 ms /   112 runs   (  153.36 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:       total time =   21474.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "110it [27:30, 16.76s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.37 ms /   109 runs   (    0.21 ms per token,  4664.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1785.29 ms /    30 tokens (   59.51 ms per token,    16.80 tokens per second)\n",
      "llama_print_timings:        eval time =   16454.01 ms /   108 runs   (  152.35 ms per token,     6.56 tokens per second)\n",
      "llama_print_timings:       total time =   18491.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "111it [27:46, 16.26s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.42 ms /    78 runs   (    0.22 ms per token,  4477.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2014.95 ms /    33 tokens (   61.06 ms per token,    16.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12901.44 ms /    77 runs   (  167.55 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   15094.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "112it [27:56, 14.44s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    55 runs   (    0.23 ms per token,  4298.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1876.28 ms /    30 tokens (   62.54 ms per token,    15.99 tokens per second)\n",
      "llama_print_timings:        eval time =    8181.55 ms /    54 runs   (  151.51 ms per token,     6.60 tokens per second)\n",
      "llama_print_timings:       total time =   10185.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "113it [28:10, 14.50s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.33 ms /    74 runs   (    0.22 ms per token,  4532.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2667.57 ms /    42 tokens (   63.51 ms per token,    15.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11798.75 ms /    73 runs   (  161.63 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =   14641.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "114it [28:21, 13.46s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.24 ms /    59 runs   (    0.22 ms per token,  4454.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2078.96 ms /    36 tokens (   57.75 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =    8818.29 ms /    58 runs   (  152.04 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   11029.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "115it [28:43, 15.97s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.03 ms /   114 runs   (    0.22 ms per token,  4555.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3546.81 ms /    62 tokens (   57.21 ms per token,    17.48 tokens per second)\n",
      "llama_print_timings:        eval time =   18015.17 ms /   113 runs   (  159.43 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   21831.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "116it [28:54, 14.36s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    58 runs   (    0.21 ms per token,  4689.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1725.46 ms /    30 tokens (   57.52 ms per token,    17.39 tokens per second)\n",
      "llama_print_timings:        eval time =    8752.26 ms /    57 runs   (  153.55 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:       total time =   10608.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "117it [29:10, 14.80s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.76 ms /    90 runs   (    0.23 ms per token,  4335.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2005.39 ms /    34 tokens (   58.98 ms per token,    16.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13609.24 ms /    89 runs   (  152.91 ms per token,     6.54 tokens per second)\n",
      "llama_print_timings:       total time =   15829.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "118it [29:22, 14.03s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.47 ms /    65 runs   (    0.22 ms per token,  4492.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1803.93 ms /    30 tokens (   60.13 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10284.85 ms /    64 runs   (  160.70 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   12238.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "119it [29:36, 14.18s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.27 ms /    75 runs   (    0.23 ms per token,  4342.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2563.29 ms /    42 tokens (   61.03 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11794.14 ms /    74 runs   (  159.38 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   14531.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "120it [29:45, 12.56s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       9.99 ms /    44 runs   (    0.23 ms per token,  4403.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2128.93 ms /    36 tokens (   59.14 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6541.41 ms /    43 runs   (  152.13 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =    8772.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "121it [30:06, 14.96s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.35 ms /   109 runs   (    0.22 ms per token,  4477.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3858.67 ms /    67 tokens (   57.59 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =   16447.60 ms /   108 runs   (  152.29 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =   20569.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "122it [30:26, 16.60s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.22 ms /   117 runs   (    0.22 ms per token,  4639.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2072.18 ms /    30 tokens (   69.07 ms per token,    14.48 tokens per second)\n",
      "llama_print_timings:        eval time =   18064.58 ms /   116 runs   (  155.73 ms per token,     6.42 tokens per second)\n",
      "llama_print_timings:       total time =   20409.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "123it [30:41, 16.00s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.39 ms /    80 runs   (    0.23 ms per token,  4351.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1984.64 ms /    33 tokens (   60.14 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12432.20 ms /    79 runs   (  157.37 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   14602.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "124it [30:56, 15.91s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.16 ms /    91 runs   (    0.22 ms per token,  4514.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1869.69 ms /    30 tokens (   62.32 ms per token,    16.05 tokens per second)\n",
      "llama_print_timings:        eval time =   13606.02 ms /    90 runs   (  151.18 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:       total time =   15684.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "125it [31:10, 15.11s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.79 ms /    66 runs   (    0.22 ms per token,  4463.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2561.75 ms /    42 tokens (   60.99 ms per token,    16.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10548.41 ms /    65 runs   (  162.28 ms per token,     6.16 tokens per second)\n",
      "llama_print_timings:       total time =   13265.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "126it [31:23, 14.44s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.13 ms /    72 runs   (    0.22 ms per token,  4463.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2041.49 ms /    36 tokens (   56.71 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10667.27 ms /    71 runs   (  150.24 ms per token,     6.66 tokens per second)\n",
      "llama_print_timings:       total time =   12876.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "127it [31:47, 17.28s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.47 ms /   125 runs   (    0.21 ms per token,  4722.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3989.54 ms /    62 tokens (   64.35 ms per token,    15.54 tokens per second)\n",
      "llama_print_timings:        eval time =   19613.46 ms /   124 runs   (  158.17 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   23891.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "128it [32:03, 17.12s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.50 ms /    98 runs   (    0.22 ms per token,  4558.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1742.52 ms /    30 tokens (   58.08 ms per token,    17.22 tokens per second)\n",
      "llama_print_timings:        eval time =   14789.75 ms /    97 runs   (  152.47 ms per token,     6.56 tokens per second)\n",
      "llama_print_timings:       total time =   16761.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "129it [32:17, 16.23s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.12 ms /    76 runs   (    0.23 ms per token,  4438.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1936.45 ms /    34 tokens (   56.95 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12017.18 ms /    75 runs   (  160.23 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   14130.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "130it [32:33, 15.93s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.65 ms /    88 runs   (    0.22 ms per token,  4477.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1698.85 ms /    30 tokens (   56.63 ms per token,    17.66 tokens per second)\n",
      "llama_print_timings:        eval time =   13324.55 ms /    87 runs   (  153.16 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   15230.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "131it [32:46, 15.23s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    67 runs   (    0.22 ms per token,  4467.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2603.41 ms /    42 tokens (   61.99 ms per token,    16.13 tokens per second)\n",
      "llama_print_timings:        eval time =   10848.55 ms /    66 runs   (  164.37 ms per token,     6.08 tokens per second)\n",
      "llama_print_timings:       total time =   13609.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "132it [32:57, 13.98s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    59 runs   (    0.23 ms per token,  4432.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2128.87 ms /    36 tokens (   59.14 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =    8794.72 ms /    58 runs   (  151.63 ms per token,     6.59 tokens per second)\n",
      "llama_print_timings:       total time =   11059.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "133it [33:19, 16.24s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.59 ms /   112 runs   (    0.23 ms per token,  4377.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3508.57 ms /    62 tokens (   56.59 ms per token,    17.67 tokens per second)\n",
      "llama_print_timings:        eval time =   17714.42 ms /   111 runs   (  159.59 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   21494.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "134it [33:30, 14.75s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.91 ms /    62 runs   (    0.22 ms per token,  4458.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1869.09 ms /    30 tokens (   62.30 ms per token,    16.05 tokens per second)\n",
      "llama_print_timings:        eval time =    9277.10 ms /    61 runs   (  152.08 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   11289.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "135it [33:44, 14.58s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.95 ms /    76 runs   (    0.22 ms per token,  4482.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2003.94 ms /    33 tokens (   60.73 ms per token,    16.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12010.47 ms /    75 runs   (  160.14 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   14188.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "136it [33:56, 13.85s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.59 ms /    68 runs   (    0.23 ms per token,  4361.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1703.26 ms /    30 tokens (   56.78 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10265.96 ms /    67 runs   (  153.22 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   12129.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "137it [34:08, 13.11s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    56 runs   (    0.22 ms per token,  4510.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2379.82 ms /    42 tokens (   56.66 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =    8861.59 ms /    55 runs   (  161.12 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   11373.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "138it [34:20, 12.73s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.51 ms /    63 runs   (    0.23 ms per token,  4343.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2287.92 ms /    36 tokens (   63.55 ms per token,    15.73 tokens per second)\n",
      "llama_print_timings:        eval time =    9424.42 ms /    62 runs   (  152.01 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   11861.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "139it [34:40, 15.02s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.33 ms /   106 runs   (    0.22 ms per token,  4543.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3526.52 ms /    62 tokens (   56.88 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   16589.13 ms /   105 runs   (  157.99 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   20369.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "140it [34:59, 16.34s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.65 ms /   113 runs   (    0.22 ms per token,  4583.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1938.17 ms /    30 tokens (   64.61 ms per token,    15.48 tokens per second)\n",
      "llama_print_timings:        eval time =   17193.57 ms /   112 runs   (  153.51 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:       total time =   19400.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "141it [35:15, 16.14s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.94 ms /    84 runs   (    0.23 ms per token,  4434.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2213.02 ms /    34 tokens (   65.09 ms per token,    15.36 tokens per second)\n",
      "llama_print_timings:        eval time =   13254.83 ms /    83 runs   (  159.70 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   15660.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "142it [35:25, 14.18s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    52 runs   (    0.24 ms per token,  4249.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1709.71 ms /    30 tokens (   56.99 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =    7782.37 ms /    51 runs   (  152.60 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =    9611.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "143it [35:38, 13.98s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.43 ms /    70 runs   (    0.22 ms per token,  4537.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2391.82 ms /    42 tokens (   56.95 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   10970.03 ms /    69 runs   (  158.99 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   13524.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "144it [35:50, 13.46s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.24 ms /    67 runs   (    0.23 ms per token,  4395.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2105.70 ms /    36 tokens (   58.49 ms per token,    17.10 tokens per second)\n",
      "llama_print_timings:        eval time =    9972.32 ms /    66 runs   (  151.10 ms per token,     6.62 tokens per second)\n",
      "llama_print_timings:       total time =   12232.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "145it [36:11, 15.68s/it]llama_print_timings:      sample time =      24.31 ms /   109 runs   (    0.22 ms per token,  4484.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3539.07 ms /    62 tokens (   57.08 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   17067.96 ms /   108 runs   (  158.04 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   20867.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "146it [36:29, 16.27s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.06 ms /   103 runs   (    0.22 ms per token,  4466.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1869.08 ms /    30 tokens (   62.30 ms per token,    16.05 tokens per second)\n",
      "llama_print_timings:        eval time =   15546.15 ms /   102 runs   (  152.41 ms per token,     6.56 tokens per second)\n",
      "llama_print_timings:       total time =   17654.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "147it [36:43, 15.60s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.23 ms /    77 runs   (    0.22 ms per token,  4468.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2228.79 ms /    33 tokens (   67.54 ms per token,    14.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11616.31 ms /    76 runs   (  152.85 ms per token,     6.54 tokens per second)\n",
      "llama_print_timings:       total time =   14020.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "148it [36:55, 14.57s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.47 ms /    68 runs   (    0.23 ms per token,  4395.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1826.86 ms /    30 tokens (   60.90 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =   10192.98 ms /    67 runs   (  152.13 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =   12174.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "149it [37:09, 14.23s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.83 ms /    68 runs   (    0.23 ms per token,  4295.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2475.23 ms /    42 tokens (   58.93 ms per token,    16.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10776.24 ms /    67 runs   (  160.84 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   13424.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "150it [37:19, 13.07s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    53 runs   (    0.23 ms per token,  4319.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2347.83 ms /    36 tokens (   65.22 ms per token,    15.33 tokens per second)\n",
      "llama_print_timings:        eval time =    7893.99 ms /    52 runs   (  151.81 ms per token,     6.59 tokens per second)\n",
      "llama_print_timings:       total time =   10364.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "151it [37:41, 15.64s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.88 ms /   117 runs   (    0.22 ms per token,  4521.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3545.36 ms /    62 tokens (   57.18 ms per token,    17.49 tokens per second)\n",
      "llama_print_timings:        eval time =   17803.43 ms /   116 runs   (  153.48 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:       total time =   21626.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "152it [37:58, 16.16s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.40 ms /   101 runs   (    0.22 ms per token,  4508.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1916.30 ms /    30 tokens (   63.88 ms per token,    15.66 tokens per second)\n",
      "llama_print_timings:        eval time =   15218.85 ms /   100 runs   (  152.19 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =   17373.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "153it [38:13, 15.71s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.14 ms /    79 runs   (    0.23 ms per token,  4355.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1961.43 ms /    34 tokens (   57.69 ms per token,    17.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12512.79 ms /    78 runs   (  160.42 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:       total time =   14657.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "154it [38:28, 15.68s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.44 ms /    89 runs   (    0.23 ms per token,  4355.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2033.98 ms /    30 tokens (   67.80 ms per token,    14.75 tokens per second)\n",
      "llama_print_timings:        eval time =   13381.59 ms /    88 runs   (  152.06 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   15623.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "155it [38:36, 13.40s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    34 runs   (    0.23 ms per token,  4425.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2395.96 ms /    42 tokens (   57.05 ms per token,    17.53 tokens per second)\n",
      "llama_print_timings:        eval time =    5589.84 ms /    33 runs   (  169.39 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =    8066.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "156it [38:48, 12.84s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.29 ms /    61 runs   (    0.23 ms per token,  4267.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2250.84 ms /    36 tokens (   62.52 ms per token,    15.99 tokens per second)\n",
      "llama_print_timings:        eval time =    9141.77 ms /    60 runs   (  152.36 ms per token,     6.56 tokens per second)\n",
      "llama_print_timings:       total time =   11536.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "157it [39:09, 15.34s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.16 ms /   110 runs   (    0.22 ms per token,  4553.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3525.92 ms /    62 tokens (   56.87 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   17382.92 ms /   109 runs   (  159.48 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   21173.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "158it [39:28, 16.51s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.21 ms /   113 runs   (    0.21 ms per token,  4667.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1735.53 ms /    30 tokens (   57.85 ms per token,    17.29 tokens per second)\n",
      "llama_print_timings:        eval time =   17222.67 ms /   112 runs   (  153.77 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:       total time =   19224.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "159it [39:43, 16.06s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.18 ms /    80 runs   (    0.23 ms per token,  4401.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2113.50 ms /    33 tokens (   64.05 ms per token,    15.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12707.03 ms /    79 runs   (  160.85 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   15009.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "160it [39:56, 14.97s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.16 ms /    70 runs   (    0.23 ms per token,  4332.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1763.11 ms /    30 tokens (   58.77 ms per token,    17.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10505.68 ms /    69 runs   (  152.26 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =   12433.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "161it [40:04, 13.02s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    38 runs   (    0.22 ms per token,  4542.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2464.52 ms /    42 tokens (   58.68 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =    5930.35 ms /    37 runs   (  160.28 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =    8481.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "162it [40:18, 13.24s/it]llama_print_timings:      sample time =      17.03 ms /    76 runs   (    0.22 ms per token,  4461.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2134.28 ms /    36 tokens (   59.29 ms per token,    16.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11418.87 ms /    75 runs   (  152.25 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =   13731.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "163it [40:32, 13.35s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.68 ms /    65 runs   (    0.23 ms per token,  4429.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3551.52 ms /    62 tokens (   57.28 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =    9908.78 ms /    64 runs   (  154.82 ms per token,     6.46 tokens per second)\n",
      "llama_print_timings:       total time =   13616.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "164it [40:50, 14.73s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.39 ms /   102 runs   (    0.22 ms per token,  4556.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1735.73 ms /    30 tokens (   57.86 ms per token,    17.28 tokens per second)\n",
      "llama_print_timings:        eval time =   15958.91 ms /   101 runs   (  158.01 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   17939.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "165it [41:04, 14.77s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.16 ms /    84 runs   (    0.23 ms per token,  4384.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1958.04 ms /    34 tokens (   57.59 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =   12718.47 ms /    83 runs   (  153.23 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   14877.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "166it [41:20, 15.11s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.40 ms /    89 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1700.14 ms /    30 tokens (   56.67 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   13990.83 ms /    88 runs   (  158.99 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   15899.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "167it [41:33, 14.29s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.55 ms /    64 runs   (    0.23 ms per token,  4399.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2671.46 ms /    42 tokens (   63.61 ms per token,    15.72 tokens per second)\n",
      "llama_print_timings:        eval time =    9556.74 ms /    63 runs   (  151.69 ms per token,     6.59 tokens per second)\n",
      "llama_print_timings:       total time =   12379.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "168it [41:46, 14.02s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.19 ms /    71 runs   (    0.23 ms per token,  4385.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2363.22 ms /    36 tokens (   65.65 ms per token,    15.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10838.96 ms /    70 runs   (  154.84 ms per token,     6.46 tokens per second)\n",
      "llama_print_timings:       total time =   13368.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "169it [42:08, 16.28s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.33 ms /   117 runs   (    0.22 ms per token,  4619.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3540.51 ms /    62 tokens (   57.11 ms per token,    17.51 tokens per second)\n",
      "llama_print_timings:        eval time =   17752.61 ms /   116 runs   (  153.04 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   21568.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "170it [42:26, 16.89s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.73 ms /   103 runs   (    0.22 ms per token,  4531.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2435.76 ms /    30 tokens (   81.19 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:        eval time =   15614.12 ms /   102 runs   (  153.08 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   18294.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "171it [42:39, 15.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.99 ms /    75 runs   (    0.23 ms per token,  4413.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1949.68 ms /    33 tokens (   59.08 ms per token,    16.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11407.62 ms /    74 runs   (  154.16 ms per token,     6.49 tokens per second)\n",
      "llama_print_timings:       total time =   13536.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "172it [42:52, 14.98s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.61 ms /    69 runs   (    0.23 ms per token,  4419.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1791.92 ms /    30 tokens (   59.73 ms per token,    16.74 tokens per second)\n",
      "llama_print_timings:        eval time =   10917.19 ms /    68 runs   (  160.55 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:       total time =   12871.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "173it [43:04, 13.97s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.19 ms /    58 runs   (    0.23 ms per token,  4396.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2801.20 ms /    42 tokens (   66.70 ms per token,    14.99 tokens per second)\n",
      "llama_print_timings:        eval time =    8684.70 ms /    57 runs   (  152.36 ms per token,     6.56 tokens per second)\n",
      "llama_print_timings:       total time =   11620.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "174it [43:16, 13.53s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.83 ms /    62 runs   (    0.22 ms per token,  4484.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3122.16 ms /    36 tokens (   86.73 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:        eval time =    9244.80 ms /    61 runs   (  151.55 ms per token,     6.60 tokens per second)\n",
      "llama_print_timings:       total time =   12508.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "175it [43:37, 15.58s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.90 ms /   105 runs   (    0.22 ms per token,  4585.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4041.34 ms /    62 tokens (   65.18 ms per token,    15.34 tokens per second)\n",
      "llama_print_timings:        eval time =   16081.93 ms /   104 runs   (  154.63 ms per token,     6.47 tokens per second)\n",
      "llama_print_timings:       total time =   20368.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "176it [43:55, 16.39s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.93 ms /   106 runs   (    0.22 ms per token,  4622.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1858.93 ms /    30 tokens (   61.96 ms per token,    16.14 tokens per second)\n",
      "llama_print_timings:        eval time =   16144.11 ms /   105 runs   (  153.75 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:       total time =   18255.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "177it [44:09, 15.59s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.49 ms /    76 runs   (    0.23 ms per token,  4345.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2074.30 ms /    34 tokens (   61.01 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:        eval time =   11480.48 ms /    75 runs   (  153.07 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   13732.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "178it [44:22, 14.91s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.74 ms /    73 runs   (    0.23 ms per token,  4359.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1912.16 ms /    30 tokens (   63.74 ms per token,    15.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11228.22 ms /    72 runs   (  155.95 ms per token,     6.41 tokens per second)\n",
      "llama_print_timings:       total time =   13309.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "179it [44:33, 13.77s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    56 runs   (    0.22 ms per token,  4584.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2407.03 ms /    42 tokens (   57.31 ms per token,    17.45 tokens per second)\n",
      "llama_print_timings:        eval time =    8566.64 ms /    55 runs   (  155.76 ms per token,     6.42 tokens per second)\n",
      "llama_print_timings:       total time =   11101.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "180it [44:47, 13.80s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.17 ms /    72 runs   (    0.22 ms per token,  4453.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2771.00 ms /    36 tokens (   76.97 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:        eval time =   10928.16 ms /    71 runs   (  153.92 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:       total time =   13867.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "181it [45:10, 16.47s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.53 ms /   119 runs   (    0.22 ms per token,  4485.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3952.22 ms /    69 tokens (   57.28 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   18470.27 ms /   118 runs   (  156.53 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =   22698.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "182it [45:28, 17.03s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.37 ms /   108 runs   (    0.22 ms per token,  4621.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1824.06 ms /    30 tokens (   60.80 ms per token,    16.45 tokens per second)\n",
      "llama_print_timings:        eval time =   16250.46 ms /   107 runs   (  151.87 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   18328.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "183it [45:42, 16.19s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.57 ms /    77 runs   (    0.23 ms per token,  4382.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2186.61 ms /    33 tokens (   66.26 ms per token,    15.09 tokens per second)\n",
      "llama_print_timings:        eval time =   11867.05 ms /    76 runs   (  156.15 ms per token,     6.40 tokens per second)\n",
      "llama_print_timings:       total time =   14239.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "184it [45:55, 15.00s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.37 ms /    67 runs   (    0.23 ms per token,  4359.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2103.31 ms /    30 tokens (   70.11 ms per token,    14.26 tokens per second)\n",
      "llama_print_timings:        eval time =    9960.43 ms /    66 runs   (  150.92 ms per token,     6.63 tokens per second)\n",
      "llama_print_timings:       total time =   12223.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "185it [46:09, 14.68s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.29 ms /    72 runs   (    0.23 ms per token,  4420.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2382.55 ms /    42 tokens (   56.73 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11360.83 ms /    71 runs   (  160.01 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   13915.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "186it [46:21, 13.87s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    62 runs   (    0.23 ms per token,  4408.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2600.83 ms /    32 tokens (   81.28 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:        eval time =    9259.24 ms /    61 runs   (  151.79 ms per token,     6.59 tokens per second)\n",
      "llama_print_timings:       total time =   12001.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "187it [46:43, 16.41s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.07 ms /   118 runs   (    0.22 ms per token,  4525.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3528.66 ms /    62 tokens (   56.91 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   18511.44 ms /   117 runs   (  158.22 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   22320.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "188it [47:03, 17.49s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.63 ms /   118 runs   (    0.22 ms per token,  4603.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1903.71 ms /    30 tokens (   63.46 ms per token,    15.76 tokens per second)\n",
      "llama_print_timings:        eval time =   17833.91 ms /   117 runs   (  152.43 ms per token,     6.56 tokens per second)\n",
      "llama_print_timings:       total time =   20011.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "189it [47:17, 16.56s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.46 ms /    77 runs   (    0.23 ms per token,  4411.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2035.97 ms /    34 tokens (   59.88 ms per token,    16.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12180.33 ms /    76 runs   (  160.27 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   14397.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "190it [47:29, 15.17s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.05 ms /    67 runs   (    0.22 ms per token,  4451.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1723.90 ms /    30 tokens (   57.46 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10029.83 ms /    66 runs   (  151.97 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   11907.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "191it [47:43, 14.90s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.82 ms /    73 runs   (    0.23 ms per token,  4339.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2372.34 ms /    42 tokens (   56.48 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =   11713.38 ms /    72 runs   (  162.69 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   14261.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "192it [47:54, 13.47s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    55 runs   (    0.23 ms per token,  4417.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1837.40 ms /    32 tokens (   57.42 ms per token,    17.42 tokens per second)\n",
      "llama_print_timings:        eval time =    8179.48 ms /    54 runs   (  151.47 ms per token,     6.60 tokens per second)\n",
      "llama_print_timings:       total time =   10142.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "193it [48:13, 15.40s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.96 ms /   103 runs   (    0.22 ms per token,  4485.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3602.98 ms /    62 tokens (   58.11 ms per token,    17.21 tokens per second)\n",
      "llama_print_timings:        eval time =   16050.59 ms /   102 runs   (  157.36 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   19896.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "194it [48:31, 16.14s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.73 ms /   104 runs   (    0.22 ms per token,  4575.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1824.76 ms /    30 tokens (   60.83 ms per token,    16.44 tokens per second)\n",
      "llama_print_timings:        eval time =   15798.43 ms /   103 runs   (  153.38 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:       total time =   17873.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "195it [48:45, 15.48s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.16 ms /    76 runs   (    0.23 ms per token,  4429.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1883.48 ms /    33 tokens (   57.08 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11864.34 ms /    75 runs   (  158.19 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   13922.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "196it [48:59, 15.07s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.35 ms /    81 runs   (    0.23 ms per token,  4414.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1760.70 ms /    30 tokens (   58.69 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12183.93 ms /    80 runs   (  152.30 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =   14135.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "197it [49:14, 15.03s/it]llama_print_timings:      sample time =      17.71 ms /    77 runs   (    0.23 ms per token,  4347.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2410.95 ms /    42 tokens (   57.40 ms per token,    17.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12326.85 ms /    76 runs   (  162.20 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   14921.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "198it [49:25, 13.74s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.33 ms /    58 runs   (    0.23 ms per token,  4351.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1924.92 ms /    32 tokens (   60.15 ms per token,    16.62 tokens per second)\n",
      "llama_print_timings:        eval time =    8663.61 ms /    57 runs   (  151.99 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   10727.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "199it [49:47, 16.31s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.16 ms /   118 runs   (    0.23 ms per token,  4343.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3541.03 ms /    62 tokens (   57.11 ms per token,    17.51 tokens per second)\n",
      "llama_print_timings:        eval time =   18474.53 ms /   117 runs   (  157.90 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   22308.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "200it [50:09, 17.99s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.21 ms /   116 runs   (    0.22 ms per token,  4601.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1805.73 ms /    30 tokens (   60.19 ms per token,    16.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19808.29 ms /   115 runs   (  172.25 ms per token,     5.81 tokens per second)\n",
      "llama_print_timings:       total time =   21896.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "201it [50:23, 16.59s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.99 ms /    73 runs   (    0.23 ms per token,  4295.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2212.22 ms /    34 tokens (   65.07 ms per token,    15.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10950.46 ms /    72 runs   (  152.09 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   13339.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "202it [50:31, 14.08s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    43 runs   (    0.24 ms per token,  4244.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1700.78 ms /    30 tokens (   56.69 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6412.88 ms /    42 runs   (  152.69 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =    8214.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "203it [50:46, 14.27s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.62 ms /    77 runs   (    0.23 ms per token,  4371.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2428.42 ms /    42 tokens (   57.82 ms per token,    17.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12105.12 ms /    76 runs   (  159.28 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   14714.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "204it [50:57, 13.44s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.18 ms /    63 runs   (    0.23 ms per token,  4441.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1989.81 ms /    32 tokens (   62.18 ms per token,    16.08 tokens per second)\n",
      "llama_print_timings:        eval time =    9374.87 ms /    62 runs   (  151.21 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:       total time =   11511.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "205it [51:19, 16.09s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.58 ms /   116 runs   (    0.22 ms per token,  4535.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3798.75 ms /    62 tokens (   61.27 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:        eval time =   18200.67 ms /   115 runs   (  158.27 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   22275.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "206it [51:38, 16.73s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.51 ms /   108 runs   (    0.22 ms per token,  4593.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1718.88 ms /    30 tokens (   57.30 ms per token,    17.45 tokens per second)\n",
      "llama_print_timings:        eval time =   16254.35 ms /   107 runs   (  151.91 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   18227.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "207it [51:51, 15.83s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.45 ms /    77 runs   (    0.23 ms per token,  4413.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1992.34 ms /    33 tokens (   60.37 ms per token,    16.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11553.09 ms /    76 runs   (  152.01 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =   13725.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "208it [52:06, 15.49s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.22 ms /    81 runs   (    0.22 ms per token,  4446.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1704.72 ms /    30 tokens (   56.82 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =   12776.39 ms /    80 runs   (  159.70 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   14675.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "209it [52:19, 14.61s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.05 ms /    67 runs   (    0.22 ms per token,  4453.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2443.78 ms /    42 tokens (   58.19 ms per token,    17.19 tokens per second)\n",
      "llama_print_timings:        eval time =    9983.34 ms /    66 runs   (  151.26 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:       total time =   12579.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "210it [52:28, 13.02s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.29 ms /    50 runs   (    0.23 ms per token,  4429.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1806.32 ms /    32 tokens (   56.45 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =    7386.70 ms /    49 runs   (  150.75 ms per token,     6.63 tokens per second)\n",
      "llama_print_timings:       total time =    9305.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "211it [52:50, 15.73s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.58 ms /   117 runs   (    0.22 ms per token,  4574.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3513.92 ms /    62 tokens (   56.68 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =   18249.93 ms /   116 runs   (  157.33 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   22036.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "212it [53:02, 14.71s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.63 ms /    68 runs   (    0.22 ms per token,  4647.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2037.37 ms /    30 tokens (   67.91 ms per token,    14.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10158.94 ms /    67 runs   (  151.63 ms per token,     6.60 tokens per second)\n",
      "llama_print_timings:       total time =   12350.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "213it [53:17, 14.62s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.97 ms /    77 runs   (    0.23 ms per token,  4285.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1985.01 ms /    34 tokens (   58.38 ms per token,    17.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12219.32 ms /    76 runs   (  160.78 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   14386.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "214it [53:29, 13.96s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.93 ms /    70 runs   (    0.23 ms per token,  4395.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1730.04 ms /    30 tokens (   57.67 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10526.99 ms /    69 runs   (  152.57 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:       total time =   12419.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "215it [53:44, 14.18s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.15 ms /    77 runs   (    0.22 ms per token,  4489.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2354.41 ms /    42 tokens (   56.06 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12168.20 ms /    76 runs   (  160.11 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   14700.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "216it [53:55, 13.37s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.29 ms /    63 runs   (    0.23 ms per token,  4409.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1822.56 ms /    32 tokens (   56.96 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =    9495.41 ms /    62 runs   (  153.15 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   11460.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "217it [54:17, 15.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.80 ms /   114 runs   (    0.22 ms per token,  4597.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3675.38 ms /    62 tokens (   59.28 ms per token,    16.87 tokens per second)\n",
      "llama_print_timings:        eval time =   17784.70 ms /   113 runs   (  157.39 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   21730.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "218it [54:37, 17.19s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.87 ms /   120 runs   (    0.22 ms per token,  4637.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1763.54 ms /    30 tokens (   58.78 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:        eval time =   18219.62 ms /   119 runs   (  153.11 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =   20267.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "219it [54:54, 17.03s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.21 ms /    88 runs   (    0.22 ms per token,  4581.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2103.34 ms /    33 tokens (   63.74 ms per token,    15.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14324.64 ms /    87 runs   (  164.65 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =   16632.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "220it [55:07, 15.84s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.76 ms /    68 runs   (    0.23 ms per token,  4313.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1782.86 ms /    30 tokens (   59.43 ms per token,    16.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11130.42 ms /    67 runs   (  166.13 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =   13080.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "221it [55:20, 15.06s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.23 ms /    69 runs   (    0.22 ms per token,  4529.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2436.29 ms /    42 tokens (   58.01 ms per token,    17.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10653.44 ms /    68 runs   (  156.67 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:       total time =   13246.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "222it [55:32, 14.06s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.14 ms /    62 runs   (    0.23 ms per token,  4384.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1995.86 ms /    32 tokens (   62.37 ms per token,    16.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9568.84 ms /    61 runs   (  156.87 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =   11707.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "223it [55:55, 16.83s/it]llama_print_timings:      sample time =      25.00 ms /   116 runs   (    0.22 ms per token,  4640.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4349.98 ms /    62 tokens (   70.16 ms per token,    14.25 tokens per second)\n",
      "llama_print_timings:        eval time =   18656.02 ms /   115 runs   (  162.23 ms per token,     6.16 tokens per second)\n",
      "llama_print_timings:       total time =   23283.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "224it [56:07, 15.27s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    56 runs   (    0.23 ms per token,  4406.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2298.91 ms /    30 tokens (   76.63 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:        eval time =    9200.40 ms /    55 runs   (  167.28 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   11631.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "225it [56:24, 15.96s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.87 ms /    87 runs   (    0.23 ms per token,  4378.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2962.94 ms /    34 tokens (   87.15 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:        eval time =   14383.92 ms /    86 runs   (  167.25 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   17558.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "226it [56:38, 15.19s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.46 ms /    68 runs   (    0.23 ms per token,  4397.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2139.62 ms /    30 tokens (   71.32 ms per token,    14.02 tokens per second)\n",
      "llama_print_timings:        eval time =   11093.53 ms /    67 runs   (  165.58 ms per token,     6.04 tokens per second)\n",
      "llama_print_timings:       total time =   13399.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "227it [56:50, 14.22s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.56 ms /    54 runs   (    0.23 ms per token,  4299.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2613.33 ms /    42 tokens (   62.22 ms per token,    16.07 tokens per second)\n",
      "llama_print_timings:        eval time =    9232.09 ms /    53 runs   (  174.19 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   11972.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "228it [57:02, 13.67s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.20 ms /    62 runs   (    0.23 ms per token,  4366.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2574.80 ms /    32 tokens (   80.46 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:        eval time =    9639.90 ms /    61 runs   (  158.03 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   12363.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "229it [57:24, 16.16s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.95 ms /   112 runs   (    0.22 ms per token,  4488.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4249.18 ms /    62 tokens (   68.54 ms per token,    14.59 tokens per second)\n",
      "llama_print_timings:        eval time =   17443.45 ms /   111 runs   (  157.15 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   21959.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "230it [57:45, 17.58s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.82 ms /   117 runs   (    0.22 ms per token,  4532.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1845.16 ms /    30 tokens (   61.51 ms per token,    16.26 tokens per second)\n",
      "llama_print_timings:        eval time =   18772.31 ms /   116 runs   (  161.83 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   20897.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "231it [57:58, 16.35s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.75 ms /    74 runs   (    0.23 ms per token,  4418.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1943.11 ms /    33 tokens (   58.88 ms per token,    16.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11379.67 ms /    73 runs   (  155.89 ms per token,     6.41 tokens per second)\n",
      "llama_print_timings:       total time =   13492.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "232it [58:10, 15.02s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.36 ms /    63 runs   (    0.23 ms per token,  4386.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1924.20 ms /    30 tokens (   64.14 ms per token,    15.59 tokens per second)\n",
      "llama_print_timings:        eval time =    9832.72 ms /    62 runs   (  158.59 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =   11904.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "233it [58:28, 15.83s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.00 ms /    93 runs   (    0.22 ms per token,  4651.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3085.74 ms /    42 tokens (   73.47 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =   14428.83 ms /    92 runs   (  156.84 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:       total time =   17728.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "234it [58:38, 14.06s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.15 ms /    48 runs   (    0.23 ms per token,  4304.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1974.95 ms /    32 tokens (   61.72 ms per token,    16.20 tokens per second)\n",
      "llama_print_timings:        eval time =    7829.93 ms /    47 runs   (  166.59 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =    9920.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "235it [58:58, 15.90s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.78 ms /   105 runs   (    0.23 ms per token,  4414.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3590.73 ms /    62 tokens (   57.92 ms per token,    17.27 tokens per second)\n",
      "llama_print_timings:        eval time =   16346.55 ms /   104 runs   (  157.18 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   20189.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "236it [59:16, 16.51s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.55 ms /    98 runs   (    0.22 ms per token,  4546.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1883.94 ms /    30 tokens (   62.80 ms per token,    15.92 tokens per second)\n",
      "llama_print_timings:        eval time =   15801.05 ms /    97 runs   (  162.90 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   17924.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "237it [59:30, 15.70s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.13 ms /    75 runs   (    0.23 ms per token,  4377.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2050.31 ms /    34 tokens (   60.30 ms per token,    16.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11582.36 ms /    74 runs   (  156.52 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =   13808.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "238it [59:42, 14.67s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.23 ms /    65 runs   (    0.23 ms per token,  4266.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1781.79 ms /    30 tokens (   59.39 ms per token,    16.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10326.78 ms /    64 runs   (  161.36 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   12267.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "239it [59:56, 14.52s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.58 ms /    74 runs   (    0.22 ms per token,  4463.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2578.04 ms /    42 tokens (   61.38 ms per token,    16.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11409.36 ms /    73 runs   (  156.29 ms per token,     6.40 tokens per second)\n",
      "llama_print_timings:       total time =   14161.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "240it [1:00:07, 13.46s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.83 ms /    55 runs   (    0.23 ms per token,  4288.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1873.98 ms /    32 tokens (   58.56 ms per token,    17.08 tokens per second)\n",
      "llama_print_timings:        eval time =    8993.31 ms /    54 runs   (  166.54 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =   10999.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "241it [1:00:32, 16.73s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.50 ms /   127 runs   (    0.22 ms per token,  4456.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4237.72 ms /    67 tokens (   63.25 ms per token,    15.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19798.14 ms /   126 runs   (  157.13 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   24344.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "242it [1:00:43, 15.23s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.51 ms /    59 runs   (    0.23 ms per token,  4366.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1966.18 ms /    30 tokens (   65.54 ms per token,    15.26 tokens per second)\n",
      "llama_print_timings:        eval time =    9635.56 ms /    58 runs   (  166.13 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =   11739.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "243it [1:01:02, 16.10s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.71 ms /   100 runs   (    0.23 ms per token,  4402.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2121.07 ms /    33 tokens (   64.27 ms per token,    15.56 tokens per second)\n",
      "llama_print_timings:        eval time =   15781.86 ms /    99 runs   (  159.41 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   18137.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "244it [1:01:17, 15.97s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.37 ms /    87 runs   (    0.22 ms per token,  4490.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1902.75 ms /    30 tokens (   63.42 ms per token,    15.77 tokens per second)\n",
      "llama_print_timings:        eval time =   13556.80 ms /    86 runs   (  157.64 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   15669.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "245it [1:01:30, 15.14s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.23 ms /    67 runs   (    0.23 ms per token,  4398.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2670.99 ms /    42 tokens (   63.60 ms per token,    15.72 tokens per second)\n",
      "llama_print_timings:        eval time =   10353.25 ms /    66 runs   (  156.87 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =   13177.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "246it [1:01:46, 15.19s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.54 ms /    83 runs   (    0.22 ms per token,  4476.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2123.19 ms /    36 tokens (   58.98 ms per token,    16.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12981.89 ms /    82 runs   (  158.32 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   15300.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "247it [1:02:12, 18.63s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      30.07 ms /   134 runs   (    0.22 ms per token,  4456.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3792.35 ms /    62 tokens (   61.17 ms per token,    16.35 tokens per second)\n",
      "llama_print_timings:        eval time =   22551.88 ms /   133 runs   (  169.56 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   26669.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "248it [1:02:33, 19.20s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.28 ms /   116 runs   (    0.22 ms per token,  4588.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1988.98 ms /    30 tokens (   66.30 ms per token,    15.08 tokens per second)\n",
      "llama_print_timings:        eval time =   18251.90 ms /   115 runs   (  158.71 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =   20518.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "249it [1:02:51, 18.74s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.55 ms /    95 runs   (    0.23 ms per token,  4409.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2021.91 ms /    34 tokens (   59.47 ms per token,    16.82 tokens per second)\n",
      "llama_print_timings:        eval time =   15401.63 ms /    94 runs   (  163.85 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   17654.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "250it [1:03:00, 15.93s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.06 ms /    48 runs   (    0.23 ms per token,  4339.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1897.86 ms /    30 tokens (   63.26 ms per token,    15.81 tokens per second)\n",
      "llama_print_timings:        eval time =    7365.21 ms /    47 runs   (  156.71 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:       total time =    9375.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "251it [1:03:15, 15.73s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.62 ms /    76 runs   (    0.22 ms per token,  4572.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2639.17 ms /    42 tokens (   62.84 ms per token,    15.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12438.43 ms /    75 runs   (  165.85 ms per token,     6.03 tokens per second)\n",
      "llama_print_timings:       total time =   15255.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "252it [1:03:27, 14.50s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.15 ms /    58 runs   (    0.23 ms per token,  4409.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2594.37 ms /    36 tokens (   72.07 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =    8909.85 ms /    57 runs   (  156.31 ms per token,     6.40 tokens per second)\n",
      "llama_print_timings:       total time =   11638.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "253it [1:03:42, 14.75s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.36 ms /    68 runs   (    0.23 ms per token,  4426.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3839.60 ms /    62 tokens (   61.93 ms per token,    16.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11315.89 ms /    67 runs   (  168.89 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   15316.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "254it [1:04:01, 15.99s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.97 ms /   106 runs   (    0.23 ms per token,  4422.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1881.20 ms /    30 tokens (   62.71 ms per token,    15.95 tokens per second)\n",
      "llama_print_timings:        eval time =   16743.49 ms /   105 runs   (  159.46 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   18878.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "255it [1:04:19, 16.54s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.37 ms /    96 runs   (    0.23 ms per token,  4292.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2009.90 ms /    33 tokens (   60.91 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =   15588.90 ms /    95 runs   (  164.09 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =   17840.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "256it [1:04:33, 15.73s/it]llama_print_timings:      sample time =      17.01 ms /    75 runs   (    0.23 ms per token,  4409.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1852.68 ms /    30 tokens (   61.76 ms per token,    16.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11795.05 ms /    74 runs   (  159.39 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   13823.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "257it [1:04:48, 15.54s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.12 ms /    75 runs   (    0.23 ms per token,  4380.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3163.40 ms /    42 tokens (   75.32 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11774.73 ms /    74 runs   (  159.12 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   15115.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "258it [1:04:58, 14.05s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    54 runs   (    0.23 ms per token,  4409.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2143.19 ms /    36 tokens (   59.53 ms per token,    16.80 tokens per second)\n",
      "llama_print_timings:        eval time =    8303.88 ms /    53 runs   (  156.68 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:       total time =   10569.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "259it [1:05:21, 16.56s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.22 ms /   112 runs   (    0.23 ms per token,  4441.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3974.96 ms /    62 tokens (   64.11 ms per token,    15.60 tokens per second)\n",
      "llama_print_timings:        eval time =   18151.11 ms /   111 runs   (  163.52 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   22398.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "260it [1:05:39, 17.04s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.45 ms /   101 runs   (    0.22 ms per token,  4498.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1778.95 ms /    30 tokens (   59.30 ms per token,    16.86 tokens per second)\n",
      "llama_print_timings:        eval time =   16142.44 ms /   100 runs   (  161.42 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =   18164.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "261it [1:05:58, 17.53s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.15 ms /   100 runs   (    0.23 ms per token,  4320.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2240.03 ms /    34 tokens (   65.88 ms per token,    15.18 tokens per second)\n",
      "llama_print_timings:        eval time =   16202.60 ms /    99 runs   (  163.66 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   18679.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "262it [1:06:14, 17.16s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.93 ms /    88 runs   (    0.23 ms per token,  4416.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1754.91 ms /    30 tokens (   58.50 ms per token,    17.09 tokens per second)\n",
      "llama_print_timings:        eval time =   14324.10 ms /    87 runs   (  164.64 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =   16293.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "263it [1:06:28, 16.27s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.12 ms /    74 runs   (    0.23 ms per token,  4322.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2541.25 ms /    42 tokens (   60.51 ms per token,    16.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11462.82 ms /    73 runs   (  157.02 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =   14179.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "264it [1:06:42, 15.55s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.25 ms /    69 runs   (    0.24 ms per token,  4246.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2358.84 ms /    36 tokens (   65.52 ms per token,    15.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11348.46 ms /    68 runs   (  166.89 ms per token,     5.99 tokens per second)\n",
      "llama_print_timings:       total time =   13876.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "265it [1:07:06, 17.97s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.16 ms /   122 runs   (    0.22 ms per token,  4491.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4062.25 ms /    62 tokens (   65.52 ms per token,    15.26 tokens per second)\n",
      "llama_print_timings:        eval time =   19254.04 ms /   121 runs   (  159.12 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   23614.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "266it [1:07:26, 18.81s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.62 ms /   114 runs   (    0.22 ms per token,  4449.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1938.88 ms /    30 tokens (   64.63 ms per token,    15.47 tokens per second)\n",
      "llama_print_timings:        eval time =   18532.69 ms /   113 runs   (  164.01 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   20756.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "267it [1:07:45, 18.62s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.45 ms /    98 runs   (    0.23 ms per token,  4364.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2176.89 ms /    33 tokens (   65.97 ms per token,    15.16 tokens per second)\n",
      "llama_print_timings:        eval time =   15780.01 ms /    97 runs   (  162.68 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   18193.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "268it [1:07:54, 15.81s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.82 ms /    45 runs   (    0.24 ms per token,  4158.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1980.95 ms /    30 tokens (   66.03 ms per token,    15.14 tokens per second)\n",
      "llama_print_timings:        eval time =    7165.24 ms /    44 runs   (  162.85 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =    9253.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "269it [1:08:07, 14.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.93 ms /    60 runs   (    0.23 ms per token,  4307.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3283.66 ms /    42 tokens (   78.18 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:        eval time =    9280.94 ms /    59 runs   (  157.30 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   12708.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "270it [1:08:18, 13.76s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    53 runs   (    0.23 ms per token,  4305.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2475.77 ms /    36 tokens (   68.77 ms per token,    14.54 tokens per second)\n",
      "llama_print_timings:        eval time =    8539.81 ms /    52 runs   (  164.23 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =   11143.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "271it [1:08:42, 16.96s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.72 ms /   125 runs   (    0.22 ms per token,  4509.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3867.46 ms /    62 tokens (   62.38 ms per token,    16.03 tokens per second)\n",
      "llama_print_timings:        eval time =   20269.22 ms /   124 runs   (  163.46 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   24437.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "272it [1:09:01, 17.46s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.21 ms /   104 runs   (    0.22 ms per token,  4481.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2179.88 ms /    30 tokens (   72.66 ms per token,    13.76 tokens per second)\n",
      "llama_print_timings:        eval time =   16184.68 ms /   103 runs   (  157.13 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   18618.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "273it [1:09:19, 17.55s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.42 ms /    88 runs   (    0.23 ms per token,  4309.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2513.26 ms /    34 tokens (   73.92 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =   15025.64 ms /    87 runs   (  172.71 ms per token,     5.79 tokens per second)\n",
      "llama_print_timings:       total time =   17753.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "274it [1:09:33, 16.64s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.68 ms /    81 runs   (    0.23 ms per token,  4336.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1812.01 ms /    30 tokens (   60.40 ms per token,    16.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12521.74 ms /    80 runs   (  156.52 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =   14528.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "275it [1:09:42, 14.35s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       8.93 ms /    38 runs   (    0.24 ms per token,  4253.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2477.79 ms /    42 tokens (   58.99 ms per token,    16.95 tokens per second)\n",
      "llama_print_timings:        eval time =    6436.11 ms /    37 runs   (  173.95 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =    9009.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "276it [1:09:54, 13.60s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.45 ms /    62 runs   (    0.23 ms per token,  4290.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2135.46 ms /    36 tokens (   59.32 ms per token,    16.86 tokens per second)\n",
      "llama_print_timings:        eval time =    9545.12 ms /    61 runs   (  156.48 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =   11827.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "277it [1:10:16, 16.15s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.34 ms /   110 runs   (    0.22 ms per token,  4519.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4056.68 ms /    62 tokens (   65.43 ms per token,    15.28 tokens per second)\n",
      "llama_print_timings:        eval time =   17798.43 ms /   109 runs   (  163.29 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   22116.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "278it [1:10:34, 16.62s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.90 ms /    99 runs   (    0.22 ms per token,  4520.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1841.40 ms /    30 tokens (   61.38 ms per token,    16.29 tokens per second)\n",
      "llama_print_timings:        eval time =   15628.98 ms /    98 runs   (  159.48 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   17711.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "279it [1:10:51, 16.85s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.80 ms /    96 runs   (    0.23 ms per token,  4403.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2124.91 ms /    33 tokens (   64.39 ms per token,    15.53 tokens per second)\n",
      "llama_print_timings:        eval time =   15037.55 ms /    95 runs   (  158.29 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   17392.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "280it [1:11:06, 16.22s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.57 ms /    82 runs   (    0.23 ms per token,  4416.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1804.06 ms /    30 tokens (   60.14 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12729.45 ms /    81 runs   (  157.15 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   14728.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "281it [1:11:19, 15.39s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.30 ms /    67 runs   (    0.23 ms per token,  4379.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2561.91 ms /    42 tokens (   61.00 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10735.52 ms /    66 runs   (  162.66 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   13459.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "282it [1:11:34, 15.20s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.67 ms /    76 runs   (    0.23 ms per token,  4300.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2737.65 ms /    36 tokens (   76.05 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:        eval time =   11849.90 ms /    75 runs   (  158.00 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   14772.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "283it [1:11:59, 18.02s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.48 ms /   127 runs   (    0.22 ms per token,  4459.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3700.06 ms /    62 tokens (   59.68 ms per token,    16.76 tokens per second)\n",
      "llama_print_timings:        eval time =   20564.70 ms /   126 runs   (  163.21 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   24573.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "284it [1:12:19, 18.70s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.36 ms /   110 runs   (    0.22 ms per token,  4515.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1889.05 ms /    30 tokens (   62.97 ms per token,    15.88 tokens per second)\n",
      "llama_print_timings:        eval time =   18142.81 ms /   109 runs   (  166.45 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =   20305.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "285it [1:12:35, 17.78s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.22 ms /    86 runs   (    0.24 ms per token,  4252.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2066.00 ms /    34 tokens (   60.76 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   13334.87 ms /    85 runs   (  156.88 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =   15607.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "286it [1:12:49, 16.68s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.94 ms /    74 runs   (    0.23 ms per token,  4368.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1839.94 ms /    30 tokens (   61.33 ms per token,    16.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12117.92 ms /    73 runs   (  166.00 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =   14137.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "287it [1:13:02, 15.68s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.99 ms /    67 runs   (    0.24 ms per token,  4190.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2857.18 ms /    42 tokens (   68.03 ms per token,    14.70 tokens per second)\n",
      "llama_print_timings:        eval time =   10324.31 ms /    66 runs   (  156.43 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =   13350.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "288it [1:13:15, 14.78s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.92 ms /    63 runs   (    0.24 ms per token,  4221.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2144.80 ms /    36 tokens (   59.58 ms per token,    16.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10381.61 ms /    62 runs   (  167.45 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   12676.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "289it [1:13:39, 17.52s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.38 ms /   127 runs   (    0.22 ms per token,  4474.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3656.53 ms /    62 tokens (   58.98 ms per token,    16.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19930.74 ms /   126 runs   (  158.18 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   23888.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "290it [1:14:01, 19.00s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.77 ms /   126 runs   (    0.22 ms per token,  4536.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1798.00 ms /    30 tokens (   59.93 ms per token,    16.69 tokens per second)\n",
      "llama_print_timings:        eval time =   20363.91 ms /   125 runs   (  162.91 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   22468.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "291it [1:14:16, 17.86s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.05 ms /    79 runs   (    0.23 ms per token,  4375.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2134.65 ms /    33 tokens (   64.69 ms per token,    15.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12862.32 ms /    78 runs   (  164.90 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =   15186.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "292it [1:14:29, 16.35s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.89 ms /    69 runs   (    0.23 ms per token,  4342.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1949.64 ms /    30 tokens (   64.99 ms per token,    15.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10706.56 ms /    68 runs   (  157.45 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   12818.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "293it [1:14:39, 14.40s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.08 ms /    46 runs   (    0.24 ms per token,  4150.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2680.80 ms /    42 tokens (   63.83 ms per token,    15.67 tokens per second)\n",
      "llama_print_timings:        eval time =    7059.26 ms /    45 runs   (  156.87 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =    9850.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "294it [1:14:55, 14.93s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.10 ms /    79 runs   (    0.23 ms per token,  4365.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3019.20 ms /    36 tokens (   83.87 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12953.04 ms /    78 runs   (  166.06 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =   16165.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "295it [1:15:19, 17.67s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.99 ms /   124 runs   (    0.23 ms per token,  4430.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3637.47 ms /    62 tokens (   58.67 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   20142.64 ms /   123 runs   (  163.76 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   24080.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "296it [1:15:41, 18.92s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.16 ms /   121 runs   (    0.22 ms per token,  4624.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1889.57 ms /    30 tokens (   62.99 ms per token,    15.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19653.44 ms /   120 runs   (  163.78 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   21836.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "297it [1:15:59, 18.76s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.45 ms /   102 runs   (    0.23 ms per token,  4350.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2075.01 ms /    34 tokens (   61.03 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:        eval time =   16042.37 ms /   101 runs   (  158.84 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =   18364.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "298it [1:16:14, 17.59s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.78 ms /    74 runs   (    0.24 ms per token,  4162.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2141.18 ms /    30 tokens (   71.37 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12535.22 ms /    73 runs   (  171.72 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =   14869.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "299it [1:16:24, 15.30s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.86 ms /    46 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2779.26 ms /    42 tokens (   66.17 ms per token,    15.11 tokens per second)\n",
      "llama_print_timings:        eval time =    7066.15 ms /    45 runs   (  157.03 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =    9956.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "300it [1:16:40, 15.34s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.42 ms /    79 runs   (    0.23 ms per token,  4288.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2400.04 ms /    36 tokens (   66.67 ms per token,    15.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12825.36 ms /    78 runs   (  164.43 ms per token,     6.08 tokens per second)\n",
      "llama_print_timings:       total time =   15416.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "301it [1:17:04, 17.93s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.92 ms /   126 runs   (    0.23 ms per token,  4356.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3957.54 ms /    67 tokens (   59.07 ms per token,    16.93 tokens per second)\n",
      "llama_print_timings:        eval time =   19714.95 ms /   125 runs   (  157.72 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   23978.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "302it [1:17:27, 19.48s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.83 ms /   128 runs   (    0.23 ms per token,  4440.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2129.17 ms /    30 tokens (   70.97 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =   20661.53 ms /   127 runs   (  162.69 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   23105.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "303it [1:17:45, 19.17s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.42 ms /    99 runs   (    0.23 ms per token,  4416.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2137.34 ms /    33 tokens (   64.77 ms per token,    15.44 tokens per second)\n",
      "llama_print_timings:        eval time =   16057.85 ms /    98 runs   (  163.86 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   18433.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "304it [1:17:58, 17.36s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.85 ms /    72 runs   (    0.23 ms per token,  4272.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1816.85 ms /    30 tokens (   60.56 ms per token,    16.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11135.96 ms /    71 runs   (  156.84 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:       total time =   13127.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "305it [1:18:12, 16.13s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.20 ms /    64 runs   (    0.24 ms per token,  4209.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2486.82 ms /    42 tokens (   59.21 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10625.26 ms /    63 runs   (  168.65 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   13273.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "306it [1:18:25, 15.28s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.06 ms /    71 runs   (    0.23 ms per token,  4421.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2159.96 ms /    36 tokens (   60.00 ms per token,    16.67 tokens per second)\n",
      "llama_print_timings:        eval time =   10958.85 ms /    70 runs   (  156.55 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =   13286.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "307it [1:18:38, 14.66s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.93 ms /    59 runs   (    0.24 ms per token,  4236.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3892.20 ms /    62 tokens (   62.78 ms per token,    15.93 tokens per second)\n",
      "llama_print_timings:        eval time =    9179.13 ms /    58 runs   (  158.26 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   13214.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "308it [1:19:00, 16.88s/it]llama_print_timings:      sample time =      26.80 ms /   121 runs   (    0.22 ms per token,  4514.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2694.45 ms /    30 tokens (   89.82 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:        eval time =   19073.35 ms /   120 runs   (  158.94 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   22057.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "309it [1:19:16, 16.60s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.45 ms /    84 runs   (    0.23 ms per token,  4319.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2246.09 ms /    34 tokens (   66.06 ms per token,    15.14 tokens per second)\n",
      "llama_print_timings:        eval time =   13500.62 ms /    83 runs   (  162.66 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   15952.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "310it [1:19:26, 14.53s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.75 ms /    50 runs   (    0.23 ms per token,  4255.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1842.84 ms /    30 tokens (   61.43 ms per token,    16.28 tokens per second)\n",
      "llama_print_timings:        eval time =    7720.21 ms /    49 runs   (  157.56 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =    9680.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "311it [1:19:40, 14.36s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.95 ms /    69 runs   (    0.23 ms per token,  4326.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2469.19 ms /    42 tokens (   58.79 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:        eval time =   11334.65 ms /    68 runs   (  166.69 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =   13969.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "312it [1:19:52, 13.66s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.60 ms /    61 runs   (    0.24 ms per token,  4179.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2476.52 ms /    36 tokens (   68.79 ms per token,    14.54 tokens per second)\n",
      "llama_print_timings:        eval time =    9407.71 ms /    60 runs   (  156.80 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:       total time =   12030.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "313it [1:20:16, 16.67s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.08 ms /   121 runs   (    0.23 ms per token,  4309.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3636.08 ms /    62 tokens (   58.65 ms per token,    17.05 tokens per second)\n",
      "llama_print_timings:        eval time =   19764.32 ms /   120 runs   (  164.70 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =   23691.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "314it [1:20:35, 17.54s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.45 ms /   111 runs   (    0.22 ms per token,  4540.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1930.74 ms /    30 tokens (   64.36 ms per token,    15.54 tokens per second)\n",
      "llama_print_timings:        eval time =   17372.69 ms /   110 runs   (  157.93 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   19570.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "315it [1:20:51, 17.03s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.55 ms /    84 runs   (    0.23 ms per token,  4297.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1976.39 ms /    33 tokens (   59.89 ms per token,    16.70 tokens per second)\n",
      "llama_print_timings:        eval time =   13640.36 ms /    83 runs   (  164.34 ms per token,     6.08 tokens per second)\n",
      "llama_print_timings:       total time =   15820.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "316it [1:21:00, 14.56s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.59 ms /    45 runs   (    0.24 ms per token,  4248.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1780.90 ms /    30 tokens (   59.36 ms per token,    16.85 tokens per second)\n",
      "llama_print_timings:        eval time =    6931.47 ms /    44 runs   (  157.53 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =    8815.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "317it [1:21:15, 14.66s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.99 ms /    74 runs   (    0.23 ms per token,  4354.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2452.95 ms /    42 tokens (   58.40 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12260.87 ms /    73 runs   (  167.96 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   14893.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "318it [1:21:30, 14.77s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.93 ms /    81 runs   (    0.23 ms per token,  4279.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2203.60 ms /    36 tokens (   61.21 ms per token,    16.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12631.08 ms /    80 runs   (  157.89 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   15030.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "319it [1:21:55, 18.03s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      29.52 ms /   133 runs   (    0.22 ms per token,  4505.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3826.96 ms /    62 tokens (   61.73 ms per token,    16.20 tokens per second)\n",
      "llama_print_timings:        eval time =   21489.93 ms /   132 runs   (  162.80 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   25635.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "320it [1:22:15, 18.48s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.03 ms /   107 runs   (    0.22 ms per token,  4646.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1897.30 ms /    30 tokens (   63.24 ms per token,    15.81 tokens per second)\n",
      "llama_print_timings:        eval time =   17385.42 ms /   106 runs   (  164.01 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   19533.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "321it [1:22:29, 17.33s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.16 ms /    79 runs   (    0.23 ms per token,  4349.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2119.02 ms /    34 tokens (   62.32 ms per token,    16.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12317.30 ms /    78 runs   (  157.91 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   14624.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "322it [1:22:43, 16.29s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.66 ms /    72 runs   (    0.23 ms per token,  4320.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1822.05 ms /    30 tokens (   60.73 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   11877.65 ms /    71 runs   (  167.29 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   13874.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "323it [1:22:57, 15.44s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.67 ms /    67 runs   (    0.23 ms per token,  4274.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2838.63 ms /    42 tokens (   67.59 ms per token,    14.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10435.04 ms /    66 runs   (  158.11 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   13436.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "324it [1:23:09, 14.49s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    60 runs   (    0.23 ms per token,  4330.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2250.10 ms /    36 tokens (   62.50 ms per token,    16.00 tokens per second)\n",
      "llama_print_timings:        eval time =    9896.65 ms /    59 runs   (  167.74 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   12290.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "325it [1:23:31, 16.70s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.43 ms /   114 runs   (    0.23 ms per token,  4313.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3683.06 ms /    62 tokens (   59.40 ms per token,    16.83 tokens per second)\n",
      "llama_print_timings:        eval time =   17894.42 ms /   113 runs   (  158.36 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =   21851.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "326it [1:23:43, 15.36s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.78 ms /    61 runs   (    0.23 ms per token,  4425.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1984.09 ms /    30 tokens (   66.14 ms per token,    15.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10102.66 ms /    60 runs   (  168.38 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   12232.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "327it [1:24:00, 15.80s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.25 ms /    91 runs   (    0.23 ms per token,  4281.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2265.95 ms /    33 tokens (   68.67 ms per token,    14.56 tokens per second)\n",
      "llama_print_timings:        eval time =   14330.57 ms /    90 runs   (  159.23 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   16819.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "328it [1:24:14, 15.41s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.18 ms /    75 runs   (    0.23 ms per token,  4365.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2097.82 ms /    30 tokens (   69.93 ms per token,    14.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12214.37 ms /    74 runs   (  165.06 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =   14496.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "329it [1:24:27, 14.46s/it]llama_print_timings:      sample time =      14.10 ms /    61 runs   (    0.23 ms per token,  4327.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2648.06 ms /    42 tokens (   63.05 ms per token,    15.86 tokens per second)\n",
      "llama_print_timings:        eval time =    9439.09 ms /    60 runs   (  157.32 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   12233.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "330it [1:24:39, 13.74s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.75 ms /    58 runs   (    0.24 ms per token,  4219.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2268.91 ms /    36 tokens (   63.03 ms per token,    15.87 tokens per second)\n",
      "llama_print_timings:        eval time =    9661.03 ms /    57 runs   (  169.49 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   12072.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "331it [1:24:54, 14.07s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.49 ms /    66 runs   (    0.23 ms per token,  4259.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3769.28 ms /    62 tokens (   60.79 ms per token,    16.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10914.83 ms /    65 runs   (  167.92 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   14849.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "332it [1:25:14, 15.90s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.62 ms /   112 runs   (    0.23 ms per token,  4372.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1824.68 ms /    30 tokens (   60.82 ms per token,    16.44 tokens per second)\n",
      "llama_print_timings:        eval time =   18046.08 ms /   111 runs   (  162.58 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   20144.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "333it [1:25:30, 15.86s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.95 ms /    87 runs   (    0.23 ms per token,  4361.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2034.25 ms /    34 tokens (   59.83 ms per token,    16.71 tokens per second)\n",
      "llama_print_timings:        eval time =   13525.62 ms /    86 runs   (  157.27 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   15766.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "334it [1:25:45, 15.80s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.54 ms /    82 runs   (    0.23 ms per token,  4421.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2119.07 ms /    30 tokens (   70.64 ms per token,    14.16 tokens per second)\n",
      "llama_print_timings:        eval time =   13332.76 ms /    81 runs   (  164.60 ms per token,     6.08 tokens per second)\n",
      "llama_print_timings:       total time =   15648.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "335it [1:25:59, 15.31s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.07 ms /    74 runs   (    0.23 ms per token,  4333.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2578.77 ms /    42 tokens (   61.40 ms per token,    16.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11427.42 ms /    73 runs   (  156.54 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =   14181.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "336it [1:26:11, 14.26s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.62 ms /    58 runs   (    0.23 ms per token,  4257.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2193.96 ms /    36 tokens (   60.94 ms per token,    16.41 tokens per second)\n",
      "llama_print_timings:        eval time =    9468.52 ms /    57 runs   (  166.11 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =   11801.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "337it [1:26:35, 17.14s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.63 ms /   127 runs   (    0.23 ms per token,  4436.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3715.72 ms /    62 tokens (   59.93 ms per token,    16.69 tokens per second)\n",
      "llama_print_timings:        eval time =   19818.78 ms /   126 runs   (  157.29 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   23849.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "338it [1:26:58, 18.83s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.36 ms /   127 runs   (    0.22 ms per token,  4478.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2046.79 ms /    30 tokens (   68.23 ms per token,    14.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20403.51 ms /   126 runs   (  161.93 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   22766.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "339it [1:27:15, 18.44s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.35 ms /    94 runs   (    0.23 ms per token,  4403.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1953.95 ms /    33 tokens (   59.21 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =   15353.89 ms /    93 runs   (  165.10 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =   17531.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "340it [1:27:31, 17.55s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.65 ms /    86 runs   (    0.23 ms per token,  4377.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1829.40 ms /    30 tokens (   60.98 ms per token,    16.40 tokens per second)\n",
      "llama_print_timings:        eval time =   13429.33 ms /    85 runs   (  157.99 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   15468.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "341it [1:27:44, 16.27s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    66 runs   (    0.23 ms per token,  4400.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2497.62 ms /    42 tokens (   59.47 ms per token,    16.82 tokens per second)\n",
      "llama_print_timings:        eval time =   10641.36 ms /    65 runs   (  163.71 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   13295.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "342it [1:27:58, 15.54s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.25 ms /    74 runs   (    0.23 ms per token,  4289.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2175.70 ms /    36 tokens (   60.44 ms per token,    16.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11476.34 ms /    73 runs   (  157.21 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   13831.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "343it [1:28:23, 18.47s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      29.50 ms /   131 runs   (    0.23 ms per token,  4441.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3860.38 ms /    62 tokens (   62.26 ms per token,    16.06 tokens per second)\n",
      "llama_print_timings:        eval time =   21116.48 ms /   130 runs   (  162.43 ms per token,     6.16 tokens per second)\n",
      "llama_print_timings:       total time =   25289.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "344it [1:28:43, 18.82s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.20 ms /   108 runs   (    0.22 ms per token,  4462.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1929.62 ms /    30 tokens (   64.32 ms per token,    15.55 tokens per second)\n",
      "llama_print_timings:        eval time =   17469.38 ms /   107 runs   (  163.27 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   19660.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "345it [1:29:00, 18.42s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.84 ms /    94 runs   (    0.23 ms per token,  4304.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2600.94 ms /    34 tokens (   76.50 ms per token,    13.07 tokens per second)\n",
      "llama_print_timings:        eval time =   14645.79 ms /    93 runs   (  157.48 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   17475.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "346it [1:29:16, 17.56s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.02 ms /    84 runs   (    0.23 ms per token,  4417.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1789.56 ms /    30 tokens (   59.65 ms per token,    16.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13540.04 ms /    83 runs   (  163.13 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   15533.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "347it [1:29:27, 15.63s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.26 ms /    54 runs   (    0.25 ms per token,  4073.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2624.46 ms /    42 tokens (   62.49 ms per token,    16.00 tokens per second)\n",
      "llama_print_timings:        eval time =    8366.67 ms /    53 runs   (  157.86 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   11122.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "348it [1:29:41, 15.11s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.17 ms /    74 runs   (    0.23 ms per token,  4309.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2127.86 ms /    36 tokens (   59.11 ms per token,    16.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11600.90 ms /    73 runs   (  158.92 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   13909.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "349it [1:30:06, 17.99s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.73 ms /   126 runs   (    0.23 ms per token,  4385.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4499.73 ms /    62 tokens (   72.58 ms per token,    13.78 tokens per second)\n",
      "llama_print_timings:        eval time =   19886.26 ms /   125 runs   (  159.09 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   24689.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "350it [1:30:18, 16.22s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.03 ms /    61 runs   (    0.23 ms per token,  4346.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2487.76 ms /    30 tokens (   82.93 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    9470.17 ms /    60 runs   (  157.84 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   12106.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "351it [1:30:34, 16.15s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.48 ms /    86 runs   (    0.23 ms per token,  4415.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2337.34 ms /    33 tokens (   70.83 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:        eval time =   13440.84 ms /    85 runs   (  158.13 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   15984.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "352it [1:30:48, 15.53s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.47 ms /    74 runs   (    0.24 ms per token,  4235.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1847.33 ms /    30 tokens (   61.58 ms per token,    16.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12030.12 ms /    73 runs   (  164.80 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =   14065.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "353it [1:31:02, 15.00s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.19 ms /    70 runs   (    0.23 ms per token,  4324.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2791.89 ms /    42 tokens (   66.47 ms per token,    15.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10795.56 ms /    69 runs   (  156.46 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =   13755.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "354it [1:31:16, 14.74s/it]llama_print_timings:      sample time =      16.14 ms /    70 runs   (    0.23 ms per token,  4338.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2460.79 ms /    36 tokens (   68.36 ms per token,    14.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11496.27 ms /    69 runs   (  166.61 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =   14127.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "355it [1:31:38, 17.04s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.16 ms /   114 runs   (    0.22 ms per token,  4531.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3661.15 ms /    62 tokens (   59.05 ms per token,    16.93 tokens per second)\n",
      "llama_print_timings:        eval time =   18477.22 ms /   113 runs   (  163.52 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   22417.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "356it [1:31:50, 15.49s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.37 ms /    63 runs   (    0.23 ms per token,  4384.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1978.51 ms /    30 tokens (   65.95 ms per token,    15.16 tokens per second)\n",
      "llama_print_timings:        eval time =    9736.23 ms /    62 runs   (  157.04 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =   11863.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "357it [1:32:01, 14.00s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.01 ms /    54 runs   (    0.24 ms per token,  4150.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2040.19 ms /    34 tokens (   60.01 ms per token,    16.67 tokens per second)\n",
      "llama_print_timings:        eval time =    8356.90 ms /    53 runs   (  157.68 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   10528.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "358it [1:32:10, 12.70s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.70 ms /    49 runs   (    0.24 ms per token,  4187.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1810.03 ms /    30 tokens (   60.33 ms per token,    16.57 tokens per second)\n",
      "llama_print_timings:        eval time =    7732.43 ms /    48 runs   (  161.09 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =    9661.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "359it [1:32:20, 11.82s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.05 ms /    43 runs   (    0.23 ms per token,  4279.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2981.11 ms /    42 tokens (   70.98 ms per token,    14.09 tokens per second)\n",
      "llama_print_timings:        eval time =    6682.81 ms /    42 runs   (  159.11 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =    9766.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "360it [1:32:32, 11.85s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.19 ms /    61 runs   (    0.23 ms per token,  4297.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2395.03 ms /    36 tokens (   66.53 ms per token,    15.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9388.83 ms /    60 runs   (  156.48 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =   11928.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "361it [1:32:57, 15.72s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.52 ms /   126 runs   (    0.23 ms per token,  4417.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4643.81 ms /    69 tokens (   67.30 ms per token,    14.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19771.33 ms /   125 runs   (  158.17 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   24725.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "362it [1:33:14, 16.36s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.32 ms /    97 runs   (    0.22 ms per token,  4549.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1846.48 ms /    30 tokens (   61.55 ms per token,    16.25 tokens per second)\n",
      "llama_print_timings:        eval time =   15772.46 ms /    96 runs   (  164.30 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =   17854.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "363it [1:33:30, 15.97s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.81 ms /    82 runs   (    0.23 ms per token,  4358.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2050.44 ms /    33 tokens (   62.13 ms per token,    16.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12828.34 ms /    81 runs   (  158.37 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =   15076.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "364it [1:33:44, 15.63s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.85 ms /    77 runs   (    0.23 ms per token,  4314.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1799.71 ms /    30 tokens (   59.99 ms per token,    16.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12827.53 ms /    76 runs   (  168.78 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   14816.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "365it [1:33:57, 14.87s/it]llama_print_timings:      sample time =      14.48 ms /    62 runs   (    0.23 ms per token,  4282.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2828.63 ms /    42 tokens (   67.35 ms per token,    14.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10128.90 ms /    61 runs   (  166.05 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =   13112.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "366it [1:34:05, 12.80s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    39 runs   (    0.24 ms per token,  4242.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1916.20 ms /    32 tokens (   59.88 ms per token,    16.70 tokens per second)\n",
      "llama_print_timings:        eval time =    5950.26 ms /    38 runs   (  156.59 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:       total time =    7958.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "367it [1:34:29, 15.91s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.44 ms /   118 runs   (    0.22 ms per token,  4462.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3673.11 ms /    62 tokens (   59.24 ms per token,    16.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19201.99 ms /   117 runs   (  164.12 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =   23163.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "368it [1:34:48, 16.91s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.20 ms /   106 runs   (    0.22 ms per token,  4568.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1781.34 ms /    30 tokens (   59.38 ms per token,    16.84 tokens per second)\n",
      "llama_print_timings:        eval time =   17217.29 ms /   105 runs   (  163.97 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   19255.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "369it [1:35:03, 16.34s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.91 ms /    81 runs   (    0.23 ms per token,  4284.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2081.89 ms /    34 tokens (   61.23 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12710.01 ms /    80 runs   (  158.88 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   14989.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "370it [1:35:15, 15.17s/it]llama_print_timings:      sample time =      14.16 ms /    62 runs   (    0.23 ms per token,  4377.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2027.44 ms /    30 tokens (   67.58 ms per token,    14.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10252.85 ms /    61 runs   (  168.08 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   12430.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "371it [1:35:28, 14.36s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.77 ms /    62 runs   (    0.22 ms per token,  4503.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2795.25 ms /    42 tokens (   66.55 ms per token,    15.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9533.30 ms /    61 runs   (  156.28 ms per token,     6.40 tokens per second)\n",
      "llama_print_timings:       total time =   12473.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "372it [1:35:41, 13.96s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.20 ms /    67 runs   (    0.23 ms per token,  4407.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1936.37 ms /    32 tokens (   60.51 ms per token,    16.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10945.89 ms /    66 runs   (  165.85 ms per token,     6.03 tokens per second)\n",
      "llama_print_timings:       total time =   13040.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "373it [1:36:04, 16.68s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.22 ms /   111 runs   (    0.23 ms per token,  4401.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3744.53 ms /    62 tokens (   60.40 ms per token,    16.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19008.13 ms /   110 runs   (  172.80 ms per token,     5.79 tokens per second)\n",
      "llama_print_timings:       total time =   23031.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "374it [1:36:26, 18.38s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.79 ms /   120 runs   (    0.22 ms per token,  4479.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2055.89 ms /    30 tokens (   68.53 ms per token,    14.59 tokens per second)\n",
      "llama_print_timings:        eval time =   19973.89 ms /   119 runs   (  167.85 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   22330.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "375it [1:36:41, 17.37s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.53 ms /    77 runs   (    0.23 ms per token,  4393.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2085.79 ms /    33 tokens (   63.21 ms per token,    15.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12756.51 ms /    76 runs   (  167.85 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   15029.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "376it [1:36:58, 17.21s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.43 ms /    92 runs   (    0.23 ms per token,  4292.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1828.66 ms /    30 tokens (   60.96 ms per token,    16.41 tokens per second)\n",
      "llama_print_timings:        eval time =   14752.57 ms /    91 runs   (  162.12 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   16811.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "377it [1:37:11, 15.96s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.11 ms /    62 runs   (    0.23 ms per token,  4394.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2523.15 ms /    42 tokens (   60.07 ms per token,    16.65 tokens per second)\n",
      "llama_print_timings:        eval time =   10394.56 ms /    61 runs   (  170.40 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   13065.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.99 ms /    67 runs   (    0.24 ms per token,  4189.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1936.12 ms /    32 tokens (   60.50 ms per token,    16.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10646.00 ms /    66 runs   (  161.30 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   12751.15 ms\n",
      "378it [1:37:24, 15.00s/it]Llama.generate: prefix-match hit\n",
      "379it [1:37:39, 15.08s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.42 ms /    64 runs   (    0.23 ms per token,  4439.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4124.85 ms /    62 tokens (   66.53 ms per token,    15.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10991.25 ms /    63 runs   (  174.46 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =   15275.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "380it [1:38:01, 17.20s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.29 ms /   116 runs   (    0.22 ms per token,  4587.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1857.31 ms /    30 tokens (   61.91 ms per token,    16.15 tokens per second)\n",
      "llama_print_timings:        eval time =   19969.83 ms /   115 runs   (  173.65 ms per token,     5.76 tokens per second)\n",
      "llama_print_timings:       total time =   22120.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "381it [1:38:17, 16.70s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.53 ms /    73 runs   (    0.24 ms per token,  4165.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2117.54 ms /    34 tokens (   62.28 ms per token,    16.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13231.00 ms /    72 runs   (  183.76 ms per token,     5.44 tokens per second)\n",
      "llama_print_timings:       total time =   15536.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "382it [1:38:33, 16.59s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.73 ms /    82 runs   (    0.23 ms per token,  4377.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1959.81 ms /    30 tokens (   65.33 ms per token,    15.31 tokens per second)\n",
      "llama_print_timings:        eval time =   14162.99 ms /    81 runs   (  174.85 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   16325.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "383it [1:38:43, 14.68s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       9.58 ms /    42 runs   (    0.23 ms per token,  4385.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2675.41 ms /    42 tokens (   63.70 ms per token,    15.70 tokens per second)\n",
      "llama_print_timings:        eval time =    7447.59 ms /    41 runs   (  181.65 ms per token,     5.51 tokens per second)\n",
      "llama_print_timings:       total time =   10228.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "384it [1:38:55, 13.78s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.33 ms /    57 runs   (    0.23 ms per token,  4276.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2007.81 ms /    32 tokens (   62.74 ms per token,    15.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9527.07 ms /    56 runs   (  170.13 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   11674.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "385it [1:39:19, 16.89s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.54 ms /   112 runs   (    0.23 ms per token,  4384.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4092.57 ms /    62 tokens (   66.01 ms per token,    15.15 tokens per second)\n",
      "llama_print_timings:        eval time =   19783.20 ms /   111 runs   (  178.23 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:       total time =   24159.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "386it [1:39:39, 17.89s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.65 ms /   103 runs   (    0.22 ms per token,  4547.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2178.73 ms /    30 tokens (   72.62 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =   17792.56 ms /   102 runs   (  174.44 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =   20226.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "387it [1:39:55, 17.10s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.92 ms /    75 runs   (    0.24 ms per token,  4184.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2101.76 ms /    33 tokens (   63.69 ms per token,    15.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12938.53 ms /    74 runs   (  174.84 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   15228.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "388it [1:40:07, 15.70s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.18 ms /    62 runs   (    0.23 ms per token,  4373.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1997.84 ms /    30 tokens (   66.59 ms per token,    15.02 tokens per second)\n",
      "llama_print_timings:        eval time =   10295.54 ms /    61 runs   (  168.78 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   12446.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "389it [1:40:20, 14.73s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.73 ms /    59 runs   (    0.23 ms per token,  4298.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2610.41 ms /    42 tokens (   62.15 ms per token,    16.09 tokens per second)\n",
      "llama_print_timings:        eval time =    9717.81 ms /    58 runs   (  167.55 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   12473.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "390it [1:40:31, 13.65s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.97 ms /    54 runs   (    0.24 ms per token,  4163.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2053.22 ms /    32 tokens (   64.16 ms per token,    15.59 tokens per second)\n",
      "llama_print_timings:        eval time =    8925.19 ms /    53 runs   (  168.40 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   11114.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "391it [1:40:45, 13.94s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.26 ms /    62 runs   (    0.23 ms per token,  4346.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4041.40 ms /    62 tokens (   65.18 ms per token,    15.34 tokens per second)\n",
      "llama_print_timings:        eval time =   10443.26 ms /    61 runs   (  171.20 ms per token,     5.84 tokens per second)\n",
      "llama_print_timings:       total time =   14634.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "392it [1:41:08, 16.47s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.15 ms /   115 runs   (    0.22 ms per token,  4572.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2230.74 ms /    30 tokens (   74.36 ms per token,    13.45 tokens per second)\n",
      "llama_print_timings:        eval time =   19839.95 ms /   114 runs   (  174.03 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   22356.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "393it [1:41:23, 16.21s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.77 ms /    78 runs   (    0.23 ms per token,  4390.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2381.93 ms /    34 tokens (   70.06 ms per token,    14.27 tokens per second)\n",
      "llama_print_timings:        eval time =   13020.77 ms /    77 runs   (  169.10 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   15591.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "394it [1:41:39, 16.09s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.59 ms /    81 runs   (    0.23 ms per token,  4357.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2026.69 ms /    30 tokens (   67.56 ms per token,    14.80 tokens per second)\n",
      "llama_print_timings:        eval time =   13588.82 ms /    80 runs   (  169.86 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   15817.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "395it [1:41:54, 15.83s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.90 ms /    71 runs   (    0.22 ms per token,  4464.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2787.56 ms /    42 tokens (   66.37 ms per token,    15.07 tokens per second)\n",
      "llama_print_timings:        eval time =   12246.62 ms /    70 runs   (  174.95 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   15206.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "396it [1:42:08, 15.19s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.57 ms /    66 runs   (    0.24 ms per token,  4238.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2025.05 ms /    32 tokens (   63.28 ms per token,    15.80 tokens per second)\n",
      "llama_print_timings:        eval time =   11519.78 ms /    65 runs   (  177.23 ms per token,     5.64 tokens per second)\n",
      "llama_print_timings:       total time =   13707.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "397it [1:42:31, 17.46s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.62 ms /   111 runs   (    0.22 ms per token,  4507.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3744.30 ms /    62 tokens (   60.39 ms per token,    16.56 tokens per second)\n",
      "llama_print_timings:        eval time =   18722.53 ms /   110 runs   (  170.20 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   22738.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "398it [1:42:52, 18.51s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.62 ms /   110 runs   (    0.21 ms per token,  4658.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1836.86 ms /    30 tokens (   61.23 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =   18862.48 ms /   109 runs   (  173.05 ms per token,     5.78 tokens per second)\n",
      "llama_print_timings:       total time =   20973.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "399it [1:43:08, 17.80s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.46 ms /    80 runs   (    0.23 ms per token,  4334.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2567.76 ms /    33 tokens (   77.81 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:        eval time =   13375.32 ms /    79 runs   (  169.31 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   16141.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "400it [1:43:20, 15.99s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.07 ms /    47 runs   (    0.24 ms per token,  4246.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2969.08 ms /    30 tokens (   98.97 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:        eval time =    8688.12 ms /    46 runs   (  188.87 ms per token,     5.29 tokens per second)\n",
      "llama_print_timings:       total time =   11775.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "401it [1:43:31, 14.67s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    56 runs   (    0.23 ms per token,  4370.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2544.47 ms /    42 tokens (   60.58 ms per token,    16.51 tokens per second)\n",
      "llama_print_timings:        eval time =    8899.09 ms /    55 runs   (  161.80 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   11577.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "402it [1:43:44, 14.25s/it]llama_print_timings:      sample time =      14.63 ms /    62 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2103.72 ms /    32 tokens (   65.74 ms per token,    15.21 tokens per second)\n",
      "llama_print_timings:        eval time =   11020.04 ms /    61 runs   (  180.66 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =   13284.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "403it [1:44:06, 16.55s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.62 ms /   106 runs   (    0.22 ms per token,  4487.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3953.13 ms /    62 tokens (   63.76 ms per token,    15.68 tokens per second)\n",
      "llama_print_timings:        eval time =   17679.26 ms /   105 runs   (  168.37 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   21893.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "404it [1:44:26, 17.57s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.26 ms /   102 runs   (    0.22 ms per token,  4581.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2641.03 ms /    30 tokens (   88.03 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:        eval time =   17059.11 ms /   101 runs   (  168.90 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   19955.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "405it [1:44:43, 17.42s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.03 ms /    88 runs   (    0.23 ms per token,  4393.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2020.40 ms /    34 tokens (   59.42 ms per token,    16.83 tokens per second)\n",
      "llama_print_timings:        eval time =   14832.24 ms /    87 runs   (  170.49 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   17075.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "406it [1:44:58, 16.71s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.67 ms /    80 runs   (    0.22 ms per token,  4527.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1967.92 ms /    30 tokens (   65.60 ms per token,    15.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12872.16 ms /    79 runs   (  162.94 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   15036.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "407it [1:45:14, 16.50s/it]llama_print_timings:      sample time =      17.91 ms /    78 runs   (    0.23 ms per token,  4355.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2689.10 ms /    42 tokens (   64.03 ms per token,    15.62 tokens per second)\n",
      "llama_print_timings:        eval time =   13125.51 ms /    77 runs   (  170.46 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   16004.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "408it [1:45:26, 15.13s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.65 ms /    61 runs   (    0.22 ms per token,  4469.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1957.64 ms /    32 tokens (   61.18 ms per token,    16.35 tokens per second)\n",
      "llama_print_timings:        eval time =    9834.70 ms /    60 runs   (  163.91 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   11941.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "409it [1:45:50, 17.67s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.68 ms /   117 runs   (    0.22 ms per token,  4556.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3807.86 ms /    62 tokens (   61.42 ms per token,    16.28 tokens per second)\n",
      "llama_print_timings:        eval time =   19492.24 ms /   116 runs   (  168.04 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   23593.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "410it [1:46:11, 18.63s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.51 ms /   116 runs   (    0.22 ms per token,  4547.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1817.22 ms /    30 tokens (   60.57 ms per token,    16.51 tokens per second)\n",
      "llama_print_timings:        eval time =   18758.67 ms /   115 runs   (  163.12 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   20861.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "411it [1:46:28, 18.17s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.36 ms /    89 runs   (    0.23 ms per token,  4371.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2125.48 ms /    33 tokens (   64.41 ms per token,    15.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14747.21 ms /    88 runs   (  167.58 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   17096.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "412it [1:46:42, 16.82s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.55 ms /    70 runs   (    0.24 ms per token,  4230.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1809.21 ms /    30 tokens (   60.31 ms per token,    16.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11700.81 ms /    69 runs   (  169.58 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   13687.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "413it [1:46:56, 16.12s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.48 ms /    72 runs   (    0.23 ms per token,  4369.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2678.79 ms /    42 tokens (   63.78 ms per token,    15.68 tokens per second)\n",
      "llama_print_timings:        eval time =   11634.51 ms /    71 runs   (  163.87 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   14488.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "414it [1:47:08, 14.71s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.66 ms /    58 runs   (    0.24 ms per token,  4247.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1966.33 ms /    32 tokens (   61.45 ms per token,    16.27 tokens per second)\n",
      "llama_print_timings:        eval time =    9315.97 ms /    57 runs   (  163.44 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   11422.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "415it [1:47:22, 14.71s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.78 ms /    65 runs   (    0.23 ms per token,  4399.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3914.89 ms /    62 tokens (   63.14 ms per token,    15.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10617.90 ms /    64 runs   (  165.90 ms per token,     6.03 tokens per second)\n",
      "llama_print_timings:       total time =   14689.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "416it [1:47:44, 16.89s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.41 ms /   119 runs   (    0.22 ms per token,  4506.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1827.43 ms /    30 tokens (   60.91 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =   19852.70 ms /   118 runs   (  168.24 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   21977.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "417it [1:47:59, 16.31s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.29 ms /    78 runs   (    0.22 ms per token,  4511.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2167.00 ms /    34 tokens (   63.74 ms per token,    15.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12595.36 ms /    77 runs   (  163.58 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   14946.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "418it [1:48:08, 13.94s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       9.39 ms /    41 runs   (    0.23 ms per token,  4367.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1807.45 ms /    30 tokens (   60.25 ms per token,    16.60 tokens per second)\n",
      "llama_print_timings:        eval time =    6500.33 ms /    40 runs   (  162.51 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =    8403.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "419it [1:48:17, 12.58s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       9.02 ms /    39 runs   (    0.23 ms per token,  4323.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2513.73 ms /    42 tokens (   59.85 ms per token,    16.71 tokens per second)\n",
      "llama_print_timings:        eval time =    6795.76 ms /    38 runs   (  178.84 ms per token,     5.59 tokens per second)\n",
      "llama_print_timings:       total time =    9408.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "420it [1:48:30, 12.57s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.92 ms /    65 runs   (    0.23 ms per token,  4356.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1920.27 ms /    32 tokens (   60.01 ms per token,    16.66 tokens per second)\n",
      "llama_print_timings:        eval time =   10474.16 ms /    64 runs   (  163.66 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   12551.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "421it [1:48:54, 16.19s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.62 ms /   122 runs   (    0.23 ms per token,  4416.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3931.60 ms /    67 tokens (   58.68 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   20400.76 ms /   121 runs   (  168.60 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   24633.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "422it [1:49:16, 17.89s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.20 ms /   118 runs   (    0.22 ms per token,  4503.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1928.68 ms /    30 tokens (   64.29 ms per token,    15.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19642.54 ms /   117 runs   (  167.88 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   21862.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "423it [1:49:34, 18.02s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.55 ms /    99 runs   (    0.23 ms per token,  4390.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2082.36 ms /    33 tokens (   63.10 ms per token,    15.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15991.92 ms /    98 runs   (  163.18 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   18315.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "424it [1:49:49, 16.86s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.99 ms /    69 runs   (    0.23 ms per token,  4315.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2319.31 ms /    30 tokens (   77.31 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:        eval time =   11661.64 ms /    68 runs   (  171.49 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =   14149.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "425it [1:50:05, 16.83s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.24 ms /    85 runs   (    0.23 ms per token,  4417.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2620.57 ms /    42 tokens (   62.39 ms per token,    16.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13927.01 ms /    84 runs   (  165.80 ms per token,     6.03 tokens per second)\n",
      "llama_print_timings:       total time =   16759.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "426it [1:50:19, 15.94s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.47 ms /    68 runs   (    0.23 ms per token,  4394.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2620.45 ms /    36 tokens (   72.79 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =   11091.99 ms /    67 runs   (  165.55 ms per token,     6.04 tokens per second)\n",
      "llama_print_timings:       total time =   13877.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "427it [1:50:42, 17.89s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.31 ms /   110 runs   (    0.23 ms per token,  4345.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3738.72 ms /    62 tokens (   60.30 ms per token,    16.58 tokens per second)\n",
      "llama_print_timings:        eval time =   18418.50 ms /   109 runs   (  168.98 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   22435.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "428it [1:50:54, 16.16s/it]llama_print_timings:      sample time =      14.10 ms /    63 runs   (    0.22 ms per token,  4468.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1814.80 ms /    30 tokens (   60.49 ms per token,    16.53 tokens per second)\n",
      "llama_print_timings:        eval time =   10164.17 ms /    62 runs   (  163.94 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   12129.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "429it [1:51:09, 16.04s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.27 ms /    82 runs   (    0.23 ms per token,  4255.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2094.69 ms /    34 tokens (   61.61 ms per token,    16.23 tokens per second)\n",
      "llama_print_timings:        eval time =   13442.37 ms /    81 runs   (  165.96 ms per token,     6.03 tokens per second)\n",
      "llama_print_timings:       total time =   15737.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "430it [1:51:24, 15.48s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.70 ms /    72 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1825.28 ms /    30 tokens (   60.84 ms per token,    16.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12187.13 ms /    71 runs   (  171.65 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =   14190.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "431it [1:51:36, 14.55s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.59 ms /    60 runs   (    0.23 ms per token,  4414.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2589.33 ms /    42 tokens (   61.65 ms per token,    16.22 tokens per second)\n",
      "llama_print_timings:        eval time =    9643.65 ms /    59 runs   (  163.45 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   12374.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "432it [1:51:49, 14.03s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.42 ms /    61 runs   (    0.24 ms per token,  4231.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2811.29 ms /    36 tokens (   78.09 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:        eval time =    9836.18 ms /    60 runs   (  163.94 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   12800.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "433it [1:52:13, 17.19s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.57 ms /   122 runs   (    0.23 ms per token,  4425.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3773.18 ms /    62 tokens (   60.86 ms per token,    16.43 tokens per second)\n",
      "llama_print_timings:        eval time =   20505.44 ms /   121 runs   (  169.47 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   24578.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "434it [1:52:28, 16.42s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.01 ms /    78 runs   (    0.22 ms per token,  4584.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1802.45 ms /    30 tokens (   60.08 ms per token,    16.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12613.99 ms /    77 runs   (  163.82 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   14605.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "435it [1:52:44, 16.34s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.90 ms /    82 runs   (    0.23 ms per token,  4337.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2240.17 ms /    33 tokens (   67.88 ms per token,    14.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13724.33 ms /    81 runs   (  169.44 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   16166.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "436it [1:53:02, 16.63s/it]llama_print_timings:      sample time =      21.40 ms /    94 runs   (    0.23 ms per token,  4392.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1841.33 ms /    30 tokens (   61.38 ms per token,    16.29 tokens per second)\n",
      "llama_print_timings:        eval time =   15233.58 ms /    93 runs   (  163.80 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   17310.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "437it [1:53:14, 15.47s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    60 runs   (    0.23 ms per token,  4267.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2528.39 ms /    42 tokens (   60.20 ms per token,    16.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10092.68 ms /    59 runs   (  171.06 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   12770.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "438it [1:53:32, 16.06s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.02 ms /    94 runs   (    0.23 ms per token,  4268.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2187.46 ms /    36 tokens (   60.76 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   15009.46 ms /    93 runs   (  161.39 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   17425.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "439it [1:53:55, 18.18s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.73 ms /   115 runs   (    0.22 ms per token,  4468.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3685.29 ms /    62 tokens (   59.44 ms per token,    16.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19155.47 ms /   114 runs   (  168.03 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   23127.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "440it [1:54:08, 16.79s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.24 ms /    68 runs   (    0.22 ms per token,  4463.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1843.80 ms /    30 tokens (   61.46 ms per token,    16.27 tokens per second)\n",
      "llama_print_timings:        eval time =   11526.55 ms /    67 runs   (  172.04 ms per token,     5.81 tokens per second)\n",
      "llama_print_timings:       total time =   13536.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "441it [1:54:26, 17.17s/it]llama_print_timings:      sample time =      22.19 ms /    97 runs   (    0.23 ms per token,  4371.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2114.53 ms /    34 tokens (   62.19 ms per token,    16.08 tokens per second)\n",
      "llama_print_timings:        eval time =   15713.21 ms /    96 runs   (  163.68 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   18063.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "442it [1:54:42, 16.58s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.83 ms /    79 runs   (    0.23 ms per token,  4430.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1859.23 ms /    30 tokens (   61.97 ms per token,    16.14 tokens per second)\n",
      "llama_print_timings:        eval time =   13149.25 ms /    78 runs   (  168.58 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   15200.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "443it [1:54:55, 15.63s/it]llama_print_timings:      sample time =      15.00 ms /    66 runs   (    0.23 ms per token,  4400.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2650.35 ms /    42 tokens (   63.10 ms per token,    15.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10604.13 ms /    65 runs   (  163.14 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   13412.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "444it [1:55:07, 14.38s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    54 runs   (    0.23 ms per token,  4347.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2236.12 ms /    36 tokens (   62.11 ms per token,    16.10 tokens per second)\n",
      "llama_print_timings:        eval time =    9100.13 ms /    53 runs   (  171.70 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =   11469.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "445it [1:55:22, 14.75s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.49 ms /    71 runs   (    0.23 ms per token,  4304.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3989.73 ms /    62 tokens (   64.35 ms per token,    15.54 tokens per second)\n",
      "llama_print_timings:        eval time =   11452.61 ms /    70 runs   (  163.61 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   15614.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "446it [1:55:42, 16.16s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.97 ms /   103 runs   (    0.22 ms per token,  4484.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1927.35 ms /    30 tokens (   64.24 ms per token,    15.57 tokens per second)\n",
      "llama_print_timings:        eval time =   17263.19 ms /   102 runs   (  169.25 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   19449.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "447it [1:55:57, 15.96s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.04 ms /    81 runs   (    0.24 ms per token,  4253.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2113.42 ms /    33 tokens (   64.04 ms per token,    15.61 tokens per second)\n",
      "llama_print_timings:        eval time =   13157.44 ms /    80 runs   (  164.47 ms per token,     6.08 tokens per second)\n",
      "llama_print_timings:       total time =   15473.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "448it [1:56:11, 15.33s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.97 ms /    73 runs   (    0.23 ms per token,  4302.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1946.77 ms /    30 tokens (   64.89 ms per token,    15.41 tokens per second)\n",
      "llama_print_timings:        eval time =   11745.55 ms /    72 runs   (  163.13 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   13871.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "449it [1:56:27, 15.41s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.24 ms /    76 runs   (    0.23 ms per token,  4408.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3175.97 ms /    42 tokens (   75.62 ms per token,    13.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12231.53 ms /    75 runs   (  163.09 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   15591.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "450it [1:56:42, 15.28s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.78 ms /    75 runs   (    0.24 ms per token,  4218.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2194.43 ms /    36 tokens (   60.96 ms per token,    16.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12591.24 ms /    74 runs   (  170.15 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   14968.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "451it [1:57:04, 17.41s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.06 ms /   112 runs   (    0.22 ms per token,  4469.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3982.77 ms /    62 tokens (   64.24 ms per token,    15.57 tokens per second)\n",
      "llama_print_timings:        eval time =   18133.80 ms /   111 runs   (  163.37 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   22386.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "452it [1:57:16, 15.86s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.43 ms /    59 runs   (    0.23 ms per token,  4393.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2083.20 ms /    30 tokens (   69.44 ms per token,    14.40 tokens per second)\n",
      "llama_print_timings:        eval time =   10010.01 ms /    58 runs   (  172.59 ms per token,     5.79 tokens per second)\n",
      "llama_print_timings:       total time =   12243.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "453it [1:57:30, 15.36s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.42 ms /    75 runs   (    0.23 ms per token,  4306.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2061.30 ms /    34 tokens (   60.63 ms per token,    16.49 tokens per second)\n",
      "llama_print_timings:        eval time =   11951.14 ms /    74 runs   (  161.50 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =   14195.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "454it [1:57:45, 15.03s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.23 ms /    73 runs   (    0.24 ms per token,  4235.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1964.89 ms /    30 tokens (   65.50 ms per token,    15.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12098.48 ms /    72 runs   (  168.03 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   14244.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "455it [1:57:56, 14.01s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.88 ms /    56 runs   (    0.23 ms per token,  4348.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2590.83 ms /    42 tokens (   61.69 ms per token,    16.21 tokens per second)\n",
      "llama_print_timings:        eval time =    8908.35 ms /    55 runs   (  161.97 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   11632.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "456it [1:58:10, 13.90s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.89 ms /    67 runs   (    0.24 ms per token,  4215.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2199.88 ms /    36 tokens (   61.11 ms per token,    16.36 tokens per second)\n",
      "llama_print_timings:        eval time =   11270.61 ms /    66 runs   (  170.77 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   13637.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "457it [1:58:35, 17.25s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.61 ms /   128 runs   (    0.22 ms per token,  4473.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3876.15 ms /    62 tokens (   62.52 ms per token,    16.00 tokens per second)\n",
      "llama_print_timings:        eval time =   20889.03 ms /   127 runs   (  164.48 ms per token,     6.08 tokens per second)\n",
      "llama_print_timings:       total time =   25075.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "458it [1:58:54, 17.92s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.38 ms /   103 runs   (    0.23 ms per token,  4405.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1902.81 ms /    30 tokens (   63.43 ms per token,    15.77 tokens per second)\n",
      "llama_print_timings:        eval time =   17311.99 ms /   102 runs   (  169.73 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   19472.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "459it [1:59:12, 17.82s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.07 ms /    91 runs   (    0.23 ms per token,  4318.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1984.74 ms /    33 tokens (   60.14 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   15363.22 ms /    90 runs   (  170.70 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   17571.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "460it [1:59:29, 17.58s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.49 ms /    90 runs   (    0.23 ms per token,  4391.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2194.12 ms /    30 tokens (   73.14 ms per token,    13.67 tokens per second)\n",
      "llama_print_timings:        eval time =   14616.99 ms /    89 runs   (  164.24 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =   17030.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "461it [1:59:39, 15.18s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       9.44 ms /    41 runs   (    0.23 ms per token,  4344.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2504.99 ms /    42 tokens (   59.64 ms per token,    16.77 tokens per second)\n",
      "llama_print_timings:        eval time =    6972.78 ms /    40 runs   (  174.32 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =    9579.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "462it [1:59:52, 14.79s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.27 ms /    70 runs   (    0.23 ms per token,  4302.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2450.90 ms /    36 tokens (   68.08 ms per token,    14.69 tokens per second)\n",
      "llama_print_timings:        eval time =   11237.60 ms /    69 runs   (  162.86 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   13863.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "463it [2:00:20, 18.59s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      30.39 ms /   140 runs   (    0.22 ms per token,  4606.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3718.70 ms /    62 tokens (   59.98 ms per token,    16.67 tokens per second)\n",
      "llama_print_timings:        eval time =   23390.28 ms /   139 runs   (  168.28 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   27450.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "464it [2:00:40, 18.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.58 ms /   104 runs   (    0.23 ms per token,  4410.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1906.03 ms /    30 tokens (   63.53 ms per token,    15.74 tokens per second)\n",
      "llama_print_timings:        eval time =   17411.13 ms /   103 runs   (  169.04 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   19571.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "465it [2:00:56, 18.26s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.49 ms /    90 runs   (    0.23 ms per token,  4392.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2045.64 ms /    34 tokens (   60.17 ms per token,    16.62 tokens per second)\n",
      "llama_print_timings:        eval time =   14527.85 ms /    89 runs   (  163.23 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   16791.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "466it [2:01:14, 18.17s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.51 ms /    94 runs   (    0.23 ms per token,  4370.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2003.51 ms /    30 tokens (   66.78 ms per token,    14.97 tokens per second)\n",
      "llama_print_timings:        eval time =   15729.05 ms /    93 runs   (  169.13 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   17958.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "467it [2:01:23, 15.35s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    38 runs   (    0.23 ms per token,  4334.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2579.08 ms /    42 tokens (   61.41 ms per token,    16.28 tokens per second)\n",
      "llama_print_timings:        eval time =    6100.02 ms /    37 runs   (  164.87 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =    8771.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "468it [2:01:37, 14.82s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.02 ms /    69 runs   (    0.23 ms per token,  4307.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2201.75 ms /    36 tokens (   61.16 ms per token,    16.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11203.33 ms /    68 runs   (  164.75 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =   13574.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "469it [2:02:00, 17.36s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.39 ms /   113 runs   (    0.22 ms per token,  4449.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4036.87 ms /    62 tokens (   65.11 ms per token,    15.36 tokens per second)\n",
      "llama_print_timings:        eval time =   18962.80 ms /   112 runs   (  169.31 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   23278.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "470it [2:02:22, 18.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.01 ms /   121 runs   (    0.22 ms per token,  4480.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1967.96 ms /    30 tokens (   65.60 ms per token,    15.24 tokens per second)\n",
      "llama_print_timings:        eval time =   20181.80 ms /   120 runs   (  168.18 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   22450.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "471it [2:02:38, 17.93s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.24 ms /    83 runs   (    0.23 ms per token,  4314.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2131.58 ms /    33 tokens (   64.59 ms per token,    15.48 tokens per second)\n",
      "llama_print_timings:        eval time =   13352.81 ms /    82 runs   (  162.84 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   15685.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "472it [2:02:53, 16.90s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.29 ms /    75 runs   (    0.23 ms per token,  4338.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2036.88 ms /    30 tokens (   67.90 ms per token,    14.73 tokens per second)\n",
      "llama_print_timings:        eval time =   12275.32 ms /    74 runs   (  165.88 ms per token,     6.03 tokens per second)\n",
      "llama_print_timings:       total time =   14492.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "473it [2:03:06, 15.86s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.30 ms /    63 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2539.27 ms /    42 tokens (   60.46 ms per token,    16.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10738.64 ms /    62 runs   (  173.20 ms per token,     5.77 tokens per second)\n",
      "llama_print_timings:       total time =   13434.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "474it [2:03:19, 14.91s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    58 runs   (    0.24 ms per token,  4229.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2263.02 ms /    36 tokens (   62.86 ms per token,    15.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10287.67 ms /    57 runs   (  180.49 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =   12695.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "475it [2:03:44, 17.97s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.70 ms /   120 runs   (    0.22 ms per token,  4493.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3821.28 ms /    62 tokens (   61.63 ms per token,    16.22 tokens per second)\n",
      "llama_print_timings:        eval time =   21007.81 ms /   119 runs   (  176.54 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =   25121.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "476it [2:04:04, 18.58s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.27 ms /   105 runs   (    0.22 ms per token,  4513.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1992.17 ms /    30 tokens (   66.41 ms per token,    15.06 tokens per second)\n",
      "llama_print_timings:        eval time =   17750.94 ms /   104 runs   (  170.68 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   20001.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "477it [2:04:16, 16.60s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.26 ms /    55 runs   (    0.24 ms per token,  4147.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2116.44 ms /    34 tokens (   62.25 ms per token,    16.06 tokens per second)\n",
      "llama_print_timings:        eval time =    9728.43 ms /    54 runs   (  180.16 ms per token,     5.55 tokens per second)\n",
      "llama_print_timings:       total time =   11985.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "478it [2:04:31, 16.17s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.99 ms /    78 runs   (    0.23 ms per token,  4335.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1868.24 ms /    30 tokens (   62.27 ms per token,    16.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13107.09 ms /    77 runs   (  170.22 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   15167.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "479it [2:04:45, 15.59s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.47 ms /    68 runs   (    0.23 ms per token,  4396.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2689.81 ms /    42 tokens (   64.04 ms per token,    15.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11377.66 ms /    67 runs   (  169.82 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   14228.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "480it [2:04:57, 14.60s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    59 runs   (    0.23 ms per token,  4302.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2310.03 ms /    36 tokens (   64.17 ms per token,    15.58 tokens per second)\n",
      "llama_print_timings:        eval time =    9839.73 ms /    58 runs   (  169.65 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   12292.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "481it [2:05:24, 18.31s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      29.12 ms /   128 runs   (    0.23 ms per token,  4396.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4224.59 ms /    67 tokens (   63.05 ms per token,    15.86 tokens per second)\n",
      "llama_print_timings:        eval time =   22406.26 ms /   127 runs   (  176.43 ms per token,     5.67 tokens per second)\n",
      "llama_print_timings:       total time =   26953.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "482it [2:05:47, 19.57s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.14 ms /   117 runs   (    0.22 ms per token,  4476.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1919.58 ms /    30 tokens (   63.99 ms per token,    15.63 tokens per second)\n",
      "llama_print_timings:        eval time =   20317.60 ms /   116 runs   (  175.15 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   22527.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "483it [2:06:05, 19.17s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.66 ms /    93 runs   (    0.23 ms per token,  4292.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2383.09 ms /    33 tokens (   72.21 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15609.89 ms /    92 runs   (  169.67 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   18223.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "484it [2:06:21, 18.06s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.07 ms /    80 runs   (    0.23 ms per token,  4427.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2032.97 ms /    30 tokens (   67.77 ms per token,    14.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13231.02 ms /    79 runs   (  167.48 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   15457.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "485it [2:06:34, 16.69s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.85 ms /    65 runs   (    0.23 ms per token,  4376.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2576.58 ms /    42 tokens (   61.35 ms per token,    16.30 tokens per second)\n",
      "llama_print_timings:        eval time =   10779.02 ms /    64 runs   (  168.42 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   13513.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "486it [2:06:48, 15.71s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.31 ms /    66 runs   (    0.23 ms per token,  4310.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2357.86 ms /    36 tokens (   65.50 ms per token,    15.27 tokens per second)\n",
      "llama_print_timings:        eval time =   10878.02 ms /    65 runs   (  167.35 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   13396.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "487it [2:07:13, 18.62s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.12 ms /   127 runs   (    0.22 ms per token,  4516.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3705.23 ms /    62 tokens (   59.76 ms per token,    16.73 tokens per second)\n",
      "llama_print_timings:        eval time =   21408.93 ms /   126 runs   (  169.91 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   25424.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "488it [2:07:35, 19.53s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.30 ms /   116 runs   (    0.22 ms per token,  4585.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1898.74 ms /    30 tokens (   63.29 ms per token,    15.80 tokens per second)\n",
      "llama_print_timings:        eval time =   19463.57 ms /   115 runs   (  169.25 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   21639.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "489it [2:07:51, 18.62s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.80 ms /    83 runs   (    0.23 ms per token,  4416.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2417.62 ms /    34 tokens (   71.11 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13897.99 ms /    82 runs   (  169.49 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   16513.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "490it [2:08:08, 18.14s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.94 ms /    89 runs   (    0.22 ms per token,  4463.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1856.59 ms /    30 tokens (   61.89 ms per token,    16.16 tokens per second)\n",
      "llama_print_timings:        eval time =   14944.81 ms /    88 runs   (  169.83 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   17017.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "491it [2:08:22, 16.90s/it]llama_print_timings:      sample time =      14.95 ms /    68 runs   (    0.22 ms per token,  4549.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2522.51 ms /    42 tokens (   60.06 ms per token,    16.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11326.47 ms /    67 runs   (  169.05 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   14011.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "492it [2:08:35, 15.55s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.30 ms /    58 runs   (    0.23 ms per token,  4359.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2516.25 ms /    36 tokens (   69.90 ms per token,    14.31 tokens per second)\n",
      "llama_print_timings:        eval time =    9720.22 ms /    57 runs   (  170.53 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   12379.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "493it [2:08:56, 17.24s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.14 ms /   102 runs   (    0.23 ms per token,  4407.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3699.98 ms /    62 tokens (   59.68 ms per token,    16.76 tokens per second)\n",
      "llama_print_timings:        eval time =   17238.99 ms /   101 runs   (  170.68 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   21185.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "494it [2:09:17, 18.47s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.14 ms /   114 runs   (    0.22 ms per token,  4534.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1852.79 ms /    30 tokens (   61.76 ms per token,    16.19 tokens per second)\n",
      "llama_print_timings:        eval time =   19216.19 ms /   113 runs   (  170.05 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   21346.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "495it [2:09:34, 17.96s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.14 ms /    86 runs   (    0.23 ms per token,  4269.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2206.92 ms /    33 tokens (   66.88 ms per token,    14.95 tokens per second)\n",
      "llama_print_timings:        eval time =   14340.85 ms /    85 runs   (  168.72 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   16755.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "496it [2:09:47, 16.62s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.17 ms /    69 runs   (    0.23 ms per token,  4267.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1831.14 ms /    30 tokens (   61.04 ms per token,    16.38 tokens per second)\n",
      "llama_print_timings:        eval time =   11507.82 ms /    68 runs   (  169.23 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   13508.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "497it [2:09:57, 14.52s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    41 runs   (    0.22 ms per token,  4467.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2793.91 ms /    42 tokens (   66.52 ms per token,    15.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6736.89 ms /    40 runs   (  168.42 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =    9625.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "498it [2:10:06, 12.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =       9.53 ms /    41 runs   (    0.23 ms per token,  4304.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2187.93 ms /    36 tokens (   60.78 ms per token,    16.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6756.21 ms /    40 runs   (  168.91 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =    9040.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "499it [2:10:30, 16.28s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.09 ms /   118 runs   (    0.22 ms per token,  4522.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4048.05 ms /    62 tokens (   65.29 ms per token,    15.32 tokens per second)\n",
      "llama_print_timings:        eval time =   19883.55 ms /   117 runs   (  169.94 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   24217.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "500it [2:10:51, 17.58s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.68 ms /   108 runs   (    0.22 ms per token,  4561.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2238.81 ms /    30 tokens (   74.63 ms per token,    13.40 tokens per second)\n",
      "llama_print_timings:        eval time =   18119.68 ms /   107 runs   (  169.34 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   20620.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "501it [2:11:09, 17.87s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.95 ms /    96 runs   (    0.23 ms per token,  4372.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2230.46 ms /    34 tokens (   65.60 ms per token,    15.24 tokens per second)\n",
      "llama_print_timings:        eval time =   16074.37 ms /    95 runs   (  169.20 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   18539.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "502it [2:11:26, 17.40s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.09 ms /    85 runs   (    0.22 ms per token,  4451.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1927.60 ms /    30 tokens (   64.25 ms per token,    15.56 tokens per second)\n",
      "llama_print_timings:        eval time =   14174.01 ms /    84 runs   (  168.74 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   16306.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "503it [2:11:39, 16.03s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.55 ms /    60 runs   (    0.23 ms per token,  4427.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2746.50 ms /    42 tokens (   65.39 ms per token,    15.29 tokens per second)\n",
      "llama_print_timings:        eval time =    9924.51 ms /    59 runs   (  168.21 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   12815.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "504it [2:11:55, 16.10s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.02 ms /    83 runs   (    0.23 ms per token,  4364.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2205.51 ms /    36 tokens (   61.26 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:        eval time =   13851.85 ms /    82 runs   (  168.93 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   16259.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "505it [2:12:20, 18.71s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.35 ms /   121 runs   (    0.22 ms per token,  4592.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4142.37 ms /    62 tokens (   66.81 ms per token,    14.97 tokens per second)\n",
      "llama_print_timings:        eval time =   20367.83 ms /   120 runs   (  169.73 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   24799.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.16 ms /   114 runs   (    0.22 ms per token,  4530.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1933.75 ms /    30 tokens (   64.46 ms per token,    15.51 tokens per second)\n",
      "llama_print_timings:        eval time =   19070.18 ms /   113 runs   (  168.76 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   21289.15 ms\n",
      "506it [2:12:41, 19.48s/it]Llama.generate: prefix-match hit\n",
      "507it [2:12:57, 18.42s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.32 ms /    82 runs   (    0.22 ms per token,  4475.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2064.33 ms /    33 tokens (   62.56 ms per token,    15.99 tokens per second)\n",
      "llama_print_timings:        eval time =   13674.80 ms /    81 runs   (  168.82 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   15933.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "508it [2:13:13, 17.65s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.70 ms /    83 runs   (    0.23 ms per token,  4437.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1814.06 ms /    30 tokens (   60.47 ms per token,    16.54 tokens per second)\n",
      "llama_print_timings:        eval time =   13848.60 ms /    82 runs   (  168.89 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   15866.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "509it [2:13:27, 16.70s/it]llama_print_timings:      sample time =      16.05 ms /    71 runs   (    0.23 ms per token,  4423.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2488.50 ms /    42 tokens (   59.25 ms per token,    16.88 tokens per second)\n",
      "llama_print_timings:        eval time =   11797.45 ms /    70 runs   (  168.53 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   14458.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "510it [2:13:39, 15.24s/it]llama_print_timings:      sample time =      13.08 ms /    58 runs   (    0.23 ms per token,  4435.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2181.23 ms /    36 tokens (   60.59 ms per token,    16.50 tokens per second)\n",
      "llama_print_timings:        eval time =    9530.32 ms /    57 runs   (  167.20 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   11847.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "511it [2:13:54, 15.28s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.93 ms /    69 runs   (    0.23 ms per token,  4332.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3681.77 ms /    62 tokens (   59.38 ms per token,    16.84 tokens per second)\n",
      "llama_print_timings:        eval time =   11525.78 ms /    68 runs   (  169.50 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   15376.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "512it [2:14:16, 17.32s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.34 ms /   119 runs   (    0.21 ms per token,  4697.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1859.13 ms /    30 tokens (   61.97 ms per token,    16.14 tokens per second)\n",
      "llama_print_timings:        eval time =   19938.09 ms /   118 runs   (  168.97 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   22084.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "513it [2:14:32, 16.86s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.56 ms /    81 runs   (    0.23 ms per token,  4363.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2054.13 ms /    34 tokens (   60.42 ms per token,    16.55 tokens per second)\n",
      "llama_print_timings:        eval time =   13520.78 ms /    80 runs   (  169.01 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   15771.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "514it [2:14:48, 16.67s/it]llama_print_timings:      sample time =      19.16 ms /    84 runs   (    0.23 ms per token,  4383.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1955.82 ms /    30 tokens (   65.19 ms per token,    15.34 tokens per second)\n",
      "llama_print_timings:        eval time =   14072.01 ms /    83 runs   (  169.54 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   16229.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "515it [2:15:04, 16.20s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.39 ms /    75 runs   (    0.22 ms per token,  4574.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2486.20 ms /    42 tokens (   59.20 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12426.96 ms /    74 runs   (  167.93 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   15088.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "516it [2:15:17, 15.48s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.55 ms /    69 runs   (    0.23 ms per token,  4438.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2231.37 ms /    36 tokens (   61.98 ms per token,    16.13 tokens per second)\n",
      "llama_print_timings:        eval time =   11416.71 ms /    68 runs   (  167.89 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   13815.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "517it [2:15:41, 17.98s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.70 ms /   118 runs   (    0.22 ms per token,  4592.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3750.77 ms /    62 tokens (   60.50 ms per token,    16.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19761.00 ms /   117 runs   (  168.90 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   23790.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "518it [2:16:03, 19.07s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.08 ms /   116 runs   (    0.22 ms per token,  4624.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1845.43 ms /    30 tokens (   61.51 ms per token,    16.26 tokens per second)\n",
      "llama_print_timings:        eval time =   19514.27 ms /   115 runs   (  169.69 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   21634.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "519it [2:16:19, 18.11s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.58 ms /    81 runs   (    0.23 ms per token,  4359.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2059.40 ms /    33 tokens (   62.41 ms per token,    16.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13618.57 ms /    80 runs   (  170.23 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   15869.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "520it [2:16:35, 17.46s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.84 ms /    83 runs   (    0.23 ms per token,  4405.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1862.67 ms /    30 tokens (   62.09 ms per token,    16.11 tokens per second)\n",
      "llama_print_timings:        eval time =   13870.85 ms /    82 runs   (  169.16 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   15929.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "521it [2:16:48, 16.25s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.96 ms /    62 runs   (    0.23 ms per token,  4440.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2986.76 ms /    42 tokens (   71.11 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10283.44 ms /    61 runs   (  168.58 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   13416.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "522it [2:17:02, 15.59s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.13 ms /    70 runs   (    0.23 ms per token,  4340.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2223.20 ms /    36 tokens (   61.76 ms per token,    16.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11663.20 ms /    69 runs   (  169.03 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   14050.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "523it [2:17:17, 15.40s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.85 ms /    67 runs   (    0.22 ms per token,  4512.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3660.28 ms /    62 tokens (   59.04 ms per token,    16.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11132.42 ms /    66 runs   (  168.67 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   14950.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "524it [2:17:38, 17.08s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.32 ms /   112 runs   (    0.22 ms per token,  4605.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1875.16 ms /    30 tokens (   62.51 ms per token,    16.00 tokens per second)\n",
      "llama_print_timings:        eval time =   18865.22 ms /   111 runs   (  169.96 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   21006.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "525it [2:17:53, 16.44s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.24 ms /    76 runs   (    0.23 ms per token,  4408.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2154.17 ms /    34 tokens (   63.36 ms per token,    15.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12626.26 ms /    75 runs   (  168.35 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   14955.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "526it [2:18:09, 16.44s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.42 ms /    86 runs   (    0.23 ms per token,  4427.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1900.01 ms /    30 tokens (   63.33 ms per token,    15.79 tokens per second)\n",
      "llama_print_timings:        eval time =   14335.35 ms /    85 runs   (  168.65 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   16444.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "527it [2:18:24, 15.94s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.20 ms /    72 runs   (    0.23 ms per token,  4443.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2628.90 ms /    42 tokens (   62.59 ms per token,    15.98 tokens per second)\n",
      "llama_print_timings:        eval time =   11957.63 ms /    71 runs   (  168.42 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   14755.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "528it [2:18:36, 14.85s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    60 runs   (    0.23 ms per token,  4374.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2266.35 ms /    36 tokens (   62.95 ms per token,    15.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9885.14 ms /    59 runs   (  167.54 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   12293.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "529it [2:19:00, 17.51s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.86 ms /   117 runs   (    0.22 ms per token,  4524.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3742.34 ms /    62 tokens (   60.36 ms per token,    16.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19716.04 ms /   116 runs   (  169.97 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   23730.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "530it [2:19:23, 19.18s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.22 ms /   124 runs   (    0.22 ms per token,  4555.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1903.92 ms /    30 tokens (   63.46 ms per token,    15.76 tokens per second)\n",
      "llama_print_timings:        eval time =   20855.92 ms /   123 runs   (  169.56 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   23054.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "531it [2:19:41, 18.80s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.35 ms /    94 runs   (    0.23 ms per token,  4403.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1986.13 ms /    33 tokens (   60.19 ms per token,    16.62 tokens per second)\n",
      "llama_print_timings:        eval time =   15717.57 ms /    93 runs   (  169.01 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   17926.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "532it [2:19:58, 18.09s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.69 ms /    85 runs   (    0.22 ms per token,  4547.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2043.18 ms /    30 tokens (   68.11 ms per token,    14.68 tokens per second)\n",
      "llama_print_timings:        eval time =   14180.68 ms /    84 runs   (  168.82 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   16423.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "533it [2:20:12, 16.86s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.95 ms /    68 runs   (    0.22 ms per token,  4548.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2520.63 ms /    42 tokens (   60.01 ms per token,    16.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11312.20 ms /    67 runs   (  168.84 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   13995.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "534it [2:20:24, 15.37s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    57 runs   (    0.23 ms per token,  4406.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2329.70 ms /    36 tokens (   64.71 ms per token,    15.45 tokens per second)\n",
      "llama_print_timings:        eval time =    9422.17 ms /    56 runs   (  168.25 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   11886.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "535it [2:20:49, 18.42s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.40 ms /   124 runs   (    0.22 ms per token,  4526.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3799.08 ms /    62 tokens (   61.28 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:        eval time =   21439.67 ms /   123 runs   (  174.31 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   25539.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "536it [2:21:11, 19.41s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.92 ms /   116 runs   (    0.21 ms per token,  4654.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2016.12 ms /    30 tokens (   67.20 ms per token,    14.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19441.01 ms /   115 runs   (  169.05 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   21725.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "537it [2:21:26, 18.04s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.13 ms /    76 runs   (    0.23 ms per token,  4436.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2052.81 ms /    34 tokens (   60.38 ms per token,    16.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12601.51 ms /    75 runs   (  168.02 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   14831.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "538it [2:21:43, 17.70s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.62 ms /    89 runs   (    0.22 ms per token,  4535.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1822.40 ms /    30 tokens (   60.75 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   14863.84 ms /    88 runs   (  168.91 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   16890.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "539it [2:21:55, 16.01s/it]llama_print_timings:      sample time =      12.74 ms /    55 runs   (    0.23 ms per token,  4318.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2794.45 ms /    42 tokens (   66.53 ms per token,    15.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9141.89 ms /    54 runs   (  169.29 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   12064.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "540it [2:22:07, 14.93s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.25 ms /    59 runs   (    0.22 ms per token,  4453.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2560.49 ms /    36 tokens (   71.12 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =    9709.84 ms /    58 runs   (  167.41 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   12406.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "541it [2:22:31, 17.62s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.84 ms /   116 runs   (    0.22 ms per token,  4489.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4306.69 ms /    69 tokens (   62.42 ms per token,    16.02 tokens per second)\n",
      "llama_print_timings:        eval time =   19322.50 ms /   115 runs   (  168.02 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   23910.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "542it [2:22:49, 17.65s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.39 ms /    94 runs   (    0.22 ms per token,  4609.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1860.33 ms /    30 tokens (   62.01 ms per token,    16.13 tokens per second)\n",
      "llama_print_timings:        eval time =   15620.91 ms /    93 runs   (  167.97 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   17705.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "543it [2:23:04, 16.90s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.76 ms /    79 runs   (    0.22 ms per token,  4448.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1964.86 ms /    33 tokens (   59.54 ms per token,    16.80 tokens per second)\n",
      "llama_print_timings:        eval time =   13003.44 ms /    78 runs   (  166.71 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =   15151.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "544it [2:23:20, 16.59s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.20 ms /    84 runs   (    0.22 ms per token,  4614.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1832.16 ms /    30 tokens (   61.07 ms per token,    16.37 tokens per second)\n",
      "llama_print_timings:        eval time =   13836.00 ms /    83 runs   (  166.70 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =   15863.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "545it [2:23:32, 15.37s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.05 ms /    60 runs   (    0.23 ms per token,  4271.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2478.44 ms /    42 tokens (   59.01 ms per token,    16.95 tokens per second)\n",
      "llama_print_timings:        eval time =    9911.65 ms /    59 runs   (  167.99 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   12531.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "546it [2:23:45, 14.51s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.08 ms /    63 runs   (    0.22 ms per token,  4476.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2031.16 ms /    32 tokens (   63.47 ms per token,    15.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10331.13 ms /    62 runs   (  166.63 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =   12509.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "547it [2:24:11, 17.97s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.60 ms /   131 runs   (    0.22 ms per token,  4580.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3647.51 ms /    62 tokens (   58.83 ms per token,    17.00 tokens per second)\n",
      "llama_print_timings:        eval time =   22062.86 ms /   130 runs   (  169.71 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   26021.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "548it [2:24:30, 18.33s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.00 ms /   102 runs   (    0.22 ms per token,  4635.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2063.82 ms /    30 tokens (   68.79 ms per token,    14.54 tokens per second)\n",
      "llama_print_timings:        eval time =   16876.67 ms /   101 runs   (  167.10 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   19184.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "549it [2:24:47, 17.97s/it]llama_print_timings:      sample time =      20.19 ms /    89 runs   (    0.23 ms per token,  4409.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2108.16 ms /    34 tokens (   62.00 ms per token,    16.13 tokens per second)\n",
      "llama_print_timings:        eval time =   14805.65 ms /    88 runs   (  168.25 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   17126.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "550it [2:25:02, 17.11s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.30 ms /    79 runs   (    0.22 ms per token,  4565.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1835.47 ms /    30 tokens (   61.18 ms per token,    16.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13094.98 ms /    78 runs   (  167.88 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   15111.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "551it [2:25:16, 16.15s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.64 ms /    68 runs   (    0.23 ms per token,  4348.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2459.82 ms /    42 tokens (   58.57 ms per token,    17.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11285.47 ms /    67 runs   (  168.44 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   13906.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "552it [2:25:29, 15.27s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.06 ms /    67 runs   (    0.22 ms per token,  4448.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1964.92 ms /    32 tokens (   61.40 ms per token,    16.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11084.03 ms /    66 runs   (  167.94 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   13202.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "553it [2:25:51, 17.34s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.36 ms /   109 runs   (    0.21 ms per token,  4665.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3648.95 ms /    62 tokens (   58.85 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:        eval time =   18257.10 ms /   108 runs   (  169.05 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   22162.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "554it [2:26:13, 18.71s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.02 ms /   117 runs   (    0.21 ms per token,  4676.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2031.79 ms /    30 tokens (   67.73 ms per token,    14.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19596.84 ms /   116 runs   (  168.94 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   21901.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "555it [2:26:28, 17.63s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.15 ms /    78 runs   (    0.22 ms per token,  4547.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1983.64 ms /    33 tokens (   60.11 ms per token,    16.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12941.82 ms /    77 runs   (  168.08 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   15103.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "556it [2:26:43, 16.74s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.77 ms /    76 runs   (    0.22 ms per token,  4531.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1841.77 ms /    30 tokens (   61.39 ms per token,    16.29 tokens per second)\n",
      "llama_print_timings:        eval time =   12651.00 ms /    75 runs   (  168.68 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   14669.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "557it [2:26:57, 15.77s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.95 ms /    65 runs   (    0.23 ms per token,  4348.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2542.78 ms /    42 tokens (   60.54 ms per token,    16.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10792.20 ms /    64 runs   (  168.63 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   13490.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "558it [2:27:10, 14.96s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.95 ms /    66 runs   (    0.23 ms per token,  4414.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1939.53 ms /    32 tokens (   60.61 ms per token,    16.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10992.17 ms /    65 runs   (  169.11 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   13084.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "559it [2:27:32, 17.12s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.06 ms /   107 runs   (    0.22 ms per token,  4639.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3844.64 ms /    62 tokens (   62.01 ms per token,    16.13 tokens per second)\n",
      "llama_print_timings:        eval time =   18061.97 ms /   106 runs   (  170.40 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   22160.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "560it [2:27:54, 18.53s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.61 ms /   117 runs   (    0.21 ms per token,  4753.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1890.77 ms /    30 tokens (   63.03 ms per token,    15.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19661.15 ms /   116 runs   (  169.49 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   21823.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "561it [2:28:11, 18.11s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.89 ms /    86 runs   (    0.22 ms per token,  4551.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2489.44 ms /    34 tokens (   73.22 ms per token,    13.66 tokens per second)\n",
      "llama_print_timings:        eval time =   14423.04 ms /    85 runs   (  169.68 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   17111.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "562it [2:28:24, 16.64s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.49 ms /    68 runs   (    0.23 ms per token,  4390.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1837.51 ms /    30 tokens (   61.25 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =   11222.50 ms /    67 runs   (  167.50 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   13223.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "563it [2:28:37, 15.58s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.44 ms /    63 runs   (    0.23 ms per token,  4362.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2461.47 ms /    42 tokens (   58.61 ms per token,    17.06 tokens per second)\n",
      "llama_print_timings:        eval time =   10472.51 ms /    62 runs   (  168.91 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   13086.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "564it [2:28:53, 15.76s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.59 ms /    84 runs   (    0.22 ms per token,  4518.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2003.89 ms /    32 tokens (   62.62 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =   13988.88 ms /    83 runs   (  168.54 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   16190.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "565it [2:29:17, 18.22s/it]llama_print_timings:      sample time =      25.51 ms /   117 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4035.02 ms /    62 tokens (   65.08 ms per token,    15.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19643.52 ms /   116 runs   (  169.34 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   23954.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "566it [2:29:38, 19.13s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.34 ms /   114 runs   (    0.21 ms per token,  4682.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1850.57 ms /    30 tokens (   61.69 ms per token,    16.21 tokens per second)\n",
      "llama_print_timings:        eval time =   19123.45 ms /   113 runs   (  169.23 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   21236.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "567it [2:29:55, 18.40s/it]llama_print_timings:      sample time =      19.12 ms /    85 runs   (    0.22 ms per token,  4446.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2373.11 ms /    33 tokens (   71.91 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:        eval time =   14138.39 ms /    84 runs   (  168.31 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   16705.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "568it [2:30:10, 17.26s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.82 ms /    75 runs   (    0.22 ms per token,  4457.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1965.76 ms /    30 tokens (   65.53 ms per token,    15.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12471.66 ms /    74 runs   (  168.54 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   14605.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "569it [2:30:28, 17.62s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.20 ms /    95 runs   (    0.22 ms per token,  4480.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2520.47 ms /    42 tokens (   60.01 ms per token,    16.66 tokens per second)\n",
      "llama_print_timings:        eval time =   15719.48 ms /    94 runs   (  167.23 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   18452.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "570it [2:30:40, 15.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.68 ms /    59 runs   (    0.23 ms per token,  4313.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1925.42 ms /    32 tokens (   60.17 ms per token,    16.62 tokens per second)\n",
      "llama_print_timings:        eval time =    9751.38 ms /    58 runs   (  168.13 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   11813.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "571it [2:31:03, 18.12s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.02 ms /   116 runs   (    0.22 ms per token,  4637.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3621.85 ms /    62 tokens (   58.42 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:        eval time =   19475.74 ms /   115 runs   (  169.35 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   23361.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "572it [2:31:21, 18.03s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.93 ms /    93 runs   (    0.21 ms per token,  4667.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1986.36 ms /    30 tokens (   66.21 ms per token,    15.10 tokens per second)\n",
      "llama_print_timings:        eval time =   15602.17 ms /    92 runs   (  169.59 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   17795.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "573it [2:31:38, 17.64s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.66 ms /    87 runs   (    0.23 ms per token,  4425.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2050.13 ms /    34 tokens (   60.30 ms per token,    16.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14485.88 ms /    86 runs   (  168.44 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   16732.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "574it [2:31:52, 16.67s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.09 ms /    75 runs   (    0.23 ms per token,  4389.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1808.98 ms /    30 tokens (   60.30 ms per token,    16.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12439.26 ms /    74 runs   (  168.10 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   14416.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "575it [2:32:05, 15.36s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.13 ms /    58 runs   (    0.23 ms per token,  4416.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2490.92 ms /    42 tokens (   59.31 ms per token,    16.86 tokens per second)\n",
      "llama_print_timings:        eval time =    9661.63 ms /    57 runs   (  169.50 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   12281.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "576it [2:32:15, 13.90s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.15 ms /    51 runs   (    0.22 ms per token,  4572.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1926.62 ms /    32 tokens (   60.21 ms per token,    16.61 tokens per second)\n",
      "llama_print_timings:        eval time =    8461.30 ms /    50 runs   (  169.23 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   10498.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "577it [2:32:30, 14.10s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.57 ms /    65 runs   (    0.22 ms per token,  4461.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3644.56 ms /    62 tokens (   58.78 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:        eval time =   10774.78 ms /    64 runs   (  168.36 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   14562.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "578it [2:32:51, 16.26s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.36 ms /   115 runs   (    0.21 ms per token,  4721.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1845.35 ms /    30 tokens (   61.51 ms per token,    16.26 tokens per second)\n",
      "llama_print_timings:        eval time =   19213.83 ms /   114 runs   (  168.54 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   21310.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "579it [2:33:06, 15.97s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.69 ms /    78 runs   (    0.23 ms per token,  4410.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2025.83 ms /    33 tokens (   61.39 ms per token,    16.29 tokens per second)\n",
      "llama_print_timings:        eval time =   13078.19 ms /    77 runs   (  169.85 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   15274.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "580it [2:33:23, 16.24s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.87 ms /    87 runs   (    0.22 ms per token,  4610.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2072.13 ms /    30 tokens (   69.07 ms per token,    14.48 tokens per second)\n",
      "llama_print_timings:        eval time =   14602.89 ms /    86 runs   (  169.80 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   16863.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "581it [2:33:40, 16.33s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.81 ms /    76 runs   (    0.22 ms per token,  4522.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3546.20 ms /    42 tokens (   84.43 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12843.83 ms /    75 runs   (  171.25 ms per token,     5.84 tokens per second)\n",
      "llama_print_timings:       total time =   16561.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "582it [2:33:52, 15.18s/it]llama_print_timings:      sample time =      13.76 ms /    62 runs   (    0.22 ms per token,  4504.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2059.65 ms /    32 tokens (   64.36 ms per token,    15.54 tokens per second)\n",
      "llama_print_timings:        eval time =   10288.36 ms /    61 runs   (  168.66 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   12482.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "583it [2:34:15, 17.38s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.57 ms /   111 runs   (    0.22 ms per token,  4518.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3713.50 ms /    62 tokens (   59.90 ms per token,    16.70 tokens per second)\n",
      "llama_print_timings:        eval time =   18540.14 ms /   110 runs   (  168.55 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   22503.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "584it [2:34:27, 15.80s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.08 ms /    61 runs   (    0.23 ms per token,  4332.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1903.94 ms /    30 tokens (   63.46 ms per token,    15.76 tokens per second)\n",
      "llama_print_timings:        eval time =   10071.36 ms /    60 runs   (  167.86 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   12117.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "585it [2:34:44, 16.13s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.16 ms /    86 runs   (    0.22 ms per token,  4488.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2212.19 ms /    34 tokens (   65.06 ms per token,    15.37 tokens per second)\n",
      "llama_print_timings:        eval time =   14499.18 ms /    85 runs   (  170.58 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   16900.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "586it [2:35:00, 16.06s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.27 ms /    82 runs   (    0.22 ms per token,  4488.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1822.72 ms /    30 tokens (   60.76 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   13876.36 ms /    81 runs   (  171.31 ms per token,     5.84 tokens per second)\n",
      "llama_print_timings:       total time =   15888.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "587it [2:35:13, 15.21s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.21 ms /    64 runs   (    0.22 ms per token,  4504.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2456.27 ms /    42 tokens (   58.48 ms per token,    17.10 tokens per second)\n",
      "llama_print_timings:        eval time =   10637.11 ms /    63 runs   (  168.84 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   13236.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "588it [2:35:25, 14.27s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.37 ms /    60 runs   (    0.22 ms per token,  4487.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2008.12 ms /    32 tokens (   62.75 ms per token,    15.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9913.62 ms /    59 runs   (  168.03 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   12053.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "589it [2:35:48, 16.90s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.22 ms /   110 runs   (    0.22 ms per token,  4542.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3761.93 ms /    62 tokens (   60.68 ms per token,    16.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19018.08 ms /   109 runs   (  174.48 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =   23031.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "590it [2:36:07, 17.43s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.73 ms /    98 runs   (    0.22 ms per token,  4509.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2065.47 ms /    30 tokens (   68.85 ms per token,    14.52 tokens per second)\n",
      "llama_print_timings:        eval time =   16381.13 ms /    97 runs   (  168.88 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   18667.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "591it [2:36:17, 15.31s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.46 ms /    50 runs   (    0.23 ms per token,  4363.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2074.92 ms /    33 tokens (   62.88 ms per token,    15.90 tokens per second)\n",
      "llama_print_timings:        eval time =    8190.95 ms /    49 runs   (  167.16 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   10376.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "592it [2:36:30, 14.70s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.74 ms /    68 runs   (    0.23 ms per token,  4319.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1820.11 ms /    30 tokens (   60.67 ms per token,    16.48 tokens per second)\n",
      "llama_print_timings:        eval time =   11288.95 ms /    67 runs   (  168.49 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   13264.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "593it [2:36:47, 15.23s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.45 ms /    83 runs   (    0.22 ms per token,  4499.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2510.00 ms /    42 tokens (   59.76 ms per token,    16.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13785.60 ms /    82 runs   (  168.12 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   16480.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "594it [2:36:59, 14.27s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.60 ms /    60 runs   (    0.23 ms per token,  4411.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1939.49 ms /    32 tokens (   60.61 ms per token,    16.50 tokens per second)\n",
      "llama_print_timings:        eval time =    9943.69 ms /    59 runs   (  168.54 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   12015.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "595it [2:37:21, 16.80s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.74 ms /   109 runs   (    0.22 ms per token,  4591.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4101.72 ms /    62 tokens (   66.16 ms per token,    15.12 tokens per second)\n",
      "llama_print_timings:        eval time =   18375.87 ms /   108 runs   (  170.15 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   22716.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "596it [2:37:42, 17.92s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.20 ms /   110 runs   (    0.22 ms per token,  4546.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1837.31 ms /    30 tokens (   61.24 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =   18423.35 ms /   109 runs   (  169.02 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   20509.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "597it [2:37:52, 15.66s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.64 ms /    50 runs   (    0.23 ms per token,  4294.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2052.49 ms /    34 tokens (   60.37 ms per token,    16.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8218.81 ms /    49 runs   (  167.73 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   10383.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "598it [2:38:05, 14.71s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.17 ms /    63 runs   (    0.22 ms per token,  4447.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1951.57 ms /    30 tokens (   65.05 ms per token,    15.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10392.68 ms /    62 runs   (  167.62 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   12483.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "599it [2:38:18, 14.18s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.08 ms /    62 runs   (    0.23 ms per token,  4402.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2526.07 ms /    42 tokens (   60.14 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   10283.26 ms /    61 runs   (  168.58 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   12943.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "600it [2:38:31, 13.75s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.31 ms /    64 runs   (    0.22 ms per token,  4471.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2055.12 ms /    32 tokens (   64.22 ms per token,    15.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10550.55 ms /    63 runs   (  167.47 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =   12744.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "601it [2:38:56, 17.31s/it]llama_print_timings:      sample time =      28.11 ms /   126 runs   (    0.22 ms per token,  4482.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4143.80 ms /    67 tokens (   61.85 ms per token,    16.17 tokens per second)\n",
      "llama_print_timings:        eval time =   21197.04 ms /   125 runs   (  169.58 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   25618.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "602it [2:39:17, 18.48s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.00 ms /   113 runs   (    0.22 ms per token,  4520.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1983.91 ms /    30 tokens (   66.13 ms per token,    15.12 tokens per second)\n",
      "llama_print_timings:        eval time =   18953.17 ms /   112 runs   (  169.22 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   21197.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "603it [2:39:34, 17.89s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.31 ms /    84 runs   (    0.23 ms per token,  4350.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2365.16 ms /    33 tokens (   71.67 ms per token,    13.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13975.17 ms /    83 runs   (  168.38 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   16529.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "604it [2:39:52, 17.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.68 ms /    93 runs   (    0.22 ms per token,  4497.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2112.50 ms /    30 tokens (   70.42 ms per token,    14.20 tokens per second)\n",
      "llama_print_timings:        eval time =   15510.65 ms /    92 runs   (  168.59 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   17830.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "605it [2:40:01, 15.39s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.04 ms /    42 runs   (    0.24 ms per token,  4181.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2572.38 ms /    42 tokens (   61.25 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =    6911.91 ms /    41 runs   (  168.58 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =    9582.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "606it [2:40:16, 15.22s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.21 ms /    73 runs   (    0.22 ms per token,  4503.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2585.88 ms /    36 tokens (   71.83 ms per token,    13.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12080.33 ms /    72 runs   (  167.78 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   14827.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "607it [2:40:40, 17.72s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.80 ms /   117 runs   (    0.22 ms per token,  4534.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3655.06 ms /    62 tokens (   58.95 ms per token,    16.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19628.56 ms /   116 runs   (  169.21 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   23544.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "608it [2:41:00, 18.44s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.70 ms /   108 runs   (    0.22 ms per token,  4557.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1803.95 ms /    30 tokens (   60.13 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   18084.55 ms /   107 runs   (  169.01 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   20132.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "609it [2:41:20, 19.03s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.80 ms /   107 runs   (    0.22 ms per token,  4496.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2262.65 ms /    34 tokens (   66.55 ms per token,    15.03 tokens per second)\n",
      "llama_print_timings:        eval time =   17893.52 ms /   106 runs   (  168.81 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   20398.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "610it [2:41:34, 17.58s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.53 ms /    73 runs   (    0.23 ms per token,  4416.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1980.18 ms /    30 tokens (   66.01 ms per token,    15.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12041.99 ms /    72 runs   (  167.25 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   14188.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "611it [2:41:47, 16.01s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      13.34 ms /    59 runs   (    0.23 ms per token,  4424.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2463.99 ms /    42 tokens (   58.67 ms per token,    17.05 tokens per second)\n",
      "llama_print_timings:        eval time =    9748.35 ms /    58 runs   (  168.08 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   12344.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "612it [2:42:00, 15.32s/it]llama_print_timings:      sample time =      15.41 ms /    69 runs   (    0.22 ms per token,  4478.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2201.64 ms /    36 tokens (   61.16 ms per token,    16.35 tokens per second)\n",
      "llama_print_timings:        eval time =   11349.17 ms /    68 runs   (  166.90 ms per token,     5.99 tokens per second)\n",
      "llama_print_timings:       total time =   13705.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "613it [2:42:26, 18.24s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.18 ms /   125 runs   (    0.23 ms per token,  4435.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3898.89 ms /    62 tokens (   62.89 ms per token,    15.90 tokens per second)\n",
      "llama_print_timings:        eval time =   20869.88 ms /   124 runs   (  168.31 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   25053.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "614it [2:42:46, 18.80s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.38 ms /   107 runs   (    0.22 ms per token,  4576.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2048.47 ms /    30 tokens (   68.28 ms per token,    14.65 tokens per second)\n",
      "llama_print_timings:        eval time =   17819.88 ms /   106 runs   (  168.11 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   20107.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "615it [2:43:02, 17.96s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.12 ms /    83 runs   (    0.23 ms per token,  4340.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1968.81 ms /    33 tokens (   59.66 ms per token,    16.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13828.19 ms /    82 runs   (  168.64 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   15986.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "616it [2:43:16, 16.91s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.07 ms /    74 runs   (    0.23 ms per token,  4336.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1984.83 ms /    30 tokens (   66.16 ms per token,    15.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12299.34 ms /    73 runs   (  168.48 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   14452.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "617it [2:43:28, 15.53s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      12.96 ms /    58 runs   (    0.22 ms per token,  4475.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2524.88 ms /    42 tokens (   60.12 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9668.05 ms /    57 runs   (  169.61 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   12322.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "618it [2:43:43, 15.13s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.17 ms /    71 runs   (    0.23 ms per token,  4391.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2199.43 ms /    36 tokens (   61.10 ms per token,    16.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11829.77 ms /    70 runs   (  169.00 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   14185.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "619it [2:44:06, 17.59s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.54 ms /   115 runs   (    0.22 ms per token,  4502.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3742.95 ms /    62 tokens (   60.37 ms per token,    16.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19336.08 ms /   114 runs   (  169.61 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   23343.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "620it [2:44:26, 18.37s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.82 ms /   108 runs   (    0.22 ms per token,  4534.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1825.65 ms /    30 tokens (   60.86 ms per token,    16.43 tokens per second)\n",
      "llama_print_timings:        eval time =   18108.50 ms /   107 runs   (  169.24 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   20177.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "621it [2:44:43, 17.82s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.15 ms /    85 runs   (    0.23 ms per token,  4439.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2053.62 ms /    34 tokens (   60.40 ms per token,    16.56 tokens per second)\n",
      "llama_print_timings:        eval time =   14314.15 ms /    84 runs   (  170.41 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   16554.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "622it [2:44:59, 17.44s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.77 ms /    85 runs   (    0.22 ms per token,  4528.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2151.74 ms /    30 tokens (   71.72 ms per token,    13.94 tokens per second)\n",
      "llama_print_timings:        eval time =   14217.44 ms /    84 runs   (  169.26 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   16554.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "623it [2:45:12, 16.15s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.17 ms /    63 runs   (    0.22 ms per token,  4444.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2493.27 ms /    42 tokens (   59.36 ms per token,    16.85 tokens per second)\n",
      "llama_print_timings:        eval time =   10506.60 ms /    62 runs   (  169.46 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   13142.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "624it [2:45:28, 16.02s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.30 ms /    80 runs   (    0.23 ms per token,  4372.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2218.07 ms /    36 tokens (   61.61 ms per token,    16.23 tokens per second)\n",
      "llama_print_timings:        eval time =   13301.82 ms /    79 runs   (  168.38 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   15701.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "625it [2:45:53, 18.59s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.62 ms /   122 runs   (    0.23 ms per token,  4416.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3757.34 ms /    62 tokens (   60.60 ms per token,    16.50 tokens per second)\n",
      "llama_print_timings:        eval time =   20547.12 ms /   121 runs   (  169.81 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   24574.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "626it [2:46:14, 19.27s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.86 ms /   111 runs   (    0.21 ms per token,  4651.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1922.22 ms /    30 tokens (   64.07 ms per token,    15.61 tokens per second)\n",
      "llama_print_timings:        eval time =   18683.43 ms /   110 runs   (  169.85 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   20850.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "627it [2:46:31, 18.64s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.30 ms /    89 runs   (    0.23 ms per token,  4384.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2009.32 ms /    33 tokens (   60.89 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =   14972.85 ms /    88 runs   (  170.15 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   17183.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "628it [2:46:45, 17.48s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.53 ms /    76 runs   (    0.23 ms per token,  4335.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2013.29 ms /    30 tokens (   67.11 ms per token,    14.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12590.93 ms /    75 runs   (  167.88 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   14776.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "629it [2:47:03, 17.55s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.61 ms /    90 runs   (    0.23 ms per token,  4367.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2546.53 ms /    42 tokens (   60.63 ms per token,    16.49 tokens per second)\n",
      "llama_print_timings:        eval time =   14961.79 ms /    89 runs   (  168.11 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   17711.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "630it [2:47:19, 16.89s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.76 ms /    78 runs   (    0.23 ms per token,  4392.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2182.01 ms /    36 tokens (   60.61 ms per token,    16.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13000.98 ms /    77 runs   (  168.84 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   15356.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "631it [2:47:42, 18.78s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.02 ms /   114 runs   (    0.22 ms per token,  4556.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3648.26 ms /    62 tokens (   58.84 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19273.97 ms /   113 runs   (  170.57 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   23174.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "632it [2:48:03, 19.45s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.74 ms /   109 runs   (    0.22 ms per token,  4591.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2429.13 ms /    30 tokens (   80.97 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:        eval time =   18345.10 ms /   108 runs   (  169.86 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   21014.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "633it [2:48:21, 19.11s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.69 ms /    95 runs   (    0.23 ms per token,  4379.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2133.32 ms /    34 tokens (   62.74 ms per token,    15.94 tokens per second)\n",
      "llama_print_timings:        eval time =   15959.20 ms /    94 runs   (  169.78 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   18308.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "634it [2:48:31, 16.35s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.31 ms /    48 runs   (    0.24 ms per token,  4244.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1854.74 ms /    30 tokens (   61.82 ms per token,    16.17 tokens per second)\n",
      "llama_print_timings:        eval time =    7966.10 ms /    47 runs   (  169.49 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =    9927.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "635it [2:48:45, 15.60s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.36 ms /    67 runs   (    0.23 ms per token,  4361.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2525.29 ms /    42 tokens (   60.13 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   11158.10 ms /    66 runs   (  169.06 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   13834.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "636it [2:48:58, 14.80s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.44 ms /    63 runs   (    0.23 ms per token,  4364.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2288.74 ms /    36 tokens (   63.58 ms per token,    15.73 tokens per second)\n",
      "llama_print_timings:        eval time =   10513.01 ms /    62 runs   (  169.56 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   12942.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "637it [2:49:24, 18.16s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.80 ms /   128 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4026.01 ms /    62 tokens (   64.94 ms per token,    15.40 tokens per second)\n",
      "llama_print_timings:        eval time =   21663.66 ms /   127 runs   (  170.58 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   25977.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "638it [2:49:47, 19.67s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.29 ms /   125 runs   (    0.22 ms per token,  4580.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1898.08 ms /    30 tokens (   63.27 ms per token,    15.81 tokens per second)\n",
      "llama_print_timings:        eval time =   21012.52 ms /   124 runs   (  169.46 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   23194.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "639it [2:50:06, 19.35s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.60 ms /    96 runs   (    0.22 ms per token,  4445.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2257.51 ms /    33 tokens (   68.41 ms per token,    14.62 tokens per second)\n",
      "llama_print_timings:        eval time =   16145.15 ms /    95 runs   (  169.95 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   18621.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "640it [2:50:22, 18.58s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.35 ms /    87 runs   (    0.22 ms per token,  4495.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1997.63 ms /    30 tokens (   66.59 ms per token,    15.02 tokens per second)\n",
      "llama_print_timings:        eval time =   14561.67 ms /    86 runs   (  169.32 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   16753.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "641it [2:50:33, 16.13s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    47 runs   (    0.22 ms per token,  4472.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2572.12 ms /    42 tokens (   61.24 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =    7758.89 ms /    46 runs   (  168.67 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   10433.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "642it [2:50:48, 15.95s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.03 ms /    74 runs   (    0.23 ms per token,  4344.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2534.61 ms /    36 tokens (   70.41 ms per token,    14.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12811.92 ms /    73 runs   (  175.51 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   15514.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "643it [2:51:13, 18.61s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.25 ms /   122 runs   (    0.22 ms per token,  4477.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3981.90 ms /    62 tokens (   64.22 ms per token,    15.57 tokens per second)\n",
      "llama_print_timings:        eval time =   20580.40 ms /   121 runs   (  170.09 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   24832.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "644it [2:51:34, 19.19s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.84 ms /   109 runs   (    0.22 ms per token,  4571.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1968.31 ms /    30 tokens (   65.61 ms per token,    15.24 tokens per second)\n",
      "llama_print_timings:        eval time =   18307.28 ms /   108 runs   (  169.51 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   20523.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "645it [2:51:51, 18.71s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.60 ms /    92 runs   (    0.22 ms per token,  4466.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2033.20 ms /    34 tokens (   59.80 ms per token,    16.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15365.55 ms /    91 runs   (  168.85 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   17607.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "646it [2:52:06, 17.54s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.91 ms /    75 runs   (    0.23 ms per token,  4435.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2104.00 ms /    30 tokens (   70.13 ms per token,    14.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12521.33 ms /    74 runs   (  169.21 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   14796.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "647it [2:52:22, 17.10s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.07 ms /    80 runs   (    0.23 ms per token,  4426.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2479.08 ms /    42 tokens (   59.03 ms per token,    16.94 tokens per second)\n",
      "llama_print_timings:        eval time =   13399.99 ms /    79 runs   (  169.62 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   16059.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "648it [2:52:35, 15.74s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.26 ms /    62 runs   (    0.23 ms per token,  4348.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2196.76 ms /    36 tokens (   61.02 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10249.06 ms /    61 runs   (  168.02 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   12586.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "649it [2:52:59, 18.42s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.19 ms /   123 runs   (    0.23 ms per token,  4363.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3705.09 ms /    62 tokens (   59.76 ms per token,    16.73 tokens per second)\n",
      "llama_print_timings:        eval time =   20677.44 ms /   122 runs   (  169.49 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   24665.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "650it [2:53:23, 19.85s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.16 ms /   125 runs   (    0.22 ms per token,  4601.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1946.63 ms /    30 tokens (   64.89 ms per token,    15.41 tokens per second)\n",
      "llama_print_timings:        eval time =   20947.99 ms /   124 runs   (  168.94 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   23180.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "651it [2:53:39, 18.77s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.87 ms /    84 runs   (    0.22 ms per token,  4451.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2019.86 ms /    33 tokens (   61.21 ms per token,    16.34 tokens per second)\n",
      "llama_print_timings:        eval time =   14025.52 ms /    83 runs   (  168.98 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   16236.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "652it [2:53:53, 17.47s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.75 ms /    75 runs   (    0.22 ms per token,  4478.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1833.13 ms /    30 tokens (   61.10 ms per token,    16.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12447.99 ms /    74 runs   (  168.22 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   14448.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "653it [2:54:07, 16.34s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.07 ms /    66 runs   (    0.23 ms per token,  4378.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2523.55 ms /    42 tokens (   60.08 ms per token,    16.64 tokens per second)\n",
      "llama_print_timings:        eval time =   11019.77 ms /    65 runs   (  169.53 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   13688.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "654it [2:54:21, 15.61s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.39 ms /    69 runs   (    0.22 ms per token,  4483.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2253.53 ms /    36 tokens (   62.60 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =   11504.61 ms /    68 runs   (  169.19 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   13908.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "655it [2:54:43, 17.62s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.74 ms /   106 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4178.91 ms /    62 tokens (   67.40 ms per token,    14.84 tokens per second)\n",
      "llama_print_timings:        eval time =   17905.61 ms /   105 runs   (  170.53 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   22324.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "656it [2:55:05, 18.94s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.18 ms /   119 runs   (    0.21 ms per token,  4726.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1819.07 ms /    30 tokens (   60.64 ms per token,    16.49 tokens per second)\n",
      "llama_print_timings:        eval time =   19918.01 ms /   118 runs   (  168.80 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   22000.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "657it [2:55:24, 18.82s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.64 ms /    96 runs   (    0.23 ms per token,  4435.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2303.06 ms /    34 tokens (   67.74 ms per token,    14.76 tokens per second)\n",
      "llama_print_timings:        eval time =   16036.43 ms /    95 runs   (  168.80 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   18553.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "658it [2:55:40, 18.15s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.30 ms /    87 runs   (    0.22 ms per token,  4508.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1816.15 ms /    30 tokens (   60.54 ms per token,    16.52 tokens per second)\n",
      "llama_print_timings:        eval time =   14556.26 ms /    86 runs   (  169.26 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   16566.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "659it [2:55:56, 17.37s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.14 ms /    67 runs   (    0.24 ms per token,  4152.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2933.63 ms /    42 tokens (   69.85 ms per token,    14.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12470.53 ms /    66 runs   (  188.95 ms per token,     5.29 tokens per second)\n",
      "llama_print_timings:       total time =   15569.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "660it [2:56:10, 16.41s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.57 ms /    73 runs   (    0.23 ms per token,  4405.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2208.77 ms /    36 tokens (   61.35 ms per token,    16.30 tokens per second)\n",
      "llama_print_timings:        eval time =   11775.65 ms /    72 runs   (  163.55 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   14146.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "661it [2:56:33, 18.49s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.13 ms /   112 runs   (    0.22 ms per token,  4456.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4641.19 ms /    67 tokens (   69.27 ms per token,    14.44 tokens per second)\n",
      "llama_print_timings:        eval time =   18437.73 ms /   111 runs   (  166.11 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =   23336.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "662it [2:56:52, 18.54s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      22.82 ms /   103 runs   (    0.22 ms per token,  4513.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1907.87 ms /    30 tokens (   63.60 ms per token,    15.72 tokens per second)\n",
      "llama_print_timings:        eval time =   16519.73 ms /   102 runs   (  161.96 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   18658.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "663it [2:57:09, 18.23s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.42 ms /    89 runs   (    0.23 ms per token,  4357.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1980.40 ms /    33 tokens (   60.01 ms per token,    16.66 tokens per second)\n",
      "llama_print_timings:        eval time =   15315.35 ms /    88 runs   (  174.04 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   17501.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "664it [2:57:26, 17.62s/it]llama_print_timings:      sample time =      19.72 ms /    87 runs   (    0.23 ms per token,  4411.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2100.04 ms /    30 tokens (   70.00 ms per token,    14.29 tokens per second)\n",
      "llama_print_timings:        eval time =   13889.68 ms /    86 runs   (  161.51 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =   16185.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "665it [2:57:41, 16.90s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.65 ms /    73 runs   (    0.23 ms per token,  4383.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2769.10 ms /    42 tokens (   65.93 ms per token,    15.17 tokens per second)\n",
      "llama_print_timings:        eval time =   12280.95 ms /    72 runs   (  170.57 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   15218.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "666it [2:57:54, 15.88s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.60 ms /    69 runs   (    0.23 ms per token,  4423.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2373.04 ms /    36 tokens (   65.92 ms per token,    15.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10994.16 ms /    68 runs   (  161.68 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =   13521.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "667it [2:58:18, 18.31s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.91 ms /   117 runs   (    0.23 ms per token,  4348.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4093.86 ms /    62 tokens (   66.03 ms per token,    15.14 tokens per second)\n",
      "llama_print_timings:        eval time =   19597.74 ms /   116 runs   (  168.95 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   23965.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "668it [2:58:31, 16.55s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.14 ms /    63 runs   (    0.22 ms per token,  4456.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2214.71 ms /    30 tokens (   73.82 ms per token,    13.55 tokens per second)\n",
      "llama_print_timings:        eval time =   10091.57 ms /    62 runs   (  162.77 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   12447.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "669it [2:58:46, 16.20s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.62 ms /    77 runs   (    0.23 ms per token,  4369.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2189.93 ms /    34 tokens (   64.41 ms per token,    15.53 tokens per second)\n",
      "llama_print_timings:        eval time =   13027.39 ms /    76 runs   (  171.41 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =   15393.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "670it [2:59:00, 15.58s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.06 ms /    74 runs   (    0.23 ms per token,  4338.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2019.48 ms /    30 tokens (   67.32 ms per token,    14.86 tokens per second)\n",
      "llama_print_timings:        eval time =   11938.48 ms /    73 runs   (  163.54 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   14132.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "671it [2:59:14, 14.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.34 ms /    62 runs   (    0.23 ms per token,  4323.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2552.86 ms /    42 tokens (   60.78 ms per token,    16.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10553.49 ms /    61 runs   (  173.01 ms per token,     5.78 tokens per second)\n",
      "llama_print_timings:       total time =   13249.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "672it [2:59:27, 14.53s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.08 ms /    71 runs   (    0.23 ms per token,  4416.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2215.92 ms /    36 tokens (   61.55 ms per token,    16.25 tokens per second)\n",
      "llama_print_timings:        eval time =   11332.35 ms /    70 runs   (  161.89 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   13709.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "673it [2:59:50, 16.98s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      24.17 ms /   107 runs   (    0.23 ms per token,  4427.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4384.55 ms /    62 tokens (   70.72 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:        eval time =   18066.51 ms /   106 runs   (  170.44 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   22704.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "674it [3:00:12, 18.55s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.57 ms /   120 runs   (    0.22 ms per token,  4515.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1812.42 ms /    30 tokens (   60.41 ms per token,    16.55 tokens per second)\n",
      "llama_print_timings:        eval time =   20101.00 ms /   119 runs   (  168.92 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   22195.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "675it [3:00:29, 17.87s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.20 ms /    86 runs   (    0.22 ms per token,  4478.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2344.85 ms /    33 tokens (   71.06 ms per token,    14.07 tokens per second)\n",
      "llama_print_timings:        eval time =   13750.04 ms /    85 runs   (  161.77 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   16287.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "676it [3:00:45, 17.38s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.14 ms /    84 runs   (    0.23 ms per token,  4388.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1851.77 ms /    30 tokens (   61.73 ms per token,    16.20 tokens per second)\n",
      "llama_print_timings:        eval time =   14196.59 ms /    83 runs   (  171.04 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   16240.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "677it [3:00:59, 16.53s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.66 ms /    74 runs   (    0.23 ms per token,  4440.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2522.79 ms /    42 tokens (   60.07 ms per token,    16.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11860.99 ms /    73 runs   (  162.48 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   14551.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "678it [3:01:13, 15.59s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.92 ms /    67 runs   (    0.24 ms per token,  4209.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2533.34 ms /    36 tokens (   70.37 ms per token,    14.21 tokens per second)\n",
      "llama_print_timings:        eval time =   10675.57 ms /    66 runs   (  161.75 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   13371.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "679it [3:01:37, 18.31s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.66 ms /   122 runs   (    0.22 ms per token,  4576.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4724.26 ms /    62 tokens (   76.20 ms per token,    13.12 tokens per second)\n",
      "llama_print_timings:        eval time =   19666.09 ms /   121 runs   (  162.53 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   24662.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "680it [3:02:00, 19.56s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.57 ms /   123 runs   (    0.22 ms per token,  4628.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1947.91 ms /    30 tokens (   64.93 ms per token,    15.40 tokens per second)\n",
      "llama_print_timings:        eval time =   20241.92 ms /   122 runs   (  165.92 ms per token,     6.03 tokens per second)\n",
      "llama_print_timings:       total time =   22472.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "681it [3:02:11, 16.95s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      11.87 ms /    50 runs   (    0.24 ms per token,  4211.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2176.35 ms /    34 tokens (   64.01 ms per token,    15.62 tokens per second)\n",
      "llama_print_timings:        eval time =    8584.40 ms /    49 runs   (  175.19 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   10875.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "682it [3:02:27, 16.78s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      20.20 ms /    90 runs   (    0.22 ms per token,  4454.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1887.80 ms /    30 tokens (   62.93 ms per token,    15.89 tokens per second)\n",
      "llama_print_timings:        eval time =   14291.99 ms /    89 runs   (  160.58 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:       total time =   16386.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "683it [3:02:42, 16.28s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.05 ms /    76 runs   (    0.22 ms per token,  4458.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2533.08 ms /    42 tokens (   60.31 ms per token,    16.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12384.17 ms /    75 runs   (  165.12 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =   15094.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "684it [3:02:58, 16.13s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.00 ms /    79 runs   (    0.23 ms per token,  4389.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3036.50 ms /    36 tokens (   84.35 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12578.62 ms /    78 runs   (  161.26 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   15793.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "685it [3:03:23, 18.75s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.16 ms /   121 runs   (    0.22 ms per token,  4454.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4262.44 ms /    62 tokens (   68.75 ms per token,    14.55 tokens per second)\n",
      "llama_print_timings:        eval time =   20303.91 ms /   120 runs   (  169.20 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   24845.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "686it [3:03:46, 19.95s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      25.09 ms /   112 runs   (    0.22 ms per token,  4464.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1813.20 ms /    30 tokens (   60.44 ms per token,    16.55 tokens per second)\n",
      "llama_print_timings:        eval time =   20668.38 ms /   111 runs   (  186.20 ms per token,     5.37 tokens per second)\n",
      "llama_print_timings:       total time =   22752.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "687it [3:04:01, 18.60s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.08 ms /    82 runs   (    0.23 ms per token,  4296.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2066.83 ms /    33 tokens (   62.63 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =   13183.21 ms /    81 runs   (  162.76 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   15441.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "688it [3:04:10, 15.81s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    46 runs   (    0.24 ms per token,  4243.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1813.64 ms /    30 tokens (   60.45 ms per token,    16.54 tokens per second)\n",
      "llama_print_timings:        eval time =    7384.82 ms /    45 runs   (  164.11 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =    9300.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "689it [3:04:23, 14.95s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.84 ms /    62 runs   (    0.24 ms per token,  4178.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2658.22 ms /    42 tokens (   63.29 ms per token,    15.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10136.05 ms /    61 runs   (  166.16 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =   12939.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "690it [3:04:38, 14.98s/it]llama_print_timings:      sample time =      17.16 ms /    76 runs   (    0.23 ms per token,  4429.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2219.24 ms /    36 tokens (   61.65 ms per token,    16.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12656.50 ms /    75 runs   (  168.75 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   15048.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "691it [3:05:03, 17.96s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      29.04 ms /   128 runs   (    0.23 ms per token,  4407.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3982.65 ms /    62 tokens (   64.24 ms per token,    15.57 tokens per second)\n",
      "llama_print_timings:        eval time =   20634.92 ms /   127 runs   (  162.48 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   24915.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "692it [3:05:23, 18.52s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.76 ms /   106 runs   (    0.22 ms per token,  4461.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1836.02 ms /    30 tokens (   61.20 ms per token,    16.34 tokens per second)\n",
      "llama_print_timings:        eval time =   17735.79 ms /   105 runs   (  168.91 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =   19822.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "693it [3:05:40, 18.08s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      21.21 ms /    93 runs   (    0.23 ms per token,  4384.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2082.31 ms /    34 tokens (   61.24 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =   14776.18 ms /    92 runs   (  160.61 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:       total time =   17065.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "694it [3:05:55, 17.04s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.25 ms /    74 runs   (    0.23 ms per token,  4290.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2090.22 ms /    30 tokens (   69.67 ms per token,    14.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12345.49 ms /    73 runs   (  169.12 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   14607.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "695it [3:06:10, 16.41s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      16.50 ms /    73 runs   (    0.23 ms per token,  4423.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2477.49 ms /    42 tokens (   58.99 ms per token,    16.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12308.55 ms /    72 runs   (  170.95 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   14951.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "696it [3:06:24, 15.83s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.21 ms /    75 runs   (    0.23 ms per token,  4356.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2375.06 ms /    36 tokens (   65.97 ms per token,    15.16 tokens per second)\n",
      "llama_print_timings:        eval time =   11924.10 ms /    74 runs   (  161.14 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   14473.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "697it [3:06:49, 18.50s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      27.31 ms /   124 runs   (    0.22 ms per token,  4540.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3786.82 ms /    62 tokens (   61.08 ms per token,    16.37 tokens per second)\n",
      "llama_print_timings:        eval time =   20648.32 ms /   123 runs   (  167.87 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   24717.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "698it [3:07:11, 19.65s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.07 ms /   121 runs   (    0.22 ms per token,  4641.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2243.05 ms /    30 tokens (   74.77 ms per token,    13.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19803.45 ms /   120 runs   (  165.03 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =   22319.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "699it [3:07:27, 18.62s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      19.85 ms /    87 runs   (    0.23 ms per token,  4382.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2130.13 ms /    33 tokens (   64.55 ms per token,    15.49 tokens per second)\n",
      "llama_print_timings:        eval time =   13903.31 ms /    86 runs   (  161.67 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =   16230.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "700it [3:07:42, 17.54s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.39 ms /    76 runs   (    0.23 ms per token,  4369.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2069.14 ms /    30 tokens (   68.97 ms per token,    14.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12776.84 ms /    75 runs   (  170.36 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   15019.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "701it [3:07:52, 15.25s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    45 runs   (    0.24 ms per token,  4237.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2735.08 ms /    42 tokens (   65.12 ms per token,    15.36 tokens per second)\n",
      "llama_print_timings:        eval time =    7077.38 ms /    44 runs   (  160.85 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =    9914.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "702it [3:08:05, 14.58s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      14.66 ms /    65 runs   (    0.23 ms per token,  4432.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2618.04 ms /    36 tokens (   72.72 ms per token,    13.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10247.60 ms /    64 runs   (  160.12 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   13011.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "703it [3:08:31, 17.92s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      28.88 ms /   132 runs   (    0.22 ms per token,  4570.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4037.90 ms /    62 tokens (   65.13 ms per token,    15.35 tokens per second)\n",
      "llama_print_timings:        eval time =   21366.34 ms /   131 runs   (  163.10 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   25706.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "704it [3:08:51, 18.59s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.49 ms /   107 runs   (    0.22 ms per token,  4554.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2058.23 ms /    30 tokens (   68.61 ms per token,    14.58 tokens per second)\n",
      "llama_print_timings:        eval time =   17846.58 ms /   106 runs   (  168.36 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   20150.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "705it [3:09:07, 17.70s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.62 ms /    76 runs   (    0.23 ms per token,  4313.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2655.16 ms /    34 tokens (   78.09 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12774.37 ms /    75 runs   (  170.32 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   15607.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "706it [3:09:23, 17.22s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.98 ms /    85 runs   (    0.22 ms per token,  4478.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2314.11 ms /    30 tokens (   77.14 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:        eval time =   13609.12 ms /    84 runs   (  162.01 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   16112.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "707it [3:09:38, 16.60s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.04 ms /    78 runs   (    0.23 ms per token,  4324.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2534.68 ms /    42 tokens (   60.35 ms per token,    16.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12413.49 ms /    77 runs   (  161.21 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   15132.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "708it [3:09:54, 16.35s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.24 ms /    78 runs   (    0.23 ms per token,  4276.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2780.52 ms /    36 tokens (   77.24 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12813.53 ms /    77 runs   (  166.41 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =   15777.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "709it [3:10:17, 18.43s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      26.02 ms /   115 runs   (    0.23 ms per token,  4419.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3832.48 ms /    62 tokens (   61.81 ms per token,    16.18 tokens per second)\n",
      "llama_print_timings:        eval time =   19176.05 ms /   114 runs   (  168.21 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   23279.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "710it [3:10:37, 18.71s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.71 ms /   105 runs   (    0.23 ms per token,  4428.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2104.73 ms /    30 tokens (   70.16 ms per token,    14.25 tokens per second)\n",
      "llama_print_timings:        eval time =   17004.51 ms /   104 runs   (  163.50 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   19352.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "711it [3:10:52, 17.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.83 ms /    83 runs   (    0.23 ms per token,  4407.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2356.98 ms /    33 tokens (   71.42 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13393.03 ms /    82 runs   (  163.33 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   15937.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "712it [3:11:07, 16.88s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.33 ms /    78 runs   (    0.23 ms per token,  4256.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1864.41 ms /    30 tokens (   62.15 ms per token,    16.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12523.48 ms /    77 runs   (  162.64 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   14567.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "713it [3:11:23, 16.47s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      17.19 ms /    76 runs   (    0.23 ms per token,  4420.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2534.38 ms /    42 tokens (   60.34 ms per token,    16.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12799.98 ms /    75 runs   (  170.67 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   15510.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "714it [3:11:38, 16.07s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.20 ms /    76 runs   (    0.24 ms per token,  4176.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2218.62 ms /    36 tokens (   61.63 ms per token,    16.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12737.40 ms /    75 runs   (  169.83 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =   15140.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "715it [3:12:04, 19.02s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      30.36 ms /   134 runs   (    0.23 ms per token,  4414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3939.93 ms /    62 tokens (   63.55 ms per token,    15.74 tokens per second)\n",
      "llama_print_timings:        eval time =   21647.61 ms /   133 runs   (  162.76 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   25899.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "716it [3:12:23, 19.22s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.44 ms /   105 runs   (    0.22 ms per token,  4479.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1886.89 ms /    30 tokens (   62.90 ms per token,    15.90 tokens per second)\n",
      "llama_print_timings:        eval time =   17539.38 ms /   104 runs   (  168.65 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   19666.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "717it [3:12:43, 19.22s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      23.57 ms /   103 runs   (    0.23 ms per token,  4370.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2278.37 ms /    34 tokens (   67.01 ms per token,    14.92 tokens per second)\n",
      "llama_print_timings:        eval time =   16710.27 ms /   102 runs   (  163.83 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   19228.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "718it [3:12:58, 18.15s/it]\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      18.63 ms /    82 runs   (    0.23 ms per token,  4402.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2331.95 ms /    30 tokens (   77.73 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13121.50 ms /    81 runs   (  161.99 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   15641.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "719it [3:13:12, 16.74s/it]llama_print_timings:        load time =    4677.82 ms\n",
      "llama_print_timings:      sample time =      15.10 ms /    64 runs   (    0.24 ms per token,  4239.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2486.26 ms /    42 tokens (   59.20 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10817.25 ms /    63 runs   (  171.70 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =   13452.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4677.82 ms\n",
      "720it [3:13:25, 15.74s/it]llama_print_timings:      sample time =      15.70 ms /    69 runs   (    0.23 ms per token,  4396.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2385.01 ms /    36 tokens (   66.25 ms per token,    15.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10880.50 ms /    68 runs   (  160.01 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   13421.06 ms\n",
      "720it [3:13:25, 16.12s/it]\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=\"../models/llama-2-7b-chat.Q4_K_M.gguf\")\n",
    "\n",
    "outputs_llama = []\n",
    "for i, row in tqdm(data.iterrows()):\n",
    "    city_from, city_to, date_str, date_back, need_luggage = (\n",
    "        row[\"city_from\"],\n",
    "        row[\"city_to\"],\n",
    "        row[\"date\"],\n",
    "        row[\"date_back\"],\n",
    "        row[\"need_luggage\"],\n",
    "    )\n",
    "    question = generate_prompt(city_from, city_to, date_str, date_back, need_luggage)\n",
    "    output = llm.create_chat_completion(\n",
    "        messages=[{\"role\": \"user\", \"content\": question}], temperature=0.8\n",
    "    )\n",
    "\n",
    "    outputs_llama.append(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "data[\"llama_question\"] = outputs_llama\n",
    "data.to_csv(\"../data/preprocessed/test_with_questions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация простых вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ../models/zephyr-7b-beta.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:            blk.2.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:            blk.2.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:              blk.2.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:              blk.2.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:         blk.2.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:              blk.2.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:              blk.2.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:            blk.3.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:              blk.3.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:              blk.3.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:            blk.3.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:            blk.4.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:            blk.4.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:              blk.4.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:              blk.4.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:         blk.4.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:              blk.4.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:              blk.4.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:            blk.5.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:            blk.5.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:              blk.5.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:              blk.5.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:         blk.5.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:              blk.5.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:              blk.5.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:            blk.6.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:            blk.6.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:              blk.6.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:              blk.6.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:         blk.6.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:              blk.6.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:              blk.6.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:            blk.7.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:            blk.7.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:              blk.7.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.7.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:         blk.7.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:              blk.7.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:              blk.7.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:         blk.8.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:              blk.8.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:           blk.10.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:           blk.10.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.10.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:             blk.10.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:        blk.10.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:             blk.10.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.10.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:           blk.11.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:           blk.11.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.11.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.11.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:        blk.11.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.11.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.11.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.12.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.12.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:             blk.12.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:        blk.12.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.12.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.12.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:            blk.8.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:            blk.8.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:              blk.8.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:            blk.9.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:            blk.9.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:              blk.9.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:              blk.9.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:         blk.9.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:              blk.9.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.9.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:           blk.12.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.13.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.13.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.13.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.13.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.13.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.13.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.13.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.14.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.14.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.14.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.14.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.14.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.14.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.14.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.15.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.15.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.15.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.15.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.15.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:        blk.17.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:           blk.17.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:             blk.17.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.21.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:             blk.21.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:           blk.21.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:        blk.26.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:             blk.26.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = huggingfaceh4_zephyr-7b-beta\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name   = huggingfaceh4_zephyr-7b-beta\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token = 2 '</s>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: mem required  = 4165.47 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =   64.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 740/740\n",
      "llama_new_context_with_model: compute buffer total size = 76.07 MiB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=\"../models/zephyr-7b-beta.Q4_K_M.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /    12 runs   (    0.21 ms per token,  4792.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.20 ms /    10 tokens (   70.52 ms per token,    14.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2068.93 ms /    11 runs   (  188.08 ms per token,     5.32 tokens per second)\n",
      "llama_print_timings:       total time =    2796.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    30 runs   (    0.23 ms per token,  4334.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    5662.28 ms /    30 runs   (  188.74 ms per token,     5.30 tokens per second)\n",
      "llama_print_timings:       total time =    5722.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    30 runs   (    0.21 ms per token,  4683.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    5636.12 ms /    30 runs   (  187.87 ms per token,     5.32 tokens per second)\n",
      "llama_print_timings:       total time =    5695.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =      22.80 ms /   100 runs   (    0.23 ms per token,  4385.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   16519.34 ms /   100 runs   (  165.19 ms per token,     6.05 tokens per second)\n",
      "llama_print_timings:       total time =   16713.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5208.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     167.08 ms /     1 runs   (  167.08 ms per token,     5.99 tokens per second)\n",
      "llama_print_timings:       total time =     168.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5235.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        eval time =     154.42 ms /     1 runs   (  154.42 ms per token,     6.48 tokens per second)\n",
      "llama_print_timings:       total time =     155.71 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     1 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     152.11 ms /     1 runs   (  152.11 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =     154.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     1 runs   (    0.18 ms per token,  5464.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     160.09 ms /     1 runs   (  160.09 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =     161.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4273.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     152.06 ms /     1 runs   (  152.06 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:       total time =     154.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    22 runs   (    0.21 ms per token,  4774.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3536.07 ms /    22 runs   (  160.73 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =    3575.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    13 runs   (    0.22 ms per token,  4564.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2099.52 ms /    13 runs   (  161.50 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =    2125.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5263.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     166.33 ms /     1 runs   (  166.33 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =     167.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5235.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     161.88 ms /     1 runs   (  161.88 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =     163.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    22 runs   (    0.21 ms per token,  4773.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3468.33 ms /    22 runs   (  157.65 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =    3508.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     159.47 ms /     1 runs   (  159.47 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =     160.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    23 runs   (    0.21 ms per token,  4744.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3644.72 ms /    23 runs   (  158.47 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =    3687.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /    16 runs   (    0.21 ms per token,  4823.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2561.00 ms /    16 runs   (  160.06 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =    2590.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5154.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     153.64 ms /     1 runs   (  153.64 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:       total time =     154.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     1 runs   (    0.18 ms per token,  5464.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     168.35 ms /     1 runs   (  168.35 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =     169.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /    14 runs   (    0.22 ms per token,  4623.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2249.56 ms /    14 runs   (  160.68 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =    2277.46 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     158.67 ms /     1 runs   (  158.67 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =     159.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5076.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     150.47 ms /     1 runs   (  150.47 ms per token,     6.65 tokens per second)\n",
      "llama_print_timings:       total time =     151.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /    12 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1904.18 ms /    12 runs   (  158.68 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =    1929.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5235.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     153.01 ms /     1 runs   (  153.01 ms per token,     6.54 tokens per second)\n",
      "llama_print_timings:       total time =     154.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /    14 runs   (    0.23 ms per token,  4339.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2346.23 ms /    14 runs   (  167.59 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =    2373.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    18 runs   (    0.22 ms per token,  4578.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2838.23 ms /    18 runs   (  157.68 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =    2872.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4347.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     153.68 ms /     1 runs   (  153.68 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:       total time =     155.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /    13 runs   (    0.22 ms per token,  4507.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2060.83 ms /    13 runs   (  158.53 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =    2086.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    21 runs   (    0.21 ms per token,  4726.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3653.91 ms /    21 runs   (  174.00 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =    3693.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5076.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     195.92 ms /     1 runs   (  195.92 ms per token,     5.10 tokens per second)\n",
      "llama_print_timings:       total time =     197.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5181.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     184.76 ms /     1 runs   (  184.76 ms per token,     5.41 tokens per second)\n",
      "llama_print_timings:       total time =     186.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5154.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     184.37 ms /     1 runs   (  184.37 ms per token,     5.42 tokens per second)\n",
      "llama_print_timings:       total time =     185.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     181.95 ms /     1 runs   (  181.95 ms per token,     5.50 tokens per second)\n",
      "llama_print_timings:       total time =     183.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    21 runs   (    0.22 ms per token,  4620.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4007.12 ms /    21 runs   (  190.82 ms per token,     5.24 tokens per second)\n",
      "llama_print_timings:       total time =    4048.25 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /    15 runs   (    0.22 ms per token,  4635.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2863.11 ms /    15 runs   (  190.87 ms per token,     5.24 tokens per second)\n",
      "llama_print_timings:       total time =    2891.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     198.90 ms /     1 runs   (  198.90 ms per token,     5.03 tokens per second)\n",
      "llama_print_timings:       total time =     201.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5235.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     192.82 ms /     1 runs   (  192.82 ms per token,     5.19 tokens per second)\n",
      "llama_print_timings:       total time =     194.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     195.87 ms /     1 runs   (  195.87 ms per token,     5.11 tokens per second)\n",
      "llama_print_timings:       total time =     197.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     186.19 ms /     1 runs   (  186.19 ms per token,     5.37 tokens per second)\n",
      "llama_print_timings:       total time =     187.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5102.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     190.68 ms /     1 runs   (  190.68 ms per token,     5.24 tokens per second)\n",
      "llama_print_timings:       total time =     192.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5291.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     192.93 ms /     1 runs   (  192.93 ms per token,     5.18 tokens per second)\n",
      "llama_print_timings:       total time =     194.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     1 runs   (    0.18 ms per token,  5434.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     185.09 ms /     1 runs   (  185.09 ms per token,     5.40 tokens per second)\n",
      "llama_print_timings:       total time =     186.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5154.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     184.46 ms /     1 runs   (  184.46 ms per token,     5.42 tokens per second)\n",
      "llama_print_timings:       total time =     186.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     176.70 ms /     1 runs   (  176.70 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =     178.72 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     173.08 ms /     1 runs   (  173.08 ms per token,     5.78 tokens per second)\n",
      "llama_print_timings:       total time =     174.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    13 runs   (    0.22 ms per token,  4569.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2358.92 ms /    13 runs   (  181.46 ms per token,     5.51 tokens per second)\n",
      "llama_print_timings:       total time =    2385.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     176.26 ms /     1 runs   (  176.26 ms per token,     5.67 tokens per second)\n",
      "llama_print_timings:       total time =     177.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.80 ms /    13 runs   (    0.22 ms per token,  4639.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2401.15 ms /    13 runs   (  184.70 ms per token,     5.41 tokens per second)\n",
      "llama_print_timings:       total time =    2426.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5102.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     186.68 ms /     1 runs   (  186.68 ms per token,     5.36 tokens per second)\n",
      "llama_print_timings:       total time =     188.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     1 runs   (    0.19 ms per token,  5181.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     177.81 ms /     1 runs   (  177.81 ms per token,     5.62 tokens per second)\n",
      "llama_print_timings:       total time =     179.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /    16 runs   (    0.21 ms per token,  4656.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2966.83 ms /    16 runs   (  185.43 ms per token,     5.39 tokens per second)\n",
      "llama_print_timings:       total time =    2998.17 ms\n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /    18 runs   (    0.22 ms per token,  4535.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2987.71 ms /    18 runs   (  165.98 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =    3022.35 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     167.50 ms /     1 runs   (  167.50 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =     169.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    19 runs   (    0.23 ms per token,  4362.80 tokens per second)\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3203.64 ms /    19 runs   (  168.61 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =    3242.85 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    21 runs   (    0.22 ms per token,  4580.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3472.21 ms /    21 runs   (  165.34 ms per token,     6.05 tokens per second)\n",
      "llama_print_timings:       total time =    3512.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     168.36 ms /     1 runs   (  168.36 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =     170.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    23 runs   (    0.22 ms per token,  4643.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3877.89 ms /    23 runs   (  168.60 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =    3921.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:      sample time =       4.74 ms /    22 runs   (    0.22 ms per token,  4645.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3681.99 ms /    22 runs   (  167.36 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =    3723.50 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =      22.05 ms /    92 runs   (    0.24 ms per token,  4171.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   15216.70 ms /    92 runs   (  165.40 ms per token,     6.05 tokens per second)\n",
      "llama_print_timings:       total time =   15411.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    34 runs   (    0.23 ms per token,  4303.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    5641.73 ms /    34 runs   (  165.93 ms per token,     6.03 tokens per second)\n",
      "llama_print_timings:       total time =    5715.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     170.27 ms /     1 runs   (  170.27 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =     171.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    20 runs   (    0.22 ms per token,  4611.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3364.94 ms /    20 runs   (  168.25 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =    3406.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     162.71 ms /     1 runs   (  162.71 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =     164.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    26 runs   (    0.22 ms per token,  4623.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4265.03 ms /    26 runs   (  164.04 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =    4318.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5076.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     169.62 ms /     1 runs   (  169.62 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =     171.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /    16 runs   (    0.24 ms per token,  4192.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2666.03 ms /    16 runs   (  166.63 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =    2702.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /    13 runs   (    0.23 ms per token,  4378.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2174.90 ms /    13 runs   (  167.30 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =    2200.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /    15 runs   (    0.23 ms per token,  4368.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2497.05 ms /    15 runs   (  166.47 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =    2528.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     170.25 ms /     1 runs   (  170.25 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =     172.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /    15 runs   (    0.22 ms per token,  4526.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2511.76 ms /    15 runs   (  167.45 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =    2540.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    25 runs   (    0.23 ms per token,  4345.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4183.44 ms /    25 runs   (  167.34 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =    4235.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    27 runs   (    0.22 ms per token,  4532.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4471.46 ms /    27 runs   (  165.61 ms per token,     6.04 tokens per second)\n",
      "llama_print_timings:       total time =    4526.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     169.87 ms /     1 runs   (  169.87 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =     171.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /    13 runs   (    0.23 ms per token,  4365.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2218.97 ms /    13 runs   (  170.69 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =    2245.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     170.26 ms /     1 runs   (  170.26 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =     171.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     169.05 ms /     1 runs   (  169.05 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =     171.11 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     172.17 ms /     1 runs   (  172.17 ms per token,     5.81 tokens per second)\n",
      "llama_print_timings:       total time =     173.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:      sample time =       6.27 ms /    28 runs   (    0.22 ms per token,  4467.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4589.62 ms /    28 runs   (  163.91 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =    4647.04 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /    16 runs   (    0.23 ms per token,  4435.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2639.66 ms /    16 runs   (  164.98 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =    2675.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5076.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     163.55 ms /     1 runs   (  163.55 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =     164.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    17 runs   (    0.23 ms per token,  4419.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2800.69 ms /    17 runs   (  164.75 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =    2837.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4608.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     167.46 ms /     1 runs   (  167.46 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =     169.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    19 runs   (    0.22 ms per token,  4628.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3144.80 ms /    19 runs   (  165.52 ms per token,     6.04 tokens per second)\n",
      "llama_print_timings:       total time =    3184.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    12 runs   (    0.22 ms per token,  4472.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1967.18 ms /    12 runs   (  163.93 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =    1991.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     1 runs   (    0.24 ms per token,  4098.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     159.65 ms /     1 runs   (  159.65 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =     162.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    27 runs   (    0.22 ms per token,  4525.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4436.29 ms /    27 runs   (  164.31 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =    4494.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5076.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     163.36 ms /     1 runs   (  163.36 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =     164.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5050.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     170.18 ms /     1 runs   (  170.18 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =     171.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     169.33 ms /     1 runs   (  169.33 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =     171.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5128.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     161.93 ms /     1 runs   (  161.93 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =     163.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     168.56 ms /     1 runs   (  168.56 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =     170.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     1 runs   (    0.18 ms per token,  5586.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     170.75 ms /     1 runs   (  170.75 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =     172.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     166.61 ms /     1 runs   (  166.61 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =     168.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5128.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     171.54 ms /     1 runs   (  171.54 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =     172.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     166.24 ms /     1 runs   (  166.24 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =     167.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     166.79 ms /     1 runs   (  166.79 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =     168.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     169.52 ms /     1 runs   (  169.52 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =     171.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /    17 runs   (    0.23 ms per token,  4269.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2850.59 ms /    17 runs   (  167.68 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =    2886.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     165.80 ms /     1 runs   (  165.80 ms per token,     6.03 tokens per second)\n",
      "llama_print_timings:       total time =     167.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /    25 runs   (    0.22 ms per token,  4573.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4158.44 ms /    25 runs   (  166.34 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =    4208.91 ms\n"
     ]
    }
   ],
   "source": [
    "NUM_QUESTIONS = 100\n",
    "\n",
    "outputs_zephyr = []\n",
    "\n",
    "for i in range(NUM_QUESTIONS):\n",
    "    prompt = f\"Q: Generate one question on any topic. A:\"\n",
    "    output = llm.create_chat_completion(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.8,\n",
    "        max_tokens=100,\n",
    "        stop=[\"\\n\", \"A:\"],\n",
    "    )\n",
    "\n",
    "    outputs_zephyr.append(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "\n",
    "with open(\"../data/random_questions.json\", \"w\") as f:\n",
    "    json.dump(outputs_zephyr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /    14 runs   (    0.22 ms per token,  4635.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1124.38 ms /    16 tokens (   70.27 ms per token,    14.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2438.82 ms /    13 runs   (  187.60 ms per token,     5.33 tokens per second)\n",
      "llama_print_timings:       total time =    3594.31 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     1 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     179.59 ms /     1 runs   (  179.59 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =     182.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    28 runs   (    0.23 ms per token,  4438.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    5154.14 ms /    28 runs   (  184.08 ms per token,     5.43 tokens per second)\n",
      "llama_print_timings:       total time =    5212.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    16 runs   (    0.22 ms per token,  4500.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2841.72 ms /    16 runs   (  177.61 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =    2875.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     159.91 ms /     1 runs   (  159.91 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =     161.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        eval time =     174.99 ms /     1 runs   (  174.99 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =     177.04 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     173.05 ms /     1 runs   (  173.05 ms per token,     5.78 tokens per second)\n",
      "llama_print_timings:       total time =     174.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     163.40 ms /     1 runs   (  163.40 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =     165.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4329.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     172.33 ms /     1 runs   (  172.33 ms per token,     5.80 tokens per second)\n",
      "llama_print_timings:       total time =     174.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /    14 runs   (    0.22 ms per token,  4651.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2362.75 ms /    14 runs   (  168.77 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =    2392.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    21 runs   (    0.23 ms per token,  4396.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4084.55 ms /    21 runs   (  194.50 ms per token,     5.14 tokens per second)\n",
      "llama_print_timings:       total time =    4130.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     200.21 ms /     1 runs   (  200.21 ms per token,     4.99 tokens per second)\n",
      "llama_print_timings:       total time =     201.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    26 runs   (    0.23 ms per token,  4400.07 tokens per second)\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4899.00 ms /    26 runs   (  188.42 ms per token,     5.31 tokens per second)\n",
      "llama_print_timings:       total time =    4956.95 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /    16 runs   (    0.22 ms per token,  4533.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        eval time =    2885.84 ms /    16 runs   (  180.36 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =    2920.38 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     1 runs   (    0.26 ms per token,  3875.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     160.08 ms /     1 runs   (  160.08 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =     162.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    17 runs   (    0.22 ms per token,  4609.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        eval time =    2860.95 ms /    17 runs   (  168.29 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =    2896.35 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    23 runs   (    0.23 ms per token,  4300.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3908.25 ms /    23 runs   (  169.92 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =    3956.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    31 runs   (    0.22 ms per token,  4461.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    5161.88 ms /    31 runs   (  166.51 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =    5226.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     1 runs   (    0.26 ms per token,  3921.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     164.85 ms /     1 runs   (  164.85 ms per token,     6.07 tokens per second)\n",
      "llama_print_timings:       total time =     166.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    17 runs   (    0.23 ms per token,  4391.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2835.67 ms /    17 runs   (  166.80 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =    2872.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    14 runs   (    0.23 ms per token,  4419.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2385.60 ms /    14 runs   (  170.40 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =    2415.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /    18 runs   (    0.22 ms per token,  4487.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3080.04 ms /    18 runs   (  171.11 ms per token,     5.84 tokens per second)\n",
      "llama_print_timings:       total time =    3117.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    12 runs   (    0.22 ms per token,  4620.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2060.45 ms /    12 runs   (  171.70 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =    2085.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    21 runs   (    0.22 ms per token,  4491.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3501.21 ms /    21 runs   (  166.72 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =    3545.76 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:      sample time =       4.71 ms /    21 runs   (    0.22 ms per token,  4457.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3552.15 ms /    21 runs   (  169.15 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =    3594.70 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /    17 runs   (    0.22 ms per token,  4577.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2823.86 ms /    17 runs   (  166.11 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =    2859.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /    17 runs   (    0.23 ms per token,  4259.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2879.12 ms /    17 runs   (  169.36 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =    2916.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /    11 runs   (    0.23 ms per token,  4407.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1858.87 ms /    11 runs   (  168.99 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =    1883.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       9.69 ms /    42 runs   (    0.23 ms per token,  4334.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    7024.84 ms /    42 runs   (  167.26 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =    7111.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /    16 runs   (    0.22 ms per token,  4475.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2670.91 ms /    16 runs   (  166.93 ms per token,     5.99 tokens per second)\n",
      "llama_print_timings:       total time =    2704.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     1 runs   (    0.24 ms per token,  4098.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     163.06 ms /     1 runs   (  163.06 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =     164.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     1 runs   (    0.26 ms per token,  3906.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     175.56 ms /     1 runs   (  175.56 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =     177.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    12 runs   (    0.22 ms per token,  4484.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1974.72 ms /    12 runs   (  164.56 ms per token,     6.08 tokens per second)\n",
      "llama_print_timings:       total time =    2001.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:      sample time =       2.75 ms /    13 runs   (    0.21 ms per token,  4735.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2195.12 ms /    13 runs   (  168.86 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =    2221.19 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /    14 runs   (    0.21 ms per token,  4674.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2400.86 ms /    14 runs   (  171.49 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =    2428.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     1 runs   (    0.26 ms per token,  3846.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     168.12 ms /     1 runs   (  168.12 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =     170.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     1 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     172.75 ms /     1 runs   (  172.75 ms per token,     5.79 tokens per second)\n",
      "llama_print_timings:       total time =     174.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    19 runs   (    0.23 ms per token,  4386.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3187.39 ms /    19 runs   (  167.76 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =    3228.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     164.32 ms /     1 runs   (  164.32 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =     166.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     1 runs   (    0.27 ms per token,  3759.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     175.72 ms /     1 runs   (  175.72 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =     177.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     9 runs   (    0.24 ms per token,  4227.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1524.37 ms /     9 runs   (  169.37 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =    1542.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     165.00 ms /     1 runs   (  165.00 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =     166.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    16 runs   (    0.23 ms per token,  4340.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2997.05 ms /    16 runs   (  187.32 ms per token,     5.34 tokens per second)\n",
      "llama_print_timings:       total time =    3032.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     1 runs   (    0.24 ms per token,  4115.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     176.70 ms /     1 runs   (  176.70 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =     178.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    17 runs   (    0.24 ms per token,  4221.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3019.02 ms /    17 runs   (  177.59 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =    3059.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /    14 runs   (    0.23 ms per token,  4355.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2366.45 ms /    14 runs   (  169.03 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =    2396.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4385.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     160.23 ms /     1 runs   (  160.23 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =     161.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /    16 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        eval time =    2683.65 ms /    16 runs   (  167.73 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =    2718.89 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    12 runs   (    0.22 ms per token,  4608.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2035.48 ms /    12 runs   (  169.62 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =    2061.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /    17 runs   (    0.23 ms per token,  4319.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2884.56 ms /    17 runs   (  169.68 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =    2922.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /    15 runs   (    0.23 ms per token,  4364.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2555.20 ms /    15 runs   (  170.35 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =    2588.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     1 runs   (    0.25 ms per token,  4032.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     160.24 ms /     1 runs   (  160.24 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =     161.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    26 runs   (    0.22 ms per token,  4555.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4297.18 ms /    26 runs   (  165.28 ms per token,     6.05 tokens per second)\n",
      "llama_print_timings:       total time =    4350.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     172.34 ms /     1 runs   (  172.34 ms per token,     5.80 tokens per second)\n",
      "llama_print_timings:       total time =     174.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     177.56 ms /     1 runs   (  177.56 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =     178.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     174.09 ms /     1 runs   (  174.09 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =     175.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     1 runs   (    0.24 ms per token,  4255.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     166.94 ms /     1 runs   (  166.94 ms per token,     5.99 tokens per second)\n",
      "llama_print_timings:       total time =     168.16 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /     7 runs   (    0.22 ms per token,  4455.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1197.20 ms /     7 runs   (  171.03 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =    1210.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    26 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4366.42 ms /    26 runs   (  167.94 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =    4420.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /     8 runs   (    0.23 ms per token,  4257.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1312.95 ms /     8 runs   (  164.12 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =    1330.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     1 runs   (    0.30 ms per token,  3355.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     167.12 ms /     1 runs   (  167.12 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =     170.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /    16 runs   (    0.23 ms per token,  4408.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2705.23 ms /    16 runs   (  169.08 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =    2739.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /    15 runs   (    0.22 ms per token,  4613.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2573.56 ms /    15 runs   (  171.57 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =    2604.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    14 runs   (    0.22 ms per token,  4488.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2304.30 ms /    14 runs   (  164.59 ms per token,     6.08 tokens per second)\n",
      "llama_print_timings:       total time =    2334.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    13 runs   (    0.22 ms per token,  4564.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2205.80 ms /    13 runs   (  169.68 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =    2233.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    22 runs   (    0.21 ms per token,  4697.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3721.36 ms /    22 runs   (  169.15 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =    3764.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /    11 runs   (    0.24 ms per token,  4208.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1944.18 ms /    11 runs   (  176.74 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =    1967.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    13 runs   (    0.21 ms per token,  4715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2217.15 ms /    13 runs   (  170.55 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =    2243.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    19 runs   (    0.23 ms per token,  4369.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3189.55 ms /    19 runs   (  167.87 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =    3230.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /    15 runs   (    0.23 ms per token,  4369.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2480.71 ms /    15 runs   (  165.38 ms per token,     6.05 tokens per second)\n",
      "llama_print_timings:       total time =    2513.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.36 ms /    24 runs   (    0.22 ms per token,  4481.79 tokens per second)\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4051.81 ms /    24 runs   (  168.83 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =    4100.05 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /    17 runs   (    0.22 ms per token,  4485.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2890.29 ms /    17 runs   (  170.02 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =    2925.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    21 runs   (    0.22 ms per token,  4591.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3552.94 ms /    21 runs   (  169.19 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =    3597.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /    15 runs   (    0.22 ms per token,  4447.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2490.73 ms /    15 runs   (  166.05 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =    2525.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     1 runs   (    0.24 ms per token,  4098.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     174.18 ms /     1 runs   (  174.18 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =     175.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     1 runs   (    0.26 ms per token,  3802.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     165.78 ms /     1 runs   (  165.78 ms per token,     6.03 tokens per second)\n",
      "llama_print_timings:       total time =     167.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    27 runs   (    0.23 ms per token,  4442.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4487.01 ms /    27 runs   (  166.19 ms per token,     6.02 tokens per second)\n",
      "llama_print_timings:       total time =    4543.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    23 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3892.48 ms /    23 runs   (  169.24 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =    3942.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    17 runs   (    0.23 ms per token,  4431.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2810.51 ms /    17 runs   (  165.32 ms per token,     6.05 tokens per second)\n",
      "llama_print_timings:       total time =    2851.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /    16 runs   (    0.22 ms per token,  4548.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2663.67 ms /    16 runs   (  166.48 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =    2696.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    29 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4915.52 ms /    29 runs   (  169.50 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =    4975.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /     6 runs   (    0.23 ms per token,  4313.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1001.73 ms /     6 runs   (  166.96 ms per token,     5.99 tokens per second)\n",
      "llama_print_timings:       total time =    1014.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     1 runs   (    0.36 ms per token,  2801.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     156.68 ms /     1 runs   (  156.68 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:       total time =     159.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /    17 runs   (    0.24 ms per token,  4238.34 tokens per second)\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2886.77 ms /    17 runs   (  169.81 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:       total time =    2924.58 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     1 runs   (    0.27 ms per token,  3649.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     181.33 ms /     1 runs   (  181.33 ms per token,     5.51 tokens per second)\n",
      "llama_print_timings:       total time =     183.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /    16 runs   (    0.22 ms per token,  4455.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2683.22 ms /    16 runs   (  167.70 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =    2716.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    18 runs   (    0.22 ms per token,  4501.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2997.03 ms /    18 runs   (  166.50 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =    3035.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    19 runs   (    0.23 ms per token,  4442.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3163.38 ms /    19 runs   (  166.49 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =    3204.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    21 runs   (    0.22 ms per token,  4492.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3560.34 ms /    21 runs   (  169.54 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =    3604.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       5.52 ms /    25 runs   (    0.22 ms per token,  4529.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4185.46 ms /    25 runs   (  167.42 ms per token,     5.97 tokens per second)\n",
      "llama_print_timings:       total time =    4238.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /    15 runs   (    0.22 ms per token,  4462.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2475.82 ms /    15 runs   (  165.05 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =    2506.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     1 runs   (    0.23 ms per token,  4347.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     161.69 ms /     1 runs   (  161.69 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =     163.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /    18 runs   (    0.22 ms per token,  4516.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2994.37 ms /    18 runs   (  166.35 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =    3032.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    13 runs   (    0.22 ms per token,  4487.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2184.14 ms /    13 runs   (  168.01 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =    2212.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     179.90 ms /     1 runs   (  179.90 ms per token,     5.56 tokens per second)\n",
      "llama_print_timings:       total time =     182.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    31 runs   (    0.24 ms per token,  4143.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    5170.15 ms /    31 runs   (  166.78 ms per token,     6.00 tokens per second)\n",
      "llama_print_timings:       total time =    5240.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    20 runs   (    0.23 ms per token,  4386.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3366.73 ms /    20 runs   (  168.34 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =    3409.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    13 runs   (    0.22 ms per token,  4487.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2234.99 ms /    13 runs   (  171.92 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =    2261.56 ms\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     1 runs   (    0.24 ms per token,  4255.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     163.13 ms /     1 runs   (  163.13 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =     164.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1894.37 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /    14 runs   (    0.22 ms per token,  4445.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    2363.71 ms /    14 runs   (  168.84 ms per token,     5.92 tokens per second)\n",
      "llama_print_timings:       total time =    2393.26 ms\n"
     ]
    }
   ],
   "source": [
    "NUM_QUESTIONS = 100\n",
    "\n",
    "outputs_zephyr = []\n",
    "\n",
    "for i in range(NUM_QUESTIONS):\n",
    "    prompt = f\"Q: Generate one question on a topic of airplains and flights. A:\"\n",
    "    output = llm.create_chat_completion(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.8,\n",
    "        max_tokens=100,\n",
    "        stop=[\"\\n\", \"A:\"],\n",
    "    )\n",
    "\n",
    "    outputs_zephyr.append(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "\n",
    "with open(\"../data/plains_flights_questions.json\", \"w\") as f:\n",
    "    json.dump(outputs_zephyr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_finetuning-2kOCaLmK-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
