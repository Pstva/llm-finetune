models/
__pycache__
llama.cpp